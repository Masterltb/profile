[{"uri":"https://masterltb.github.io/profile/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Amazon welcomes White House Executive Order and affirms commitment to pediatric cancer care and research According to the American Childhood Cancer Organization, 42 families learn that their child has been diagnosed with cancer every day in the United States. Far too often, these diagnoses are terminal‚Äîwith kids having few, if any, treatment options. The same clinicians treating children with cancer are also the scientists trying to find a cure, often limited by the number of patients they can see and the data available from similar cases around the world.\nChildhood Cancer Awareness Month shines a spotlight on these diseases, and offers the entire community‚Äîincluding patients, caregivers, clinicians, scientists, industry, and government‚Äîan opportunity to make a difference. Today marks another milestone in the efforts to combat childhood cancer with a new executive order (EO) from the White House aimed at tying together data with the most advanced artificial intelligence (AI) systems to more rapidly identify new treatment options and‚Äîultimately‚Äîsave and improve the lives of kids with a cancer diagnosis.\nThe EO will accelerate the use of AI for improving pediatric clinical trials, patient care, cancer research, and drug discovery. The support and adoption of robust data standards for interoperability is critical in ensuring clinicians, researchers, biopharma, and patients can access the right data at the right time for the right child when every second counts.\nToday‚Äôs EO launches new policy initiatives to harness advances in health data interoperability coupled with new AI technologies to find better treatment options. As a next step, federal policymakers will develop policy changes so that children, their families, and the clinicians treating them can securely use AI on patient-specific data to find a cure.\nAmazon welcomes policy actions to leverage AI and data interoperability to make scientific breakthroughs that will save lives while giving kids and their families hope. We stand ready to lend our expertise to government agencies for these proofs-of-value that use AWS services for health data interoperability, security, privacy-preserving data sharing, and applications of AI to combat cancer.\nEvery second counts, and every data element matters For many years, AWS has supported data intensive efforts in pediatric cancer research, including hosting the Kids First Data Resource Center, a portal for scientific discovery with robust genetic and clinical data for pediatric cancer and congenital disorders. At the AWS Washington DC Summit in 2024, Amazon highlighted support for the Children‚Äôs Brain Tumor Network (CBTN). This 35-site consortium of pediatric centers is focused on harnessing molecular, imaging, clinical, and pathology data to power real world observational trials by merging data and AI. Through a platform built on AWS, scientists and clinicians treating patients can share real-time insights and data with one another, to speed up time to insights for children and their families who receive a new cancer diagnosis. To further accelerate AI initiatives for children‚Äôs health, Amazon offered $1M in philanthropic support each to CBTN, Nationwide Children‚Äôs Hospital and Children‚Äôs National Hospital via the $10M Children‚Äôs Health Innovation Award (CHIA) program.\nThe collaborative model for data sharing established by CBTN scaled further with $10M in funding from the Advanced Research Projects Agency-Health (ARPA-H) for the RADIANT pediatric data infrastructure on AWS. This expanded platform has shown that real-time, secure sharing of EHR data via Bulk FHIR APIs into AWS HealthLake is possible for children with pediatric cancer. AWS is proud to be a key industry partner for RADIANT and the new model of interoperability and secure data exchange that it‚Äôs ushered in for improving research and care.\nFuture-proofing the pediatric cancer AI workforce Building the technology infrastructure serves an essential foundation, but only if clinicians and scientists have the skills they need to leverage the data and AI tools to find a cure. To further accelerate these technology skills, Amazon has collaborated with the NIH Kids First program and CBTN to get more researchers, clinicians, and trainees hands-on experience with data in the cloud and AI tools including at the CBTN Summit, where the AWS Skills Center hosted workshops to help upskill the next generation of scientists on AI and the cloud.\nHope on the horizon For children and families facing cancer diagnoses, finding effective treatment options is critical. By combining AI capabilities and health data interoperability, healthcare providers may be able to identify additional treatment possibilities that could help support patient care. This includes accelerating cancer biomarker discovery through Amazon Bedrock Agents or use of AWS Clean Rooms to enable access to data to multiple researchers without allowing the sharing or copying of the underlying data.\nWith the resilience of children battling cancer, the ingenuity brought by science‚Äôs greatest minds, and today‚Äôs EO that can drive meaningful policy changes, future patients and families receiving an unthinkable pediatric cancer diagnosis will soon have more hope and optimism.\nToday‚Äôs announcement reflects the next step toward combining data and AI to improve children‚Äôs health. Amazon is proud to work with patients, their families, clinicians, and scientists to help lead the way.\nWe encourage you to visit aws.amazon.com/healthcare to learn more about how Amazon can empower pediatric cancer research initiatives.\nAuthor Dr. Rowland Illing ‚Äî Chief Medical Officer and Director of Healthcare and Life Sciences for Amazon Web Services (AWS). In this role, he oversees strategy and engagement for healthcare customers worldwide, encompassing providers, payors, and health technology companies. His work centers on leveraging technologies such as artificial intelligence to drive innovation in health equity and sustainability, while also enabling healthcare organizations to optimize their data utilization for improved efficiency and patient outcomes. An Academic Interventional Radiologist by training, Dr. Illing was previously Director of the Interventional Oncology Service at University College Hospitals London. He holds positions as Honorary Associate Professor at University College London and Visiting Professor of Informatics and Imaging at Oxford University.\n"},{"uri":"https://masterltb.github.io/profile/4-eventparticipated/4.1-event1/","title":"AWS Cloud Day Vietnam - AI Edition 2025","tags":[],"description":"","content":"AWS Cloud Day Vietnam - AI Edition 2025 - Date: September 18, 2025 - Location: 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nEvent Overview A pivotal gathering for Vietnam\u0026rsquo;s tech and business communities, focused on accelerating digital transformation through the convergence of Cloud Computing and Artificial Intelligence.\nKey Objectives:\nDemocratize Generative AI: Move GenAI from concept to practical, context-aware enterprise applications. Align Business \u0026amp; IT: Bridge the gap between business goals and IT, especially in Financial Services. Accelerate Modernization: Provide industry-specific roadmaps for migration and cloud-native development. Strengthen Security: Promote a \u0026ldquo;security by design\u0026rdquo; mindset across the application lifecycle. Key Takeaways \u0026amp; Learnings Data is the Differentiator: A comprehensive data strategy is a prerequisite for successful Generative AI. Modernization is a Continuous Journey: The goal is not just to migrate but to \u0026ldquo;Migrate to Operate\u0026rdquo; and innovate continuously. Business-Led Technology: Technology initiatives must be driven by clear business outcomes. Security is Everyone\u0026rsquo;s Responsibility: Security must be integrated from the first line of code. Application to Work Audit Data Readiness: Assess our current data strategy to ensure it can support future GenAI initiatives. Pilot GenAI in DevOps: Experiment with AI-driven code generation and automated testing to improve development velocity. Benchmark Modernization Efforts: Analyze case studies from Honda Vietnam (SAP migration) and Masterise Group (VMware migration) to refine our own modernization roadmaps. Implement \u0026ldquo;Security at Scale\u0026rdquo;: Integrate security tools and best practices throughout the entire development lifecycle. Event Photos "},{"uri":"https://masterltb.github.io/profile/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: L√¢m Thanh B√¨nh\nPhone Number: 0352668240\nEmail: binhltse184538@fpt.edu.vn\nUniversity: FPT University Ho Chi Minh\nMajor: Information Technology\nClass: SE184538\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 12/08/2025 to 12/11/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://masterltb.github.io/profile/5-workshop/5.1-introduction/","title":"5.1 Introduction","tags":[],"description":"","content":"Module 1: Introduction to Smoking Cessation Platform Infrastructure Module Objectives Understand the overall AWS system architecture Grasp the main components of the platform Understand the data flow between services Prepare for the following modules Overall System Architecture (Hybrid - EC2 + Lambda) AWS Architecture Diagram Architecture Type: Hybrid (EC2 + Serverless Lambda) Deployment Pattern: EC2 for stateful services, Lambda for event-driven tasks\nKey Components 1. Frontend Layer (React + Vite) Hosting: S3 + CloudFront\nFeatures:\nResponsive UI for Web \u0026amp; Mobile Real-time Chat with WebSocket User Authentication (Cognito) Progress Tracking Dashboard Coach Management Interface 2. API Gateway Layer REST API: /api/v1/* endpoints WebSocket: /ws endpoints for real-time chat\nResponsibilities:\nRequest routing Authentication validation Rate limiting CORS handling 3. Backend Layer (Hybrid: EC2 + Lambda) EC2 Application Servers (Always-on):\nuser-cessation service (Port 8000)\nUser profiles, progress tracking Coaching session management Statistics \u0026amp; analytics social-media service (Port 8000)\nSocial features Notifications Community management Lambda Functions (Event-driven):\nFile Upload Lambda\nHandle image/file uploads to S3 Payment Processing Lambda\nProcess payments \u0026amp; subscriptions Specific Trigger Functions\nWebhooks Scheduled tasks 4. WebSocket \u0026amp; Real-time Layer NLB (Network Load Balancer):\nHandles persistent WebSocket connections Port 443 (HTTPS) Distributes real-time chat traffic Integration with EC2 backend servers 5. Database Layer (EC2-hosted) PostgreSQL Server (DB-PG):\nUser profiles \u0026amp; authentication Progress tracking data Coaching session records Relational data MongoDB Server (DB-Mongo):\nChat message history Social media content Message metadata Flexible schema data 6. Security Layer AWS Cognito: User authentication \u0026amp; authorization IAM Roles: Service-to-service permissions VPC: Network isolation (private subnets for databases) Security Groups: Firewall rules for EC2 \u0026amp; databases SSL/TLS: Data encryption in transit \u0026amp; at rest NLB Security Group: Restricts access to WebSocket port 7. Monitoring \u0026amp; Logging CloudWatch: Logs \u0026amp; Metrics for all services CloudTrail: API audit trail EC2 Instance Monitoring: CPU, memory, disk usage Database Monitoring: Query performance, connections Alarms: Performance \u0026amp; health alerts User Journeys \u0026amp; Data Flow Journey 1: User Registration \u0026amp; Login 1. User goes to registration page ‚Üì 2. Frontend sends credentials ‚Üí API Gateway ‚Üí Lambda (Auth Service) ‚Üì 3. Lambda validates \u0026amp; creates user in PostgreSQL (EC2) ‚Üì 4. AWS Cognito creates user account ‚Üì 5. Lambda returns access token \u0026amp; refresh token ‚Üì 6. Frontend stores token ‚Üí has access to API Journey 2: Real-time Chat 1. User A sends message ‚Üì 2. Message sent ‚Üí API Gateway WebSocket endpoint ‚Üì 3. Lambda (Chat Service) processes message ‚Üì 4. Saves message to MongoDB (EC2) ‚Üì 5. WebSocket broadcasts message to User B (connected) ‚Üì 6. User B receives real-time message Journey 3: Progress Tracking 1. User updates progress data (e.g., smoke-free days) ‚Üì 2. Frontend sends ‚Üí API Gateway ‚Üí Lambda (User Service) ‚Üì 3. Lambda validates \u0026amp; updates PostgreSQL (EC2) ‚Üì 4. Coach receives notification (via WebSocket) ‚Üì 5. Dashboard updates real-time Technologies \u0026amp; Services Component Service Details Frontend Hosting S3 + CloudFront Static website hosting + CDN Authentication Cognito User authentication \u0026amp; SSO API Management API Gateway REST API routing Compute (Always-on) EC2 (t4g.small) Main application servers Compute (Event-driven) Lambda Specific functions (upload, payment) Real-time NLB + WebSocket WebSocket connections \u0026amp; messaging Database (SQL) EC2 + PostgreSQL User data, relational data Database (NoSQL) EC2 + MongoDB Chat history, social data Storage S3 File uploads \u0026amp; assets Security VPC, Security Groups, IAM Network isolation \u0026amp; access control Monitoring CloudWatch Logs, metrics, alarms CDN CloudFront Content delivery network Next Modules Module 2: Prerequisites - Prepare account \u0026amp; tools Module 3: Setup Cognito - User authentication Module 4: Setup Lambda - Backend functions Module 5: Setup API Gateway - API endpoints Module 6: Verify EC2 Servers \u0026amp; Databases - PostgreSQL + MongoDB on EC2 Module 7: Setup S3 + CloudFront - Frontend hosting Module 8: Setup VPC \u0026amp; Security - Network security Module 9: Monitoring \u0026amp; Logging - System observability Module 10: Cleanup - Delete resources \u0026amp; cost optimization Checklist Understand overall AWS architecture Grasp 6 main components Understand 3 key user journeys Ready for Module 2 Notes System uses Serverless Architecture - no need to manage servers All services auto-scale according to demand Pay-as-you-go pricing model Highly available \u0026amp; disaster recovery ready "},{"uri":"https://masterltb.github.io/profile/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Week 1: Getting familiar with AWS Console, CLI, and basic services (VPC, EC2).\nWeek 2: IAM Users/Roles, MFA, Billing Alerts, Cost Management.\nWeek 3: Least Privilege, EC2 Instance Profiles, Budgeting strategies.\nWeek 4: Subnets, Route Tables, NAT Gateways, NACLs vs Security Groups.\nWeek 5: Launching instances, Custom AMIs, Session Manager, Lightsail.\nWeek 6: RDS setup, Multi-AZ High Availability, Read Replicas, Backups.\nWeek 7: AWS CLI v2 scripting, Cloud9 environment setup.\nWeek 8: Reviewing Well-Architected Framework and taking the exam.\nWeek 9: Dual-Service Kick-off: Scaffolding for Program \u0026amp; Chat Services, DB Schemas, and Shared Security Layer.\nWeek 10: Program Service Deep Dive: Implementing Daily Routine \u0026amp; Streak Logic.\nWeek 11: Chat Service Implementation \u0026amp; Program Service Refinement.\nWeek 12: System-Wide Finalization: Integration Testing for Both Services, Optimization, and Documentation.\n"},{"uri":"https://masterltb.github.io/profile/1-worklog/1.1-week1/","title":"Worklog Week 1","tags":[],"description":"","content":"Week 1 Objectives Get familiar with the internship environment and connect with your team/class. Build a self-learning routine and complete the challenge series to earn $100 Free Tier. Tasks for this week Day Task Start Date Completion Date Reference Material 2 - Meet teammates and gather key info.\n- Learn office procedures/forms for registration.\n- Directions to the office, visitor card process, and parking. 09/08/2025 09/08/2025 https://cloudjourney.awsstudygroup.com/ 3 - Review the overall program (workshops, projects, deliverables).\n- Create a personal worklog page and start daily notes. 09/09/2025 09/09/2025 https://workshop-sample.fcjuni.com/1-worklog/ 4 - Create an AWS Free Tier account.\n- Distinguish root user vs IAM user.\n- Lab: create/tear down a VPC; launch/terminate an EC2 instance. 09/10/2025 09/10/2025 https://aws.amazon.com/profile 5 - Read the requirements/conditions to obtain $100 credits and the first challenge.\n- Lab: complete Challenge 1 \u0026amp; 2; practice drawing architecture on draw.io. 09/11/2025 09/11/2025 https://us-east-1.console.aws.amazon.com/billing/home#/credits 6 - Continue challenges to reach the remaining $100 credits.\n- Lab: complete Challenge 3, 4, and 5. 09/12/2025 09/12/2025 https://us-east-1.console.aws.amazon.com/billing/home#/credits Week 1 Outcomes Registered for on-site sessions with the team; initial exposure to AWS via Console and common procedures. Successfully created and configured an AWS Free Tier account; understood the difference between root and IAM users. Became familiar with AWS Management Console: searching, navigating, and basic operations on services. Installed and configured AWS CLI (access key, secret key, default region, profile). CLI practice performed:\nChecked account and configuration details. Listed available regions. Queried EC2 instance status. Created/managed key pairs for SSH. Monitored active services to avoid unexpected charges. Additional notes:\nBasic understanding and hands-on with VPC (networking) and EC2 (compute). Sketched initial architecture using draw.io to visualize related resources. Combined Console and CLI in the same workflow for more effective operations. "},{"uri":"https://masterltb.github.io/profile/4-eventparticipated/4.2-event2/","title":"Discover Agentic AI ‚Äì Amazon QuickSuite Workshop","tags":[],"description":"","content":"Discover Agentic AI ‚Äì Amazon QuickSuite Workshop - Date: November 7, 2025 - Location: AWS Vietnam Office, Bitexco Financial Tower, HCMC\nEvent Overview An exclusive workshop focused on the shift from passive Generative AI to autonomous Agentic AI. The event featured the first live demonstration of Amazon QuickSuite in Vietnam and introduced the AWS LIFT Program to lower financial barriers for adoption.\nKey Objectives:\nDefine Agentic AI: Clarify the concept of autonomous AI agents that can reason and execute tasks. Introduce Amazon QuickSuite: Showcase the unified data visualization (QuickSight) and generative AI (Quick Suite Q) platform. Enable Hands-on Learning: Provide a practical environment to build AI concepts with expert guidance. Facilitate Adoption: Offer an $80,000 USD credit through the AWS LIFT Program to accelerate R\u0026amp;D. Key Takeaways \u0026amp; Learnings Focus on Autonomy: The design goal of Agentic AI is to build systems that act on a user\u0026rsquo;s behalf, not just provide information. Ecosystem Approach is Crucial: Effective agents require a connected network of tools, like the one provided by QuickSuite, to link data sources with action logic. Early Adoption Creates Advantage: Gaining proficiency with tools like QuickSuite before they become mainstream offers a significant competitive edge. Funding Accelerates Innovation: Financial incentives like the LIFT program enable companies to experiment and innovate more quickly. Application to Work Explore QuickSuite for Analytics: Investigate integrating QuickSight and Quick Suite Q to create \u0026ldquo;Analyst Agents\u0026rdquo; that can automate data reporting and analysis. Secure R\u0026amp;D Funding: Apply for the AWS LIFT Program to secure credits for upcoming AI-related research and development projects. Identify Automation Use Cases: Audit internal operations to find repetitive, multi-step tasks suitable for autonomous execution by an AI agent. Engage with Implementation Partners: Collaborate with partners like Cloud Kinetics for complex architectural design and implementation, reducing in-house development risks. Event Photos Add your event photos here\n"},{"uri":"https://masterltb.github.io/profile/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Modernize fraud prevention: GraphStorm v0.5 for real-time inference Fraud continues to inflict significant financial damage globally, costing US consumers alone $12.5 billion in 2024‚Äîa 25% increase from the previous year according to the Federal Trade Commission. This surge stems not from more frequent attacks, but from fraudsters‚Äô growing sophistication. As fraudulent activities become more complex and interconnected, conventional machine learning approaches fall short because they analyze transactions in isolation, failing to capture the coordinated networks that characterize modern fraud rings.\nGraph neural networks (GNNs) effectively address this challenge by modeling relationships between entities‚Äîsuch as users sharing devices, locations, or payment methods. By analyzing both network structure and entity features, GNNs excel at identifying sophisticated fraud rings where perpetrators mask individual suspicious activities but leave traces in their relationship networks. However, deploying GNN-based online fraud prevention in production environments presents unique challenges: achieving sub-second inference latency, scaling to billions of nodes and edges, and maintaining operational efficiency for model updates. In this post, we show you how to overcome these challenges using GraphStorm, specifically the new real-time inference capabilities of GraphStorm v0.5.\nPrevious solutions required tradeoffs between capability and simplicity. Our initial DGL approach offered comprehensive real-time capabilities but required complex service orchestration‚Äîinvolving manual updates of endpoint configurations and payload formats after retraining with new hyperparameters. This approach also lacked model flexibility, requiring custom GNN modeling and configuration when using architectures beyond relational graph convolutional networks (RGCN). Subsequent in-memory DGL implementations reduced complexity but faced scalability limitations with enterprise-grade data volumes. We built GraphStorm to bridge this gap, introducing distributed training and high-level APIs that simplify GNN development at enterprise scale.\nIn a recent blog post, we illustrated GraphStorm‚Äôs capability and simplicity in enterprise-scale GNN model training and offline inference. Although offline GNN fraud detection can identify fraudulent transactions after they occur‚Äîpreventing financial loss requires intercepting fraud before it happens. GraphStorm v0.5 now makes this possible through native real-time inference support via Amazon SageMaker AI. GraphStorm v0.5 brings two improvements: streamlined endpoint deployment that reduces weeks of custom engineering‚Äîprogramming SageMaker entry point files, packaging model artifacts, and calling SageMaker deployment APIs‚Äîto a single command operation, and a standardized payload specification that simplifies client integration with real-time inference services. These capabilities enable sub-second node classification tasks like fraud prevention, helping organizations proactively combat fraud threats with scalable, operationally simple GNN solutions.\nTo showcase these capabilities, this post presents a fraud prevention solution. Through this solution, we show how a data scientist can transition a trained GNN model to production-ready inference endpoints with minimal operational overhead. If you are interested in deploying GNN-based models for real-time fraud prevention or similar business cases, you can adapt the methods presented here to create your own solution.\nSolution overview Our proposed solution is a four-step pipeline as shown in the following figure. The pipeline starts in step 1 with exporting a transaction graph from an online transaction processing (OLTP) graph database to scalable storage (Amazon Simple Storage Service (Amazon S3) or Amazon EFS), followed by distributed model training in step 2. Step 3 is GraphStorm v0.5‚Äôs simplified deployment process, which creates SageMaker real-time inference endpoints with a single command. Once SageMaker AI has successfully deployed the endpoint, a client application integrates with the OLTP graph database to process live transaction streams in step 4. By querying the graph database, the client prepares subgraphs around the query transactions, converts the subgraph to a standardized payload format, and invokes the deployed endpoint for real-time prediction.\nTo provide concrete implementation details for each step in the real-time inference solution, we illustrate the complete workflow using the publicly available IEEE-CIS fraud detection task.\nNote: This example uses a Jupyter notebook as the controller for the entire four-step pipeline for simplicity. For a more production-ready design, refer to the architecture described in Build a GNN-based real-time fraud detection solution.\nPrerequisites To run this example, you need an AWS account where the example‚Äôs AWS Cloud Development Kit (AWS CDK) code creates the required resources, including an Amazon Virtual Private Cloud (Amazon VPC), Amazon Neptune database, Amazon SageMaker AI, Amazon Elastic Container Registry (Amazon ECR), Amazon S3, and relevant roles and permissions.\nNote: These resources incur costs during execution (approximately $6 per hour with default settings). Monitor usage carefully and review pricing pages for these services before proceeding. Follow the cleanup instructions at the end to avoid ongoing charges.\nWalkthrough: Real-time fraud prevention with the IEEE-CIS dataset The complete implementation code for this example, including Jupyter notebooks and supporting Python scripts, is available in our public repository. This repository provides a complete end-to-end implementation that you can directly execute and adapt for your own fraud prevention use cases.\nDataset and task overview The example uses the IEEE-CIS fraud detection dataset, containing 500,000 anonymized transactions with approximately 3.5% fraud cases. The dataset includes 392 categorical and numerical features, with key attributes like card type, product type, address, and email domains forming the graph structure shown in the following figure. Each transaction (with an isFraud label) connects to Card type, Location, Product type, and Purchaser and Recipient email domain entities, creating a heterogeneous graph that enables GNN models to detect fraud patterns through entity relationships.\nUnlike our previous post that demonstrated GraphStorm with Amazon Neptune Analytics for offline analytics workflows, this example uses a Neptune database as an OLTP graph store, optimized for the fast subgraph extraction required during real-time inference. Based on the graph design, the tabular IEEE-CIS data is transformed into a set of CSV files compatible with Neptune database format, allowing direct loading into both the Neptune database and GraphStorm‚Äôs model training pipeline with a single file set.\nStep 0: Environment setup Step 0 sets up the required runtime environment for the four-step fraud prevention pipeline. Complete setup instructions are available in the deployment repository.\nTo run the example solution, you need to deploy an AWS CloudFormation stack via the AWS CDK. The stack creates the Neptune DB instance, the VPC to put it in, and appropriate roles and security groups. It additionally creates a SageMaker AI notebook instance, from which you run the example notebooks included with the repository.\ngit clone [https://github.com/aws-samples/amazon-neptune-samples.git](https://github.com/aws-samples/amazon-neptune-samples.git) cd neptune-database-graphstorm-online-inference/neptune-db-cdk # Ensure you have CDK installed and have appropriate credentials set up cdk deploy Once deployment is complete (taking approximately 10 minutes for the necessary resources to be ready), the AWS CDK prints several outputs, one of which is the name of the SageMaker notebook instance you use to run through the notebooks: Bash # Example output NeptuneInfraStack.NotebookInstanceName = arn:aws:sagemaker:us-east-1:012345678912:notebook-instance/NeptuneNotebook-9KgSB9XXXXXX You can navigate to the SageMaker AI notebook UI, find the corresponding notebook instance, and select its Open Jupyterlab link to access the notebook. Alternatively, you can use the AWS Command Line Interface (AWS CLI) to get a pre-signed URL to access the notebook. You will need to replace \u0026lt;notebook-instance-name\u0026gt; with the actual notebook instance name. Bash aws sagemaker create-presigned-notebook-instance-url --notebook-instance-name \u0026lt;notebook-instance-name\u0026gt; Once you are in the notebook web console, open the first notebook, 0-Data-Preparation.ipynb, to start walking through the example. Step 1: Graph construction In Notebook 0-Data-Preparation, you transform the tabular IEEE-CIS dataset into the heterogeneous graph structure shown in the figure at the beginning of this section. The provided Jupyter Notebook extracts entities from transaction features, creating Card Type nodes from card1‚Äìcard6 attributes, Purchaser and Recipient nodes from email domains, Product Type nodes from product codes, and Location nodes from geographic information. This transformation establishes relationships between transactions and these entities, producing graph data in Neptune import format for direct ingestion into the OLTP graph store. The create_neptune_db_data() function orchestrates this entity extraction and relationship creation across all node types (taking approximately 30 seconds). Python GRAPH_NAME = \u0026#34;ieee-cis-fraud-detection\u0026#34; PROCESSED_PREFIX = f\u0026#34;./{GRAPH_NAME}\u0026#34; ID_COLS = \u0026#34;card1,card2,card3,card4,card5,card6,ProductCD,addr1,addr2,P_emaildomain,R_emaildomain\u0026#34; CAT_COLS = \u0026#34;M1,M2,M3,M4,M5,M6,M7,M8,M9\u0026#34; # Lists of columns to keep from each file COLS_TO_KEEP = { \u0026#34;transaction.csv\u0026#34;: ( ID_COLS.split(\u0026#34;,\u0026#34;) + CAT_COLS.split(\u0026#34;,\u0026#34;) + # Numerical features without missing values [f\u0026#34;C{idx}\u0026#34; for idx in range(1, 15)] + [\u0026#34;TransactionID\u0026#34;, \u0026#34;TransactionAmt\u0026#34;, \u0026#34;TransactionDT\u0026#34;, \u0026#34;isFraud\u0026#34;] ), \u0026#34;identity.csv\u0026#34;: [\u0026#34;TransactionID\u0026#34;, \u0026#34;DeviceType\u0026#34;], } create_neptune_db_data( data_prefix=\u0026#34;./input-data/\u0026#34;, output_prefix=PROCESSED_PREFIX, id_cols=ID_COLS, cat_cols=CAT_COLS, cols_to_keep=COLS_TO_KEEP, num_chunks=1, ) The notebook also generates the JSON configuration file required for GraphStorm‚Äôs GConstruct command and executes the graph construction process. This GConstruct command converts the Neptune-formatted data into a distributed binary graph format optimized for GraphStorm‚Äôs training pipeline, partitioning the heterogeneous graph structure across compute nodes to enable scalable model training on industrial-scale graphs (measured in billions of nodes and edges). For the IEEE-CIS data, the GConstruct command takes 90 seconds to complete. In Notebook 1-Load-Data-Into-Neptune-DB, you load the CSV data into the Neptune database instance (taking approximately 9 minutes), which makes them available for online inference. During online inference, upon picking a transaction node, you query the Neptune database to get the graph neighborhood of the target node, retrieving the features of every node in the neighborhood and the subgraph structure around the target. Step 2: Model training Now that you have transformed the data to distributed binary graph format, it is time to train a GNN model. GraphStorm provides command-line scripts for training a model without writing code. In Notebook 2-Model-Training, you train a GNN model using GraphStorm‚Äôs node classification command with configuration managed through YAML files. The basic configuration defines a two-layer RGCN model with 128-dimensional hidden layers, training for 4 epochs with a learning rate of 0.001 and batch size of 1024, taking approximately 100 seconds for 1 epoch of training and model evaluation on an ml.m5.4xlarge instance. To improve fraud detection accuracy, the notebook provides more advanced model configurations like the command below. Bash !python -m graphstorm.run.gs_node_classification \\ --workspace ./ \\ --part-config ieee_gs/ieee-cis.json \\ --num-trainers 1 \\ --cf ieee_nc.yaml \\ --eval-metric roc_auc \\ --save-model-path ./model-simple/ \\ --topk-model-to-save 1 \\ --imbalance-class-weights 0.1,1.0 The arguments in this command address the dataset‚Äôs label imbalance challenge, where only 3.5% of transactions are fraudulent, by using AUC-ROC as the evaluation metric and using class weights. This command also saves the best performing model along with essential configuration files required for endpoint deployment. Advanced configurations can further enhance model performance through techniques like HGT encoders, multi-head attention, and class-weighted cross entropy loss, though these optimizations increase computational requirements. GraphStorm enables these changes through run time arguments and YAML configurations, reducing the need for code modifications. Step 3: Real-time endpoint deployment In Notebook 3-GraphStorm-Endpoint-Deployment, you deploy the real-time endpoint via GraphStorm v0.5‚Äôs simplified launch script. The deployment requires three artifacts generated during training: the saved model file containing weights, the updated graph construction JSON with feature transformation metadata, and the runtime-updated training configuration YAML. These artifacts allow GraphStorm to reconstruct the exact training and model configurations for consistent inference behavior. Notably, the updated graph construction JSON and training configuration YAML files contain critical configurations essential for restoring the trained model on the endpoint and processing incoming request payloads. Using the updated JSON and YAML files for endpoint deployment is crucial. GraphStorm uses SageMaker AI‚Äôs bring your own container (BYOC) feature to deploy a consistent inference environment. You need to build and push the GraphStorm real-time Docker image to Amazon ECR using the provided shell scripts. This containerized approach provides consistent runtime environments compatible with SageMaker AI managed infrastructure. The Docker image contains the necessary dependencies for GraphStorm‚Äôs real-time inference capabilities on the deployment environment. To deploy the endpoint, you can use the launch_realtime_endpoint.py script provided by GraphStorm, which helps you gather the necessary artifacts and creates the required SageMaker AI resources to deploy an endpoint. The script accepts the Amazon ECR image URI, IAM role, model artifact paths, and S3 bucket configuration, automatically handling endpoint provisioning and configuration. By default, the script waits for endpoint deployment to complete before exiting. Upon completion, it prints the deployed endpoint name and AWS Region for subsequent inference requests. You will need to replace the fields enclosed in \u0026lt;\u0026gt; with actual values of your environment. Bash !python ~/graphstorm/sagemaker/launch/launch_realtime_endpoint.py \\ --image-uri \u0026lt;account_id\u0026gt;.dkr.ecr.\u0026lt;aws_region\u0026gt;[.amazonaws.com/graphstorm:sagemaker-endpoint-cpu](https://.amazonaws.com/graphstorm:sagemaker-endpoint-cpu) \\ --role arn:aws:iam::\u0026lt;account_id\u0026gt;:role/\u0026lt;your_role\u0026gt; \\ --region \u0026lt;aws_region\u0026gt; \\ --restore-model-path \u0026lt;restore-model-path\u0026gt;/models/epoch-1/ \\ --model-yaml-config-file \u0026lt;restore-model-path\u0026gt;/models/GRAPHSTORM_RUNTIME_UPDATED_TRAINING_CONFIG.yaml \\ --graph-json-config-file \u0026lt;restore-model-path\u0026gt;/models/data_transform_new.json \\ --infer-task-type node_classification \\ --upload-tarfile-s3 s3://\u0026lt;cdk-created-bucket\u0026gt; \\ --model-name ieee-fraud-detect Step 4: Real-time inference In Notebook 4-Sample-Graph-and-Invoke-Endpoint, you build a basic client application that integrates with the deployed GraphStorm endpoint to perform real-time fraud prevention on incoming transactions. The inference process accepts transaction data via standardized JSON payloads, performs node classification predictions in hundreds of milliseconds, and returns fraud probability scores enabling immediate decision-making. An end-to-end inference call for an existing node in the graph takes three distinct stages: Graph sampling from the Neptune database. For a given target node existing in the graph, retrieve its k-hop neighborhood with a fanout limit, i.e. cap the number of neighbors retrieved at each hop by a threshold. Prepare payload for inference. Neptune returns graphs using GraphSON, a specialized JSON-like data format used to describe graph data. In this step, you need to convert the returned GraphSON to GraphStorm‚Äôs own JSON specification. This step is performed on the client performing inference, in this case a SageMaker notebook instance. Model inference by a SageMaker endpoint. Once the payload is prepared, you send an inference request to a SageMaker endpoint that has loaded a pre-trained model snapshot. The endpoint receives the request, performs any necessary feature transformations (such as converting categorical features to one-hot encoding), creates the in-memory binary graph representation, and makes a prediction for the target node using the graph neighborhood and trained model weights. The response is encoded into JSON and sent back to the client. An example response from the endpoint looks like this: JSON { \u0026#34;status_code\u0026#34;: 200, \u0026#34;request_uid\u0026#34;: \u0026#34;877042dbc361fc33\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Request processed successfully.\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;results\u0026#34;: [ { \u0026#34;node_type\u0026#34;: \u0026#34;Transaction\u0026#34;, \u0026#34;node_id\u0026#34;: \u0026#34;2991260\u0026#34;, \u0026#34;prediction\u0026#34;: [0.995966911315918, 0.004033133387565613] } ] } } The data of interest for the single transaction you predicted is in the prediction key and corresponding node_id. The prediction result gives you the raw scores the model produced for class 0 (legitimate) and class 1 (fraudulent) at the 0th and 1st indexes of the predictions list respectively. In this example, the model flags this transaction as highly likely to be legitimate. You can find the full GraphStorm response specification in GraphStorm documentation. Complete implementation examples, including client code and payload specifications, are provided in the (repository) to guide integration with production systems. Clean up To stop incurring costs on your account, you need to delete the AWS resources you created with AWS CDK at Environment Setup step. First, you must delete the SageMaker endpoint created in Step 3 so the cdk destroy command can complete. See Delete Endpoints and Resources for options to delete an endpoint. Once done, you can run the following command from the root folder of the repository: Bash cd neptune-database-graphstorm-online-inference/neptune-db-cdk cdk destroy See AWS CDK documentation for more information on how to use cdk destroy, or CloudFormation documentation on how to delete a stack from console UI. By default, the cdk destroy command does not delete the model artifacts and processed graph data stored in S3 bucket during the training and deployment. You must delete them manually. See Deleting a general purpose bucket for information on how to empty and delete an S3 bucket AWS CDK created. Conclusion Graph neural networks address complex fraud prevention challenges by modeling entity relationships that traditional machine learning methods miss when analyzing transactions in isolation. GraphStorm v0.5 simplifies GNN real-time inference deployment with single-command endpoint creation, which previously required multi-service orchestration, and a standardized payload specification that simplifies client integration with real-time inference services. Organizations can now deploy enterprise-scale fraud prevention endpoints through streamlined commands, reducing engineering customization from weeks to single-command operations. To implement GNN-based fraud prevention with your own data: Review GraphStorm documentation for model configuration options and deployment specifications. Adapt this IEEE-CIS example for your fraud prevention dataset by modifying the graph construction and feature engineering steps, using the source code and complete tutorials available in our GitHub repository. Visit the step-by-step implementation guide to build production-ready fraud prevention solutions with GraphStorm v0.5‚Äôs advanced capabilities using your enterprise data. Author Jian Zhang ‚Äî Senior Applied Scientist who has used machine learning techniques to help customers solve various problems, such as fraud detection, decor image generation, and more. He successfully developed graph-based machine learning solutions, especially graph neural network, for customers in China, the US, and Singapore. As an evangelist of AWS graph capabilities, Zhang has given many public talks about GraphStorm, GNN, Deep Graph Library (DGL), Amazon Neptune, and other AWS services. Author Theodore Vasiloudis ‚Äî Senior Applied Scientist at AWS, where he works on distributed machine learning systems and algorithms. He led the development of GraphStorm Processing, the distributed graph processing library for GraphStorm and is a core developer for GraphStorm. He received his PhD in Computer Science from KTH Royal Institute of Technology, Stockholm, in 2019. Author Xiang Song ‚Äî Senior Applied Scientist at AWS AI Research and Education (AIRE), where he develops deep learning frameworks including GraphStorm, DGL, and DGL-KE. He led the development of Amazon Neptune ML, a new capability of Neptune that uses graph neural networks for graphs stored in a graph database. He is currently leading the development of GraphStorm, an open source graph machine learning framework for enterprise use cases. He received his PhD in computer systems and architecture at Fudan University, Shanghai, in 2014. Author Florian Saupe ‚Äî Senior Technical Product Manager at AWS AI/ML research, supporting science teams such as the graph machine learning, and ML Systems teams working on large scale distributed training, inference, and fault tolerance. Prior to joining AWS, Florian led technical product management for automated driving at Bosch, was a strategy consultant at McKinsey \u0026amp; Company, and worked as a scientist in control systems and robotics‚Äîa field he holds a PhD in. Author Ozan Eken ‚Äî Product Manager at AWS, passionate about building cutting-edge Generative AI and Graph Analytics products. With a focus on simplifying complex data challenges, Ozan helps customers unlock deeper insights and drive innovation. Outside of work, he enjoys trying new foods, exploring different countries, and watching football. "},{"uri":"https://masterltb.github.io/profile/5-workshop/5.2-perequisites/","title":"5.2 Prerequisites","tags":[],"description":"","content":"Module 2: Prerequisites - Preparing Account \u0026amp; Tools Module Objectives Create \u0026amp; configure an AWS account Set up IAM roles \u0026amp; policies Verify necessary access permissions Set up cost monitoring \u0026amp; alerts Part 1: AWS Account Setup Step 1: Create an AWS Account If you don\u0026rsquo;t have an AWS account yet:\nGo to https://aws.amazon.com/ Click \u0026ldquo;Create an AWS Account\u0026rdquo; Enter your email, password, and account name Choose a Support Plan (Free tier is available) Verify your email \u0026amp; set up billing information Step 2: Log in to the AWS Console Go to https://console.aws.amazon.com/ Enter your root account email \u0026amp; password Verify MFA (Multi-Factor Authentication) if prompted Note: It\u0026rsquo;s recommended to enable MFA for the root account for security.\nPart 2: IAM Setup - Create an Admin User Step 1: Access the IAM Dashboard From the AWS Console, search for \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; from the services list Click \u0026ldquo;Users\u0026rdquo; in the navigation menu Step 2: Create an IAM User for the Workshop Click \u0026ldquo;Create user\u0026rdquo; Enter User name: \u0026ldquo;workshop-admin\u0026rdquo; Check \u0026ldquo;Provide user access to the AWS Management Console - optional\u0026rdquo; Check \u0026ldquo;Users must create a new password at next sign-in - Recommended\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Step 3: Assign Permissions Select \u0026ldquo;Attach policies directly\u0026rdquo;\nFind and check the following policy:\nAdministratorAccess (allows access to all services) Click \u0026ldquo;Next\u0026rdquo;\nStep 4: Review \u0026amp; Create Review the user information Click \u0026ldquo;Create user\u0026rdquo; Download the \u0026ldquo;.csv\u0026rdquo; file containing the credentials Step 5: Log in with the IAM User Copy the User sign-in link from the confirmation screen Open the link in a new browser Log in with the user name \u0026amp; password Part 3: Verify Permissions Check Access to AWS Services Log in to the AWS Console with the IAM user Access each service to verify permissions: Cognito: https://console.aws.amazon.com/cognito/ Lambda: https://console.aws.amazon.com/lambda/ EC2: https://console.aws.amazon.com/ec2/ API Gateway: https://console.aws.amazon.com/apigateway/ S3: https://console.aws.amazon.com/s3/ VPC: https://console.aws.amazon.com/vpc/ Check: You should see \u0026ldquo;Create application\u0026rdquo; (not an error message).\nPart 4: Resource Naming Convention To manage resources easily, use a naming convention:\n{project-name}-{service}-{environment} Examples:\nsmoking-cessation-cognito-dev smoking-cessation-lambda-auth-dev smoking-cessation-db-pg-dev (PostgreSQL on EC2) smoking-cessation-db-mongo-dev (MongoDB on EC2) smoking-cessation-api-dev smoking-cessation-frontend-dev smoking-cessation-vpc-dev Benefit: Easy to find \u0026amp; manage resources in the console.\nTroubleshooting Cannot Create IAM User Check: Are you logged in with the root account or another IAM user? Solution: Log in again with the root account to create the IAM user. Permission Denied Errors Verify: IAM policies attached to the user. Check: Do the policies include the service you are using? Contact: AWS support if you need elevated permissions. Notes From now on, all actions will use the IAM user, not the root account. Each service will have a specific IAM role (created in the next modules). The Free Tier provides sufficient resources for learning. What You Will Achieve After Module 2, you will have:\nAn activated AWS account An IAM user \u0026ldquo;workshop-admin\u0026rdquo; with admin privileges Access to all necessary AWS services Ready for Module 3 (Setup Cognito) "},{"uri":"https://masterltb.github.io/profile/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Smoking Cessation Support System Proposal üìÑ Download Proposal (.docx)\n1. Executive Summary This proposal outlines the design and implementation of a cloud-based Smoking Cessation Support Platform aimed at helping users quit smoking through data tracking, behavioral insights, AI coaching, and community engagement.\nThe system integrates a modern, scalable backend infrastructure deployed on AWS Cloud, ensuring high availability, security, and seamless user experience.\nThe goal is to provide an intelligent, personalized journey for users to monitor, plan, and achieve their smoking cessation goals‚Äîwhile giving administrators and health coaches the tools to support and guide them.\n2. System Objectives Help users build and follow personalized quit-smoking plans. Track smoking behavior and health progress in real-time. Offer AI-driven coaching, reminders, and motivational feedback. Enable social interaction and encouragement among members. Provide a secure, cloud-native infrastructure for scalability and reliability. 3. Key Features User-Oriented Features Registration \u0026amp; Membership Plans: Users can register, select subscription tiers, and make payments for premium features. Smoking Status Tracking: Log daily cigarette consumption, cost, and frequency. Personalized Cessation Plans: Create and adjust quitting plans based on user habits and goals. Progress Tracking: Display statistics such as smoke-free days, money saved, and health improvements. Motivational Notifications: Automated reminders and encouraging messages delivered periodically. Achievements \u0026amp; Badges: Unlock milestones such as ‚Äú7 Days Smoke-Free‚Äù or ‚Äú‚Ç´100K Saved‚Äù. Community Interaction: Share achievements, advice, and encouragement within a supportive network. AI Coaching Agent: Personalized guidance and advice powered by machine learning. Health Device Integration: Collect data from wearable or IoT health devices for progress tracking. Admin \u0026amp; Operator Features Dashboard \u0026amp; Reports: Monitor user metrics, engagement, and health impact analytics. Coach Portal: Health coaches can interact with users via chat or video for counseling. Feedback \u0026amp; Rating Management: Track and respond to user satisfaction metrics. Payment \u0026amp; Subscription Management: Manage fee packages and user subscriptions. 4. System Architecture (AWS Cloud) The system leverages AWS-managed services for scalability and security, as visualized in the architecture diagram.\nFrontend Layer Amazon S3 hosts the static website (React or Angular frontend). Amazon CloudFront distributes the web content globally and handles SSL/TLS encryption. Authentication \u0026amp; Authorization Amazon Cognito manages user sign-up, sign-in, and identity federation, ensuring secure access for both end-users and coaches. Application Layer AWS Lambda powers serverless services such as payment handling or lightweight API operations. Network Load Balancer (NLB) distributes requests across backend EC2 instances. EC2 Instances (Private Subnet) host core microservices: User Service Cessation Service Social Media Service Data Layer PostgreSQL Databases for user and cessation data (on EC2 or RDS). MongoDB for social features and unstructured data. S3 Bucket (Backup) stores periodic encrypted database backups. DevOps Pipeline GitLab CI/CD Pipeline automates deployment to Amazon ECR (Elastic Container Registry) and EC2 instances. VPC Endpoint ensures secure communication with AWS services without exposing traffic to the public internet. EC2 Instance Connect Endpoint enables controlled administrative access. Figure 1 ‚Äì AWS-based cloud architecture for the Smoking Cessation Platform. 5. Security and Compliance Data Encryption: All sensitive data encrypted in transit (TLS) and at rest (AES-256). IAM Policies: Fine-grained access control for different system roles. Private Subnets: Backend and databases are isolated from public exposure. VPC Link \u0026amp; Endpoints: Secure internal communication between services. Backup Strategy: Automated daily backups to S3 with versioning and lifecycle policies. 6. Scalability and Performance Auto Scaling: EC2 and Lambda functions scale based on user demand. CDN Caching: CloudFront caches static content for faster global delivery. Load Balancing: NLB ensures traffic distribution and fault tolerance. Decoupled Microservices: Modular design allows independent scaling of user, cessation, and social services. 7. Future Enhancements Integration with mobile apps for Android and iOS. Advanced AI predictive relapse detection using user patterns. Real-time chat and video counseling. Integration with third-party payment gateways. Gamified health challenges and reward systems. 8. Expected Outcomes Increased smoking cessation success rates. Improved user motivation and engagement. Scalable platform capable of supporting large user bases. Secure, compliant, and maintainable cloud infrastructure. "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.2-week2/","title":"Worklog Week 2","tags":[],"description":"","content":"Week 2 Objectives Set up AWS account and IAM fundamentals. Enable MFA and create IAM users. Understand access control and credential management. Tasks for this week Day Task Start Date Completion Date Reference 2 - Created AWS Free Tier account with root user.\n- Set up billing alerts and free tier monitoring. 16/09/2025 16/09/2025 https://aws.amazon.com/ 3 - Enabled MFA (Multi-Factor Authentication) on root account.\n- Downloaded and saved backup codes securely. 17/09/2025 17/09/2025 https://console.aws.amazon.com/iam/ 4 - Created first IAM user for daily work.\n- Attached AdministratorAccess policy to test user.\n- Generated access keys and tested AWS CLI connection. 18/09/2025 18/09/2025 https://console.aws.amazon.com/iam/ 5 - Explored AWS Management Console navigation.\n- Learned about service regions and availability zones.\n- Reviewed billing dashboard and free tier usage. 19/09/2025 19/09/2025 https://console.aws.amazon.com/billing/ 6 - Studied IAM core components: Users, Groups, Roles, Policies.\n- Created IAM group and added users to group. 20/09/2025 20/09/2025 https://console.aws.amazon.com/iam/ Week 2 Outcomes Successfully created and secured AWS Free Tier account with MFA enabled. Understood root user vs IAM user best practices. Created first IAM user with programmatic access (AWS CLI). Gained foundational knowledge of IAM access control model. Practiced with AWS Management Console and CLI for basic operations. Set up billing alerts to monitor free tier usage and prevent unexpected charges. Key Learnings:\nRoot user should only be used for account recovery (MFA + backup codes critical). IAM users provide granular access control and audit trail. Access keys should be rotated regularly for security. Always use least privilege principle when assigning permissions. "},{"uri":"https://masterltb.github.io/profile/4-eventparticipated/4.3-event3/","title":"AWS Cloud Mastery Series #3 - Security Pillar Deep Dive","tags":[],"description":"","content":"AWS Cloud Mastery Series #3 - Security Pillar Deep Dive - Date: December 1, 2025 - Location: AWS Vietnam Office, Bitexco Financial Tower, HCMC\nEvent Overview An in-depth workshop focused on the Security Pillar of the AWS Well-Architected Framework. The event provided knowledge and best practices for securing cloud workloads.\nKey Objectives:\nDeep Dive into the Security Pillar: Analyze the design principles and key areas of security on AWS. Identity and Access Management: Gain a deep understanding of AWS IAM, MFA, and best practices for access control. Data Protection: Explore techniques for encrypting data at-rest and in-transit. Automation and Monitoring: Learn how to use AWS Config, CloudTrail, and Security Hub to monitor and automate security controls. Key Takeaways \u0026amp; Learnings Security is a Shared Responsibility: Understand the shared responsibility model and the customer\u0026rsquo;s role in securing applications in the cloud. Defense in Depth: Apply multiple layers of security to protect resources comprehensively. Automation is Key: Automating security checks and remediation reduces human error and allows for faster responses to threats. Application to Work Re-evaluate IAM Policies: Review and strengthen existing IAM policies according to the principle of least privilege. Implement Security Monitoring: Set up AWS Security Hub for a centralized, comprehensive view of the security posture. Enhance Data Encryption: Ensure all sensitive data is encrypted using AWS KMS. "},{"uri":"https://masterltb.github.io/profile/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Announcing Amazon ECS Managed Instances for containerized applications Today, we\u0026rsquo;re announcing Amazon ECS Managed Instances, a new compute option for Amazon Elastic Container Service (Amazon ECS) that enables developers to use the full range of Amazon Elastic Compute Cloud (Amazon EC2) capabilities while offloading infrastructure management responsibilities to Amazon Web Service (AWS). This new offering combines the operational simplicity of offloading infrastructure with the flexibility and control of Amazon EC2, which means customers can focus on building applications that drive innovation, while reducing total cost of ownership (TCO) and maintaining AWS best practices.\nAmazon ECS Managed Instances provides a fully managed container compute environment that supports a broad range of EC2 instance types and deep integration with AWS services. By default, it automatically selects the most cost-optimized EC2 instances for your workloads, but you can specify particular instance attributes or types when needed. AWS handles all aspects of infrastructure management, including provisioning, scaling, security patching, and cost optimization, enabling you to concentrate on building and running your applications.\nLet\u0026rsquo;s try it out Looking at the AWS Management Console experience for creating a new Amazon ECS cluster, I can see the new option for using ECS Managed Instances. Let\u0026rsquo;s take a quick tour of all the new options.\nAfter I\u0026rsquo;ve selected Fargate and Managed Instances, I\u0026rsquo;m presented with two options. If I select Use ECS default, Amazon ECS will choose general purpose instance types based on grouping together pending Tasks, and picking the optimum instance type based on cost and resilience metrics. This is the most straightforward and recommended way to get started. Selecting Use custom ‚Äì advanced opens up additional configuration parameters, where I can fine-tune the attributes of instances Amazon ECS will use.\nBy default, I see CPU and Memory as attributes, but I can select from 20 additional attributes to continue to filter the list of available instance types Amazon ECS can access.\nAfter I\u0026rsquo;ve made my attribute selections, I see a list of all the instance types that match my choices.\nFrom here, I can create my ECS cluster as usual and Amazon ECS will provision instances for me on my behalf based on the attributes and criteria I\u0026rsquo;ve defined in the previous steps.\nKey features of Amazon ECS Managed Instances With Amazon ECS Managed Instances, AWS takes full responsibility for infrastructure management, handling all aspects of instance provisioning, scaling, and maintenance. This includes implementing regular security patches initiated every 14 days (due to instance connection draining, the actual lifetime of the instance may be longer), with the ability to schedule maintenance windows using Amazon EC2 event windows to minimize disruption to your applications.\nThe service provides exceptional flexibility in instance type selection. Although it automatically selects cost-optimized instance types by default, you maintain the power to specify desired instance attributes when your workloads require specific capabilities. This includes options for GPU acceleration, CPU architecture, and network performance requirements, giving you precise control over your compute environment.\nTo help optimize costs, Amazon ECS Managed Instances intelligently manages resource utilization by automatically placing multiple tasks on larger instances when appropriate. The service continually monitors and optimizes task placement, consolidating workloads onto fewer instances to dry up, utilize and terminate idle (empty) instances, providing both high availability and cost efficiency for your containerized applications.\nIntegration with existing AWS services is seamless, particularly with Amazon EC2 features such as EC2 pricing options. This deep integration means that you can maximize existing capacity investments while maintaining the operational simplicity of a fully managed service.\nSecurity remains a top priority with Amazon ECS Managed Instances. The service runs on Bottlerocket, a purpose-built container operating system, and maintains your security posture through automated security patches and updates. You can see all the updates and patches applied to the Bottlerocket OS image on the Bottlerocket website. This comprehensive approach to security keeps your containerized applications running in a secure, maintained environment.\nAvailable now Amazon ECS Managed Instances is available today in US East (North Virginia), US West (Oregon), Europe (Ireland), Africa (Cape Town), Asia Pacific (Singapore), and Asia Pacific (Tokyo) AWS Regions. You can start using Managed Instances through the AWS Management Console, AWS Command Line Interface (AWS CLI), or infrastructure as code (IaC) tools such as AWS Cloud Development Kit (AWS CDK) and AWS CloudFormation. You pay for the EC2 instances you use plus a management fee for the service.\nTo learn more about Amazon ECS Managed Instances, visit the documentation and get started simplifying your container infrastructure today.\nAuthor Micah Walter ‚Äî Micah Walter is a Sr. Solutions Architect supporting enterprise customers in the New York City region and beyond. He advises executives, engineers, and architects at every step along their journey to the cloud, with a deep focus on sustainability and practical design. In his free time, Micah enjoys the outdoors, photography, and chasing his kids around the house.\n"},{"uri":"https://masterltb.github.io/profile/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Blog 1 - Amazon welcomes the White House Executive Order on pediatric cancer Pediatric cancer EO, AI-assisted research, and how AWS supports secure data sharing and collaboration.\nBlog 2 - Modernize fraud prevention: GraphStorm v0.5 for real-time inference GraphStorm v0.5 enables real-time, graph-based fraud detection with streamlined SageMaker endpoint deployment.\nBlog 3 - Announcing Amazon ECS Managed Instances for containerized applications ECS Managed Instances: managed EC2-backed compute for ECS combining simplicity with flexibility and cost control.\n"},{"uri":"https://masterltb.github.io/profile/5-workshop/5.3-setup-cognito/","title":"5.3 Setup Cognito","tags":[],"description":"","content":"Module 3: Create Cognito User Pool \u0026amp; Authentication Module Objectives Create a new Cognito User Pool Configure Sign-up \u0026amp; Sign-in options Create an App Client for the frontend Set up User Groups (admin, coach, user) Create test users Test the authentication flow Duration: 3-4 hours\nPart 1: Create a Cognito User Pool Step 1: Access the Cognito Console Log in to the AWS Console (https://console.aws.amazon.com/) Search for \u0026ldquo;Cognito\u0026rdquo; Click on \u0026ldquo;Cognito\u0026rdquo; from the services list Click \u0026ldquo;User pools\u0026rdquo; (left menu) Click \u0026ldquo;Create user pool\u0026rdquo; Step 2: Fill in \u0026ldquo;Set up resources for your application\u0026rdquo; After clicking \u0026ldquo;Create user pool\u0026rdquo;, you will see the \u0026ldquo;Set up resources for your application\u0026rdquo; form:\n2.1 Define your application Application type: Choose \u0026ldquo;Single-page application (SPA)\u0026rdquo; This is the type of your React application Name your application: Enter smoking-cessation-app Limit: 128 characters, can only contain letters, numbers, spaces, +, =, ,, ., @, - 2.2 Options for sign-in identifiers Choose these options:\n‚òëÔ∏è Email (Check) ‚òê Phone number (Uncheck) ‚òê Username (Uncheck) Reason: Email is the simplest way for users to log in.\n2.3 Self-registration ‚òëÔ∏è Enable self-registration (Check) This allows users to register themselves on the platform A \u0026ldquo;Sign up\u0026rdquo; link will be displayed on the login page 2.4 Required attributes for sign-up Choose the required attributes:\n‚òëÔ∏è email (Already checked because you selected Email for sign-in) ‚òëÔ∏è name (Check - to store the user\u0026rsquo;s name) 2.5 Add a return URL (optional) Click on the \u0026ldquo;Return URL\u0026rdquo; field\nEnter: https://localhost:3000/callback\nThis is where Cognito will redirect after a successful login Note: For development, localhost supports HTTP; for production, it must be HTTPS After filling it out, click the \u0026ldquo;Create user directory\u0026rdquo; button at the bottom.\nStep 3: Configure Security Requirements After clicking \u0026ldquo;Authentication methods\u0026rdquo;, you will be taken to the \u0026ldquo;Authentication methods\u0026rdquo; page:\nPassword policy:\nChoose Cognito defaults in Password policy mode Edit email configuration:\nChoose Send email with Cognito in the Email provider Click Save changes Account recovery:\nSelf-service account recovery: ‚òëÔ∏è Enable Recovery method: ‚òëÔ∏è Email ‚òëÔ∏è SMS Step 4: Configure Sign-up Experience \u0026ldquo;Configure sign-up experience\u0026rdquo; page:\nSelf-registration (enabled in step 2):\nEnable self-registration: ‚úÖ Yes Allow users to sign themselves up: ‚úÖ Yes Standard attributes to collect:\n‚òëÔ∏è email (Required) ‚òëÔ∏è name (Required) ‚òê phone_number (Optional - not needed) ‚òê family_name (Optional - not needed) Verification settings:\nHow will a user be confirmed?: Email Cognito will send a confirmation link via email Click \u0026ldquo;Next\u0026rdquo;\nStep 5: Configure Message Delivery \u0026ldquo;Configure message delivery\u0026rdquo; page:\nEmail provider:\nSelect: Cognito (default) Note: The free tier allows 50 emails/day. For production, use Amazon SES. From email address:\nUse the Cognito default email Emails will be sent from no-reply@cognito.amazonaws.com Click \u0026ldquo;Next\u0026rdquo;\nStep 6: Review \u0026amp; Create The final \u0026ldquo;Review and create\u0026rdquo; page:\nReview all the settings you have configured:\nApplication type: Single-page application (SPA) Application name: smoking-cessation-app Sign-in experience Security requirements Sign-up experience Message delivery Scroll down and enter the User pool name:\nName: smoking-cessation-users This is the name of the User Pool (different from the Application name) Click \u0026ldquo;Create user pool\u0026rdquo;\n‚è≥ Wait about 2-3 minutes for the user pool to be created. You will see a success message when it\u0026rsquo;s done.\nStep 7: Success Page - Quick Setup Guide After the user pool is created, you will see the \u0026ldquo;Set up resources for your application\u0026rdquo; page with several options:\nThis page displays:\n\u0026ldquo;Your application \u0026hellip; have been created successfully!\u0026rdquo; - Success notification \u0026ldquo;Check out your sign-in page\u0026rdquo; - A link to test the login page \u0026ldquo;What\u0026rsquo;s the development platform for your single page application?\u0026rdquo; - Options (React, Angular, JavaScript) Code examples - Guidance for frontend integration Note: You will configure the integration code in the next Module. For now, click \u0026ldquo;Go to overview\u0026rdquo; at the bottom to go to the user pool overview page.\nPart 2: Get the User Pool ID After the user pool is created:\nYou will see a success message Note the User Pool ID: The format is ap-southeast-1_xxxxxxxxxxxxx Example: ap-southeast-1_GAXOSoku5 Save it to your .env file: COGNITO_USER_POOL_ID=ap-southeast-1_dskxxxxt3 COGNITO_REGION=ap-southeast-1 Part 3: Create an App Client Step 1: Access App Integration From the User Pool dashboard (smoking-cessation-users) Left menu: Click \u0026ldquo;App integration\u0026rdquo; Click \u0026ldquo;App clients and analytics\u0026rdquo; Click \u0026ldquo;Create app client\u0026rdquo; Step 2: Configure the App Client App client name: smoking-cessation-frontend Refresh token expiration: 30 days Access token expiration: 1 hour (3600 seconds) ID token expiration: 1 hour (3600 seconds) Token validity units: hours Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Authentication Flows Authentication flows and security Select: ‚úÖ ALLOW_USER_PASSWORD_AUTH (for username/password login) ‚úÖ ALLOW_REFRESH_TOKEN_AUTH (for refresh token rotation) ‚úÖ ALLOW_USER_SRP_AUTH (secure password authentication) Click \u0026ldquo;Next\u0026rdquo; Step 4: Configure Hosted UI (Optional but Recommended) Hosted UI settings Hosted UI domain name: smoking-cessation-dev Click \u0026ldquo;Check availability\u0026rdquo; If taken, append -{number} (e.g., smoking-cessation-dev-2) Allowed callback URLs (add for your frontend): For development: http://localhost:3000/callback For production: https://yourdomain.com/callback Allowed sign-out URLs: For development: http://localhost:3000/logout For production: https://yourdomain.com/logout Allowed OAuth 2.0 scopes: ‚úÖ openid ‚úÖ email ‚úÖ profile Click \u0026ldquo;Next\u0026rdquo; Step 5: Advanced Security Settings Advanced security settings Prevent user existence errors: ‚úÖ Enable This prevents attackers from discovering valid usernames Click \u0026ldquo;Create app client\u0026rdquo; ‚è≥ Wait for the app client to be created\nStep 6: Get the App Client ID After the App Client is created:\nFind the Client ID in the app client details section Example: 4175kqc33olfjinhkll4jme379 Save it to your .env file: COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 Part 4: Create User Groups Step 1: Access User Groups From the User Pool (smoking-cessation-users) Left menu: Click \u0026ldquo;User groups\u0026rdquo; Click \u0026ldquo;Create group\u0026rdquo; Step 2: Create the Admin Group Group name: admins Description: Platform administrators with full access Assign IAM role to this group: (Optional, skip for now) Click \u0026ldquo;Create group\u0026rdquo; Step 3: Create the Coach Group Click \u0026ldquo;Create group\u0026rdquo; Group name: coaches Description: Coaches who help users quit smoking Click \u0026ldquo;Create group\u0026rdquo; Step 4: Create the User Group Click \u0026ldquo;Create group\u0026rdquo; Group name: users Description: Regular users of the platform Click \u0026ldquo;Create group\u0026rdquo; Part 5: Create Test Users Step 1: Access Users From the User Pool (smoking-cessation-users) Left menu: Click \u0026ldquo;Users\u0026rdquo; Click \u0026ldquo;Create user\u0026rdquo; Step 2: Create an Admin User Username: admin-test Email address: admin@test.com Temporary password: TempAdminPass123! Mark email as verified: ‚úÖ Check Mark phone number as verified: ‚òê Click \u0026ldquo;Create user\u0026rdquo; Step 3: Assign the Admin User to the Admin Group Click on the newly created admin-test user Scroll down to \u0026ldquo;Group membership\u0026rdquo; Click \u0026ldquo;Add user to groups\u0026rdquo; Select the admins group Click \u0026ldquo;Add user to groups\u0026rdquo; Step 4: Create a Coach User Go back to the Users list Click \u0026ldquo;Create user\u0026rdquo; Username: coach-test Email address: coach@test.com Temporary password: TempCoachPass123! Mark email as verified: ‚úÖ Check Click \u0026ldquo;Create user\u0026rdquo; Step 5: Assign the Coach User to the Coach Group Click on the coach-test user Scroll down to \u0026ldquo;Group membership\u0026rdquo; Click \u0026ldquo;Add user to groups\u0026rdquo; Select the coaches group Click \u0026ldquo;Add user to groups\u0026rdquo; Step 6: Create a Regular User Go back to the Users list Click \u0026ldquo;Create user\u0026rdquo; Username: user-test Email address: user@test.com Temporary password: TempUserPass123! Mark email as verified: ‚úÖ Check Click \u0026ldquo;Create user\u0026rdquo; Assign to the users group (similar to step 5) Part 6: Set Permanent Passwords (Optional) If you want users to be able to log in immediately without changing their temporary password:\nFrom the Users list Click on a user (e.g., admin-test) Click \u0026ldquo;Actions\u0026rdquo; ‚Üí \u0026ldquo;Set password\u0026rdquo; Permanent password: AdminPass123! Make this permanent password: ‚úÖ Check Click \u0026ldquo;Set password\u0026rdquo; Part 7: Additional App Client Configuration (Authentication Methods) Step 1: Configure App Client Details From the User Pool ‚Üí App integration ‚Üí App clients Click on smoking-cessation-frontend Scroll down ‚Üí \u0026ldquo;Client secret\u0026rdquo; ‚ö†Ô∏è Note: If you create a Client Secret, your frontend JavaScript will not be able to use it (because the secret cannot be stored securely on the client) Recommendation: Do not create a Client Secret for a public frontend Leave \u0026ldquo;Client secret\u0026rdquo; as-is (do not create) Part 8: Enable Cognito Hosted UI (Optional) Step 1: Configure the Hosted UI Domain From the User Pool ‚Üí App integration ‚Üí Domain name If already configured ‚Üí Skip If not ‚Üí Click \u0026ldquo;Create domain\u0026rdquo; Domain prefix: smoking-cessation-dev Click \u0026ldquo;Create domain\u0026rdquo; ‚è≥ Wait 1-2 minutes for the domain to be created\nStep 2: Test the Hosted UI From App integration ‚Üí App clients Click on smoking-cessation-frontend Scroll down to \u0026ldquo;Hosted UI settings\u0026rdquo; Find the Hosted UI domain URL: Format: https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com Click the link to open the Hosted UI Test login: Username: admin-test Password: AdminPass123! Should redirect to http://localhost:3000/callback (or the configured callback URL) Part 9: Summary Information Save this information to your .env file:\n# Cognito Configuration COGNITO_REGION=us-east-1 COGNITO_USER_POOL_ID=us-east-1_dskUsnKt3 COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 COGNITO_DOMAIN=smoking-cessation-dev COGNITO_HOSTED_UI_DOMAIN=https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com # Test User Credentials (to be removed before production) TEST_ADMIN_USER=admin-test TEST_ADMIN_PASSWORD=AdminPass123! TEST_COACH_USER=coach-test TEST_COACH_PASSWORD=TempCoachPass123! TEST_USER=user-test TEST_USER_PASSWORD=TempUserPass123! Part 10: Troubleshooting \u0026ldquo;Email already exists\u0026rdquo; Problem: Creating a user but the email already exists.\nSolution:\nFrom the Users list Find the user with that email Delete it (if it\u0026rsquo;s a test user) Create a new user with a different email \u0026ldquo;Temporary password doesn\u0026rsquo;t meet requirements\u0026rdquo; Problem: The password does not meet the requirements.\nSolution:\nThe password must: Be a minimum of 12 characters Have an uppercase letter (A-Z) Have a lowercase letter (a-z) Have a number (0-9) Have a special character (!@#$%^\u0026amp;*) Valid examples: TempPass123!, AdminTest456! \u0026ldquo;Hosted UI domain not available\u0026rdquo; Problem: The domain is already in use.\nSolution:\nAdd a number to the suffix: smoking-cessation-dev-2 Or use a different name Checklist User Pool \u0026ldquo;smoking-cessation-users\u0026rdquo; created successfully App Client \u0026ldquo;smoking-cessation-frontend\u0026rdquo; created successfully 3 User Groups created (admins, coaches, users) 3 test users created \u0026amp; assigned to groups Permanent passwords set for test users Hosted UI domain configured Login test successful with admin-test user .env file updated with Cognito credentials Ready for Module 4 (Setup Lambda) What You Will Achieve After Module 3, you will have:\n‚úÖ A fully functional Cognito User Pool ‚úÖ An App Client for the frontend to connect to ‚úÖ User Groups (admins, coaches, users) for role-based access control ‚úÖ Test users to verify the authentication flow ‚úÖ A Hosted UI domain that can be used for login/signup ‚úÖ Credentials saved for use in the following modules "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.3-week3/","title":"Worklog Week 3","tags":[],"description":"","content":"Week 3 Objectives Understand IAM security best practices and credential handling. Learn about AWS Budgets for cost control. Practice least privilege access patterns. Tasks for this week Day Task Start Date Completion Date Reference 2 - Studied IAM access keys vs temporary credentials.\n- Learned about EC2 instance roles and metadata service. 23/09/2025 23/09/2025 https://docs.aws.amazon.com/iam/ 3 - Created IAM roles for EC2 instances.\n- Attached policies to roles with least privilege principle.\n- Tested role-based access via metadata endpoint. 24/09/2025 24/09/2025 https://console.aws.amazon.com/iam/ 4 - Set up AWS Budgets for monthly cost monitoring.\n- Created alert thresholds at 80% and 100% of $50 limit.\n- Reviewed free tier usage patterns and cost drivers. 25/09/2025 25/09/2025 https://console.aws.amazon.com/billing/budgets/ 5 - Configured budget alerts via email notifications.\n- Learned about cost optimization strategies and Reserved Instances. 26/09/2025 26/09/2025 https://console.aws.amazon.com/ce/ 6 - Practiced applying permissions policies to users and roles.\n- Verified least privilege enforcement with test scenarios. 27/09/2025 27/09/2025 https://console.aws.amazon.com/iam/ Week 3 Outcomes Transitioned from hardcoded access keys to IAM role-based approach. Successfully configured EC2 instance roles for secure access. Established AWS Budgets and cost monitoring infrastructure. Implemented least privilege access patterns across IAM users and roles. Gained understanding of cost control mechanisms and free tier limits. IAM security practices implemented:\nIAM Roles are preferred over access keys for applications and EC2 instances. Metadata service provides temporary credentials automatically. Role-based access control ensures better security and auditability. Temporary credentials auto-rotate for enhanced security. Cost monitoring and budget setup:\nAWS Budgets configured with alerts at 80% and 100% thresholds. Email notifications track spending patterns in real-time. Regular budget reviews prevent unexpected charges. Cost monitoring enables early detection of resource waste. "},{"uri":"https://masterltb.github.io/profile/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"Event 1 Event Name: AWS Cloud Day Vietnam - AI Edition 2025\nDate: September 18, 2025\nLocation: 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nEvent Overview and Key Activities The AWS Cloud Day Vietnam - AI Edition 2025 served as a pivotal forum designed to accelerate Vietnam\u0026rsquo;s digital transformation, harnessing the power of Cloud Computing and Artificial Intelligence. The event explored four core themes:\nDemocratizing Generative AI for Enterprises Bridging the Gap Between Business and IT in Finance Accelerating Industry Modernization Enhancing Security Frameworks The day‚Äôs activities featured high-level plenary sessions with government officials and industry leaders, followed by in-depth technical tracks focused on Data Strategy, DevOps, and Cloud Migration Pathways.\nKey Takeaways and Outcomes Strategic Insights: Gained a deeper understanding of the critical interplay between Generative AI and a robust data strategy, identified as the key driver for success in modern enterprises. Migration to Operate Mindset: Developed an appreciation for the \u0026ldquo;Migrate to Operate\u0026rdquo; framework, which emphasizes using AI to streamline operations and optimize costs post-cloud migration. Technical Knowledge: Acquired insights into the integration of Generative AI within the DevOps lifecycle, particularly in automating code generation and testing. Security Innovations: Learned about the \u0026ldquo;Security by Design\u0026rdquo; approach, which focuses on embedding security measures throughout the application lifecycle rather than relying solely on perimeter defenses. This event provided invaluable knowledge and practical takeaways, further enhancing my understanding of the intersection between AI, cloud computing, and security in the context of modern enterprise solutions.\nEvent 2 Event Name: Discover Agentic AI ‚Äì Amazon QuickSuite Workshop\nDate: November 7, 2025\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City\nEvent Overview and Key Activities The \u0026ldquo;Discover Agentic AI ‚Äì Amazon QuickSuite Workshop,\u0026rdquo; organized in collaboration with Cloud Kinetics, served as a strategic technical session marking the evolution from passive Generative AI to autonomous Agentic AI. The event featured the first-ever live demonstration of Amazon QuickSuite in Vietnam. The workshop focused on four key pillars:\nDefining the \u0026ldquo;Agentic\u0026rdquo; paradigm: Autonomy, Reasoning, and Execution. Integrating Data and AI through the Amazon QuickSuite ecosystem. Hands-on building of AI concepts with AWS technical experts. Financial enablement for innovation through the AWS LIFT Program. The agenda combined theoretical architectural sessions with practical, hands-on workshops using Amazon QuickSight and Quick Suite Q, allowing participants to build functional AI concepts in real-time.\nKey Takeaways and Outcomes Paradigm Shift: Gained a clear understanding of the transition from Generative AI (content creation) to Agentic AI (autonomous task execution), where systems can perceive environments and act independently to solve business problems. Unified Ecosystem: Acquired practical insights into Amazon QuickSuite, learning how to integrate business intelligence (QuickSight) with generative capabilities to create \u0026ldquo;Analyst Agents\u0026rdquo; that streamline operations. Operational Agility: Recognized the strategic value of the \u0026ldquo;Quick\u0026rdquo; framework, which emphasizes rapid deployment and \u0026ldquo;Time-to-Value,\u0026rdquo; allowing enterprises to implement complex AI solutions with speed. Strategic Enablement: Learned about the AWS LIFT Program (offering up to $80,000 USD in credit), identifying it as a critical mechanism to de-risk R\u0026amp;D and accelerate the adoption of high-performance computing. This workshop provided a concrete roadmap for building autonomous enterprise systems, combining theoretical knowledge with hands-on technical skills and strategic financial insights to accelerate digital transformation.\nEvent 3 Event Name: AWS Cloud Mastery Series #3 - Security Pillar Deep Dive\nDate: December 1, 2025\nLocation: Online\nEvent Overview and Key Activities This in-depth workshop focused on the Security Pillar of the AWS Well-Architected Framework. The session provided a structured approach to evaluating and securing cloud workloads, covering key areas such as:\nIdentity and Access Management (IAM) best practices. Data protection techniques for encryption at-rest and in-transit. Detective controls using AWS Config, CloudTrail, and Security Hub. Infrastructure protection and automated incident response. Key Takeaways and Outcomes Shared Responsibility Model: Gained a clear understanding of the division of security responsibilities between AWS and the customer. Defense in Depth: Learned to apply a multi-layered security approach to protect cloud resources comprehensively, from the network edge to individual data. Automated Security: Understood the importance of automating security checks and remediation to reduce human error and enable faster threat response. Proactive Security Posture: Acquired the skills to use AWS tools to proactively monitor and improve the security posture of cloud environments. Event 4 Event Name: AWS Cloud Mastery Series #2 - DevOps on AWS\nDate: November 17, 2025\nLocation: Bitexco Financial Tower, District 1, Ho Chi Minh City\nEvent Overview and Key Activities This full-day deep-dive session focused on implementing DevOps culture and practices on AWS. The workshop covered the entire CI/CD lifecycle, from source control to automated deployment, and explored modern technologies including:\nInfrastructure as Code (IaC) with AWS CloudFormation and CDK. Containerization with Docker, ECR, and ECS/EKS. Building automated CI/CD pipelines using the AWS Code service suite. Implementing observability with CloudWatch and AWS X-Ray for distributed tracing. Key Takeaways and Outcomes End-to-End Automation: Mastered the concept of building fully automated software release pipelines, minimizing manual intervention and increasing deployment frequency. IaC as Standard: Understood that managing infrastructure as code is essential for repeatability, consistency, and preventing configuration drift. Observability in Distributed Systems: Learned how to use AWS X-Ray to trace requests through microservices, providing critical insights for debugging and performance optimization. Measuring DevOps Success: Gained knowledge of key DORA metrics (Deployment Frequency, MTTR, etc.) to measure and improve team performance. "},{"uri":"https://masterltb.github.io/profile/4-eventparticipated/4.4-event4/","title":"AWS Cloud Mastery Series #2 - DevOps on AWS","tags":[],"description":"","content":"AWS Cloud Mastery Series #2 - DevOps on AWS - Date: November 17, 2025 (Full Day) - Location: Bitexco Financial Tower, District 1, Ho Chi Minh City\nEvent Overview This full-day deep-dive session focused on implementing DevOps culture, AWS Continuous Integration/Continuous Delivery (CI/CD) tools, and modernizing technologies like Infrastructure as Code (IaC) and Containerization.\nKey Objectives:\nDevelop DevOps Mindset: Grasp the culture, principles, and key performance metrics (DORA, MTTR, deployment frequency). Build CI/CD Pipelines: Master the use of AWS Code services (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) for automating the release process. Implement IaC: Practice deploying and managing infrastructure using AWS CloudFormation and AWS CDK. Application Modernization: Learn about containerization, image storage (ECR), and orchestration management (ECS/EKS). Improve Observability: Set up comprehensive monitoring using CloudWatch and AWS X-Ray for distributed tracing. Key Takeaways \u0026amp; Learnings Culture is Foundational: DevOps is a combination of culture, principles, and tools; DORA metrics are crucial for measuring team performance. End-to-End Automation: The entire process from source code (CodeCommit) to deployment (CodePipeline/CodeDeploy) must be automated, prioritizing safe deployment strategies like Blue/Green and Canary. IaC is Essential: Managing infrastructure as code increases repeatability, minimizes manual errors, and allows for easy drift detection in CloudFormation. Containers for Microservices: Utilizing Docker with AWS container management services (ECS, EKS, App Runner) is the standard model for deploying microservices architecture. Distributed Tracing: AWS X-Ray is vital for understanding the performance and bottlenecks in distributed systems, complementing traditional metrics and logs from CloudWatch. Application to Work Measure DORA: Begin measuring DORA metrics (Deployment Frequency, Lead Time for Changes, Mean Time to Recovery, Change Failure Rate) for current projects. Pipeline Transformation: Select one manual or semi-automated deployment process and fully transition it to an automated AWS CodePipeline with automated Build (CodeBuild) and Deployment (CodeDeploy) steps. Pilot CDK: Start piloting the use of AWS CDK to define and deploy a small service, leveraging familiar programming languages (e.g., Python/TypeScript). Integrate X-Ray: Apply AWS X-Ray to newly developed microservices to gather tracing data and analyze inter-component performance. Event Photos "},{"uri":"https://masterltb.github.io/profile/5-workshop/5.4-setup-lambda/","title":"Module 4: Setup Lambda","tags":[],"description":"","content":"Module 4: Create Lambda Functions Module Objectives Create 5 Lambda functions from scratch Configure IAM roles \u0026amp; permissions Set up environment variables Configure a Cognito post-confirmation trigger Test Lambda functions Set up monitoring \u0026amp; alarms Duration: 4-5 hours\nLambda Functions Overview The Lambda functions will handle specific events:\nFunction Region Runtime Purpose Memory Timeout CognitoPostConfirmationTrigger us-east-1 nodejs20.x Create a user profile when a user signs up 256 MB 30s AdminManageCoachesFunction ap-southeast-1 nodejs20.x Manage coaches (CRUD operations) 512 MB 30s image-upload-lambda ap-southeast-1 nodejs20.x Handle image uploads to S3 256 MB 60s leaflungs-websocket-authorizer ap-southeast-1 nodejs20.x Authorize WebSocket connections 256 MB 30s PaymentFunction ap-southeast-1 nodejs24.x Process payments 512 MB 60s Part 1: Create an IAM Role for Lambda Functions Step 1: Access the IAM Console Log in to the AWS Console with your IAM user Search for \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; from the services list Left menu: Click \u0026ldquo;Roles\u0026rdquo; Click \u0026ldquo;Create role\u0026rdquo; Step 2: Configure the Trust Relationship Trusted entity type: Select \u0026ldquo;AWS service\u0026rdquo; Service or use case: Search for and click \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Step 3: Add Permissions Search for and check the following policies: ‚úÖ AWSLambdaVPCAccessExecutionRole (for EC2 database access) ‚úÖ AWSLambdaBasicExecutionRole (for CloudWatch logs) ‚úÖ AmazonS3FullAccess (for the image upload function) ‚úÖ SecretsManagerReadSecret (for database credentials) Click \u0026ldquo;Next\u0026rdquo; Step 4: Review \u0026amp; Create Role name: smoking-cessation-lambda-role Description: Lambda execution role for the smoking cessation platform Click \u0026ldquo;Create role\u0026rdquo; ‚è≥ Wait for the role to be created\nStep 5: Note the Role ARN Click on the newly created role: smoking-cessation-lambda-role Copy the Role ARN: The format is arn:aws:iam::014097726842:role/smoking-cessation-lambda-role Save it for use in the following modules Part 2: Create the Cognito Post-Confirmation Trigger (us-east-1) Step 1: Access the Lambda Console Log in to the AWS Console Search for \u0026ldquo;Lambda\u0026rdquo; Click the \u0026ldquo;Lambda\u0026rdquo; service Select the region: us-east-1 (must be the same as Cognito) Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Function Basics Function name: smoking-cessation-cognito-post-confirmation Runtime: nodejs20.x Execution role: Select \u0026ldquo;Use an existing role\u0026rdquo; Existing role: smoking-cessation-lambda-role (from Part 1) Click \u0026ldquo;Create function\u0026rdquo; ‚è≥ Wait for the function to be created (about 1-2 minutes)\nStep 3: Configure General Settings Scroll down to \u0026ldquo;General configuration\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Memory: 256 MB (default) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Environment Variables Scroll down to \u0026ldquo;Environment variables\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Add the following variables: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will be set via Secrets Manager later) PG_DATABASE = smoking_cessation PG_PORT = 5432 COGNITO_USER_POOL_ID = (get from Module 3) Click \u0026ldquo;Save\u0026rdquo; Step 5: Add Placeholder Code Click the \u0026ldquo;Code\u0026rdquo; tab In the code editor, replace everything with: exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Cognito post-confirmation event:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.request.userAttributes.sub; const email = event.request.userAttributes.email; const name = event.request.userAttributes.name; console.log(`Creating user profile for ${email}`); // TODO: Implement database connection to PostgreSQL // Create user record in users table // Initialize coaching session if needed return event; } catch (error) { console.error(\u0026#39;Error in post-confirmation:\u0026#39;, error); throw error; } }; Click \u0026ldquo;Deploy\u0026rdquo; Step 6: Add the Cognito Trigger (Later) Note: After deploying the code, you will configure the Cognito trigger in Part 8.\nPart 3: Create the Admin Manage Coaches Function (ap-southeast-1) Step 1: Switch to the ap-southeast-1 Region Top left: Click the region dropdown Select ap-southeast-1 Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure the Function Function name: smoking-cessation-admin-manage-coaches Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; ‚è≥ Wait for the function to be created\nStep 3: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (for database operations) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will be set via Secrets Manager) PG_DATABASE = smoking_cessation API_REGION = ap-southeast-1 Click \u0026ldquo;Save\u0026rdquo; Step 5: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Admin coaches request:\u0026#39;, JSON.stringify(event, null, 2)); try { const httpMethod = event.httpMethod; const path = event.path; const body = event.body ? JSON.parse(event.body) : {}; console.log(`${httpMethod} ${path}`); // TODO: Implement database operations // GET /admin/coaches - List all coaches // POST /admin/coaches - Create a new coach // PUT /admin/coaches/{id} - Update a coach // DELETE /admin/coaches/{id} - Delete a coach // Include RBAC check (admin only) return { statusCode: 200, body: JSON.stringify({ message: \u0026#39;Coaches function placeholder\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPart 4: Create the Image Upload Lambda (ap-southeast-1) Step 1: Create the Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-image-upload Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;General configuration\u0026rdquo; Memory: 256 MB Timeout: 60 seconds (because file uploads can take time) Click \u0026ldquo;Save\u0026rdquo; Step 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;Environment variables\u0026rdquo; Add: S3_BUCKET = smoking-cessation-images S3_REGION = ap-southeast-1 MAX_FILE_SIZE = 10485760 Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Image upload request:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.requestContext.authorizer.claims.sub; const fileBuffer = Buffer.from(event.body, \u0026#39;base64\u0026#39;); const fileName = event.headers[\u0026#39;x-filename\u0026#39;] || `image-${Date.now()}.jpg`; console.log(`Uploading ${fileName} for user ${userId}`); // TODO: Implement S3 upload // Validate file size (max 10MB) // Upload to S3 with a user prefix // Generate a pre-signed URL // Store a reference in the database const s3Url = `https://${process.env.S3_BUCKET}.s3.${process.env.S3_REGION}.amazonaws.com/${userId}/${fileName}`; return { statusCode: 200, body: JSON.stringify({ url: s3Url }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPart 5: Create the WebSocket Authorizer Lambda (ap-southeast-1) Step 1: Create the Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-websocket-authorizer Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;General configuration\u0026rdquo; Memory: 256 MB Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Step 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;Environment variables\u0026rdquo; Add: COGNITO_USER_POOL_ID = (from Module 3) COGNITO_CLIENT_ID = (from Module 3) JWT_SECRET = (will be set via Secrets Manager) Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;WebSocket authorization event:\u0026#39;, JSON.stringify(event, null, 2)); try { const token = event.authorizationToken; if (!token) { throw new Error(\u0026#39;No authorization token\u0026#39;); } console.log(\u0026#39;Validating WebSocket token\u0026#39;); // TODO: Implement JWT token validation // Validate the token signature // Check the token expiration // Extract the user ID from the token // Placeholder authorization response return { principalId: \u0026#39;user-id-placeholder\u0026#39;, policyDocument: { Version: \u0026#39;2012-10-17\u0026#39;, Statement: [ { Action: \u0026#39;execute-api:Invoke\u0026#39;, Effect: \u0026#39;Allow\u0026#39;, Resource: event.methodArn } ] } }; } catch (error) { console.error(\u0026#39;Authorization failed:\u0026#39;, error); throw new Error(\u0026#39;Unauthorized\u0026#39;); } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPart 6: Create the Payment Function (ap-southeast-1) Step 1: Create the Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-payment Runtime: nodejs24.x (latest version) Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (payment processing needs resources) Timeout: 60 seconds Click \u0026ldquo;Save\u0026rdquo; Step 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will be set via Secrets Manager) PG_DATABASE = smoking_cessation STRIPE_API_KEY = (will be set via Secrets Manager) STRIPE_WEBHOOK_SECRET = (will be set via Secrets Manager) PAYMENT_TABLE = payments Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Payment event:\u0026#39;, JSON.stringify(event, null, 2)); try { const { userId, amount, paymentMethod, description } = JSON.parse(event.body); console.log(`Processing payment for user ${userId}: $${amount}`); // TODO: Implement payment processing // Validate the amount // Process the payment via Stripe/Payment gateway // Store the payment record in the database // Send a confirmation email // Handle webhooks return { statusCode: 200, body: JSON.stringify({ success: true, transactionId: `txn-${Date.now()}`, message: \u0026#39;Payment processed successfully\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Payment error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPart 7: Create a Secret in Secrets Manager for Database Credentials Step 1: Access Secrets Manager Search for \u0026ldquo;Secrets Manager\u0026rdquo; Click the service Click \u0026ldquo;Store a new secret\u0026rdquo; Step 2: Store the Database Password Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: db-password Value: \u0026lt;your-postgres-password\u0026gt; Click \u0026ldquo;Next\u0026rdquo; Secret name: smoking-cessation/db-password Click \u0026ldquo;Store secret\u0026rdquo; Step 3: Store Payment Credentials (Optional) Click \u0026ldquo;Store a new secret\u0026rdquo; Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: stripe-api-key Value: \u0026lt;your-stripe-key\u0026gt; Secret name: smoking-cessation/stripe-api-key Click \u0026ldquo;Store secret\u0026rdquo; Step 4: Update the Lambda IAM Role Lambda needs permission to read secrets:\nGo to the IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; ‚Üí \u0026ldquo;Create inline policy\u0026rdquo; Select the \u0026ldquo;JSON\u0026rdquo; tab Paste: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:secretsmanager:*:*:secret:smoking-cessation/*\u0026#34; ] } ] } Click \u0026ldquo;Review policy\u0026rdquo; Policy name: lambda-secrets-access Click \u0026ldquo;Create policy\u0026rdquo; Part 8: Configure the Cognito Post-Confirmation Trigger Step 1: Go to the Cognito User Pool Switch the region to us-east-1 Search for \u0026ldquo;Cognito\u0026rdquo; Click the Cognito service Click \u0026ldquo;User pools\u0026rdquo; Click on your user pool: smoking-cessation-users (created in Module 3) Step 2: Add the Lambda Trigger Left menu: Click \u0026ldquo;User lifecycle\u0026rdquo; Click \u0026ldquo;Post confirmation\u0026rdquo; Click \u0026ldquo;Add Lambda trigger\u0026rdquo; Lambda function: smoking-cessation-cognito-post-confirmation Click \u0026ldquo;Save\u0026rdquo; Step 3: Verify the Trigger Refresh the page Verify the trigger shows: Trigger: Post confirmation Function: smoking-cessation-cognito-post-confirmation (us-east-1) Status: Active Part 9: Grant Cognito Permission to Invoke the Lambda Cognito needs permission to call the Lambda function:\nStep 1: Add a Resource-Based Policy Switch to the us-east-1 region Go to the Lambda console Click the function: smoking-cessation-cognito-post-confirmation Scroll down to \u0026ldquo;Resource-based policy statements\u0026rdquo; Click \u0026ldquo;Add permissions\u0026rdquo; Statement ID: AllowCognitoInvoke Principal: cognito-idp.amazonaws.com Action: lambda:InvokeFunction Source account: Source ARN: arn:aws:cognito-idp:us-east-1:\u0026lt;account-id\u0026gt;:userpool/\u0026lt;user-pool-id\u0026gt; Click \u0026ldquo;Save\u0026rdquo; Part 10: Test the Lambda Functions Step 1: Test the Cognito Post-Confirmation Trigger Go to the Lambda console (us-east-1) Click the function: smoking-cessation-cognito-post-confirmation Click the \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;userAttributes\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;12345678-1234-1234-1234-123456789012\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Test User\u0026#34; } }, \u0026#34;response\u0026#34;: {} } Click \u0026ldquo;Test\u0026rdquo; Verify: ‚úÖ Execution result: Succeeded ‚úÖ CloudWatch logs show the console.log output Step 2: Test the Admin Coaches Function Switch to ap-southeast-1 Click the function: smoking-cessation-admin-manage-coaches Click the \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/admin/coaches\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer test-token\u0026#34; }, \u0026#34;body\u0026#34;: null } Click \u0026ldquo;Test\u0026rdquo; Verify a status code of 200 in the response Step 3: Test the Image Upload Function Click the function: smoking-cessation-image-upload Click the \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/upload\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;x-filename\u0026#34;: \u0026#34;test-image.jpg\u0026#34; }, \u0026#34;body\u0026#34;: \u0026#34;base64-encoded-image-data\u0026#34;, \u0026#34;requestContext\u0026#34;: { \u0026#34;authorizer\u0026#34;: { \u0026#34;claims\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;user-123\u0026#34; } } } } Click \u0026ldquo;Test\u0026rdquo; Verify the response contains an S3 URL Step 4: View CloudWatch Logs Click the \u0026ldquo;Monitor\u0026rdquo; tab of any function Click \u0026ldquo;View logs in CloudWatch\u0026rdquo; Select the most recent log stream Verify the logs show: The input event console.log statements Execution time Part 11: Create CloudWatch Alarms Step 1: Create an Error Alarm Search for \u0026ldquo;CloudWatch\u0026rdquo; Click the \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Alarms\u0026rdquo; ‚Üí \u0026ldquo;All alarms\u0026rdquo; Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda Dimension: Function name Statistic: Sum Function: smoking-cessation-admin-manage-coaches Metric: Errors Threshold: \u0026gt; 5 in 1 minute Click \u0026ldquo;Next\u0026rdquo; Action: Create an SNS topic Topic name: smoking-cessation-lambda-errors Email endpoint: your-email@example.com Click \u0026ldquo;Create alarm\u0026rdquo; Check your email to verify the SNS subscription Step 2: Create a Duration Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda ‚Üí Durations Function: smoking-cessation-admin-manage-coaches Statistic: Average Threshold: \u0026gt; 20 seconds (warning if approaching the 30s timeout) Click \u0026ldquo;Next\u0026rdquo; Action: Use the existing SNS topic smoking-cessation-lambda-errors Click \u0026ldquo;Create alarm\u0026rdquo; Step 3: Create a Throttle Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Lambda ‚Üí Throttles Function: All functions Threshold: \u0026gt; 0 Click \u0026ldquo;Next\u0026rdquo; Action: Notify via SNS Click \u0026ldquo;Create alarm\u0026rdquo; Part 12: Enable X-Ray Tracing (Optional) Step 1: Update the IAM Role Go to the IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; ‚Üí \u0026ldquo;Attach policies directly\u0026rdquo; Search for: AWSXRayWriteAccess Check ‚úÖ Click \u0026ldquo;Attach policies\u0026rdquo; Step 2: Enable X-Ray on the Functions For each Lambda function:\nClick the function Click the \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;Monitoring and operations tools\u0026rdquo; Under \u0026ldquo;X-Ray\u0026rdquo;: Check ‚úÖ \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Environment Variables Summary Cognito Post-Confirmation Function (us-east-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation PG_PORT=5432 COGNITO_USER_POOL_ID=(from Module 3) Admin Coaches \u0026amp; Payment Functions (ap-southeast-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation API_REGION=ap-southeast-1 STRIPE_API_KEY=(from Secrets Manager) STRIPE_WEBHOOK_SECRET=(from Secrets Manager) Image Upload Function (ap-southeast-1) S3_BUCKET=smoking-cessation-images S3_REGION=ap-southeast-1 MAX_FILE_SIZE=10485760 WebSocket Authorizer (ap-southeast-1) COGNITO_USER_POOL_ID=(from Module 3) COGNITO_CLIENT_ID=(from Module 3) JWT_SECRET=(from Secrets Manager) Checklist IAM role smoking-cessation-lambda-role created Cognito Post-Confirmation function created (us-east-1) Admin Coaches function created (ap-southeast-1) Image Upload function created (ap-southeast-1) WebSocket Authorizer function created (ap-southeast-1) Payment function created (ap-southeast-1) All functions have the correct runtime \u0026amp; memory Environment variables configured for all functions Secrets Manager is set up (db-password, stripe-api-key) Cognito trigger is configured (post-confirmation) Lambda resource-based policy added for Cognito All functions tested successfully CloudWatch alarms created (errors, duration, throttles) X-Ray tracing enabled (optional) CloudWatch logs reviewed Ready for Module 5 (Setup API Gateway) Troubleshooting Function Execution Failed Issue: \u0026ldquo;An error occurred while getting the logs from CloudWatch\u0026rdquo;\nSolution:\nCheck that the IAM role has AWSLambdaBasicExecutionRole Wait 1-2 minutes for the logs to appear Check the function code for syntax errors Cognito Trigger Not Working Issue: \u0026ldquo;User created but the Lambda function didn\u0026rsquo;t execute\u0026rdquo;\nSolution:\nVerify the trigger is enabled in the Cognito console Check that the Lambda resource-based policy exists Review the CloudWatch logs for errors Check the IAM role permissions Timeout Errors Issue: \u0026ldquo;Task timed out after 30 seconds\u0026rdquo;\nSolution:\nIncrease the timeout to 60 seconds Check database connectivity (VPC configuration in Module 8) Add console logs to identify slow operations Consider increasing the memory (also increases CPU) Permission Denied Issue: \u0026ldquo;User is not authorized to perform: secretsmanager:GetSecretValue\u0026rdquo;\nSolution:\nAdd the Secrets Manager policy to the Lambda role Verify the policy resource ARN matches the secret name Check that the secret exists in the correct region Cold Start Issues Issue: \u0026ldquo;High duration on the first invocation\u0026rdquo;\nSolution:\nIncrease the memory allocation (256 ‚Üí 512 MB) Consider provisioned concurrency for frequently used functions Optimize code dependencies Next Steps Implement the actual code for each Lambda function (provided separately) Set up database connections to the EC2 instances (Module 6) Create API Gateway routes (Module 5) Test the end-to-end flow Optimize based on CloudWatch metrics What You Will Achieve After Module 4, you will have:\n‚úÖ 5 Lambda functions created and deployed ‚úÖ An IAM role with the appropriate permissions ‚úÖ Environment variables configured ‚úÖ Secrets Manager set up for sensitive data ‚úÖ A Cognito post-confirmation trigger configured ‚úÖ Resource-based policies for Cognito invocation ‚úÖ CloudWatch alarms set up ‚úÖ X-Ray tracing enabled (optional) ‚úÖ All functions tested and verified ‚úÖ Ready for Module 5 (Create API Gateway) "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.4-week4/","title":"Worklog Week 4","tags":[],"description":"","content":"Week 4 Objectives Understand AWS Support tiers and when to use each one. Learn VPC fundamentals and network design patterns. Set up a secure network infrastructure with Security Groups and NACLs. Practice hands-on VPC creation, subnet configuration, and traffic management. Tasks for this week Day Task Start Date Completion Date Reference 2 - Reviewed AWS Support plans (Basic, Developer, Business, Enterprise).\n- Understood SLA, response times, and support channels for each tier. 30/09/2025 30/09/2025 https://aws.amazon.com/support/plans/ 3 - Designed VPC with CIDR block 10.0.0.0/16.\n- Created public and private subnets across multiple AZs. 01/10/2025 01/10/2025 https://console.aws.amazon.com/vpc/ 4 - Configured Internet Gateway (IGW) for public subnet access.\n- Set up NAT Gateway in public subnet for private subnet internet access.\n- Created and configured route tables for traffic routing. 02/10/2025 02/10/2025 https://console.aws.amazon.com/vpc/ 5 - Created security groups with inbound/outbound rules.\n- Implemented Network ACLs for stateless filtering.\n- Tested connectivity between public and private subnets. 03/10/2025 03/10/2025 https://console.aws.amazon.com/vpc/ 6 - Enabled VPC Flow Logs for network traffic monitoring.\n- Reviewed security best practices and compliance requirements. 04/10/2025 04/10/2025 https://console.aws.amazon.com/vpc/ Week 4 Outcomes Successfully designed and implemented multi-AZ VPC infrastructure. Configured internet and NAT gateways for controlled connectivity. Implemented tiered security with Security Groups and Network ACLs. Enabled network visibility with VPC Flow Logs. Understood AWS Support ecosystem and selected appropriate support plan. Key Learnings:\nVPC design should include multiple AZs for high availability. Public/Private subnet separation is critical for security. Security Groups are stateful; Network ACLs are stateless. Regular security group reviews prevent overly permissive rules. "},{"uri":"https://masterltb.github.io/profile/5-workshop/","title":"Workshop","tags":[],"description":"","content":"BUILDING THE SMOKING-CESSATION SYSTEM ON AWS (END-TO-END) This workshop provides a full, practical, step-by-step guide to building a complete AWS-based system for the Smoking-Cessation Application, including Backend (Lambda + API Gateway), Databases (PostgreSQL + MongoDB), Authentication (Cognito), Infrastructure (VPC, EC2, Security), Frontend Hosting (S3 + CloudFront), Monitoring (CloudWatch), and final Cleanup.\nEach module corresponds to a major architectural component of the system.\nüéØ Workshop Objectives By completing all modules, you will understand how to:\nBuild a microservices-based system on AWS Implement user authentication with Cognito Create and operate Lambda serverless functions Publish REST APIs through API Gateway Deploy databases on EC2 (PostgreSQL + MongoDB) Configure VPC, subnets, NAT Gateway, routing, and security Host a frontend application using S3 and CloudFront Monitor logs, metrics, errors, and costs using CloudWatch Optimize cost and clean up unused infrastructure üß© System Architecture Overview This workshop will guide you through building a full production-grade system consisting of:\n8 Lambda functions 2 REST APIs (User API \u0026amp; Chat API) PostgreSQL + MongoDB databases on EC2 S3 + CloudFront for frontend hosting Cognito User Pool for authentication Custom VPC with public/private subnets, NAT Gateway, and NLB CloudWatch Dashboards \u0026amp; Alarms Secrets Manager for secure credential storage üìö Workshop Structure (10 Modules) Each module contains detailed step-by-step instructions with screenshots.\n1Ô∏è‚É£ Introduction Overview of the project goals, AWS services used, and system architecture.\n2Ô∏è‚É£ Prerequisites Prepare your AWS environment, IAM user, VS Code, SSH keys, and project directory structure.\n3Ô∏è‚É£ Cognito Setup Create User Pool, App Client, password policy, verification email, and post-confirmation Lambda trigger.\n4Ô∏è‚É£ Lambda Setup Create all backend Lambda functions, assign IAM roles, configure environment variables, and connect to Secrets Manager.\n5Ô∏è‚É£ API Gateway Setup Create two REST APIs, integrate with Lambda, configure authorization, enable CORS, set request validation and throttling.\n6Ô∏è‚É£ RDS \u0026amp; Database Setup (EC2) Create two EC2 database servers, install PostgreSQL \u0026amp; MongoDB, create database users, configure instances for production.\n7Ô∏è‚É£ S3 + CloudFront Setup Configure S3 buckets, static website hosting, OAC, CloudFront distribution, HTTPS, caching, and invalidation.\n8Ô∏è‚É£ VPC \u0026amp; Security Setup Create a custom VPC, subnets, routing tables, NAT Gateway, Internet Gateway, Security Groups, and Network Load Balancer.\n9Ô∏è‚É£ Monitoring \u0026amp; Logging Set up CloudWatch dashboards, logs, alerts, SNS notifications, CloudTrail auditing, and X-Ray tracing.\nüîü Cleanup \u0026amp; Cost Optimization Analyze costs, remove unused resources, back up databases, archive S3 objects, and clean up all AWS infrastructure safely.\n‚úî Final Notes This workshop equips you with the knowledge to build a complete, secure, scalable, and cost-efficient AWS architecture from scratch.\nYou may now continue with Module 5.1 ‚Äî Introduction.\n"},{"uri":"https://masterltb.github.io/profile/5-workshop/5.5-setup-api-gateway/","title":"5.5 Setup API Gateway","tags":[],"description":"","content":"Module 5: Create API Gateway REST APIs Module Objectives Create 2 REST APIs from scratch Create resources \u0026amp; methods Integrate with Lambda functions Configure authentication \u0026amp; authorization Set up CORS \u0026amp; rate limiting Deploy \u0026amp; test the APIs Duration: 3-4 hours\nAPI Gateway Overview 2 REST APIs will be created:\nAPI Name Region Purpose Resources Methods smoking-cessation-user-api ap-southeast-1 User management, Admin operations /admin/coaches, /api/user-info, /upload GET, POST, PUT, DELETE smoking-cessation-chat-api ap-southeast-1 Chat \u0026amp; WebSocket /chat/rooms, /chat/messages, /ws GET, POST, WebSocket Part 1: Create the First REST API (User Management) Step 1: Access the API Gateway Console Log in to the AWS Console Search for \u0026ldquo;API Gateway\u0026rdquo; Click the \u0026ldquo;API Gateway\u0026rdquo; service Select the region: ap-southeast-1 Click \u0026ldquo;Create API\u0026rdquo; Step 2: Choose the API Type Choose \u0026ldquo;REST API\u0026rdquo; Click \u0026ldquo;Build\u0026rdquo; Step 3: Configure API Details API name: smoking-cessation-user-api Description: REST API for user management and admin operations Endpoint type: Regional Click \u0026ldquo;Create API\u0026rdquo; ‚è≥ Wait for the API to be created (about 1-2 minutes)\nStep 4: View the API Dashboard After the API is created, you will see:\nThe resources tree (currently only the \u0026ldquo;/\u0026rdquo; root) The methods available for the root Integration settings Part 2: Create the /admin Resource \u0026amp; /admin/coaches Sub-resource Step 1: Create the /admin Resource Click the root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: admin Resource path: /admin ‚úÖ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 2: Create the /admin/coaches Sub-resource Click on the /admin resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: coaches Resource path: coaches (automatically becomes /admin/coaches) ‚úÖ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 3: Create the GET Method for /admin/coaches Click on the /admin/coaches resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;GET\u0026rdquo; Click the checkmark to confirm Step 4: Configure the GET Method Integration Integration type: Lambda Function Lambda Region: ap-southeast-1 Lambda Function: smoking-cessation-admin-manage-coaches ‚úÖ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Confirm the permission popup Step 5: Create the POST Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;POST\u0026rdquo; Same integration as GET: Integration type: Lambda Function Lambda Function: smoking-cessation-admin-manage-coaches ‚úÖ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Step 6: Create the PUT Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;PUT\u0026rdquo; Same Lambda integration Click \u0026ldquo;Save\u0026rdquo; Step 7: Create the DELETE Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;DELETE\u0026rdquo; Same Lambda integration Click \u0026ldquo;Save\u0026rdquo; Result: /admin/coaches now has GET, POST, PUT, and DELETE methods.\nPart 3: Create the /api/user-info Resource \u0026amp; Sub-resources Step 1: Create the /api Resource Click the root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: api Resource path: /api ‚úÖ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 2: Create the /api/user-info Resource Click on the /api resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: user-info Resource path: user-info ‚úÖ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 3: Create Methods for /api/user-info Create GET, POST, PUT, and DELETE methods (same as /admin/coaches):\nFor each method: Click \u0026ldquo;Create Method\u0026rdquo; Select the method type Integration: smoking-cessation-admin-manage-coaches Lambda ‚úÖ Lambda Proxy integration Save Step 4: Create the /{id} Resource (Path Parameter) Click on /api/user-info Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: {id} Resource path: {id} Click \u0026ldquo;Create Resource\u0026rdquo; Step 5: Create the GET Method for /api/user-info/{id} Click on the /{id} resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;GET\u0026rdquo; Integration: smoking-cessation-admin-manage-coaches Lambda Save Step 6: Create the /by-user-id Resource Click on /api/user-info (parent) Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: by-user-id Resource path: by-user-id Click \u0026ldquo;Create Resource\u0026rdquo; Add a GET method with Lambda integration Step 7: Create the /empty Resource Click on /api/user-info (parent) Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: empty Resource path: empty Click \u0026ldquo;Create Resource\u0026rdquo; Add a GET method with Lambda integration Result: The /api/user-info resource tree is created with all sub-resources.\nPart 4: Create the /upload Resource Step 1: Create the /upload Resource Click the root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: upload Resource path: /upload ‚úÖ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 2: Create the POST Method Click on the /upload resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;POST\u0026rdquo; Integration type: Lambda Function Lambda Function: smoking-cessation-image-upload ‚úÖ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Part 5: Configure Authentication \u0026amp; Authorization Step 1: Create a Cognito Authorizer Left menu: Click \u0026ldquo;Authorizers\u0026rdquo; Click \u0026ldquo;Create Authorizer\u0026rdquo; Authorizer name: cognito-user-pool-authorizer Type: Cognito Cognito User Pool: smoking-cessation-users (created in Module 3) Token source: Authorization Click \u0026ldquo;Create authorizer\u0026rdquo; Step 2: Test the Authorizer (Optional) Token: (enter a valid JWT token from your Cognito user pool) Click \u0026ldquo;Test authorizer\u0026rdquo; Verify the response shows the user claims Step 3: Add Authorization to Methods For critical endpoints (e.g., /admin/coaches):\nClick on the /admin/coaches resource Click the \u0026ldquo;GET\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Authorization: Select cognito-user-pool-authorizer Click the checkmark to save Repeat for the POST, PUT, and DELETE methods Part 6: Set up Request Validators Step 1: Create a Request Validator Left menu: Click \u0026ldquo;Request Validators\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: validate-body-and-params ‚úÖ \u0026ldquo;Validate request body\u0026rdquo; ‚úÖ \u0026ldquo;Validate query string parameters and headers\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Step 2: Apply the Validator to POST Methods Click on /admin/coaches ‚Üí \u0026ldquo;POST\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Request Validator: Select validate-body-and-params Save Part 7: Set up CORS Step 1: Enable CORS for All Resources Click the root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Enable CORS\u0026rdquo; Review the default settings Click \u0026ldquo;Enable CORS and replace existing CORS headers\u0026rdquo; Step 2: Configure CORS Headers The CORS headers are automatically configured:\nAccess-Control-Allow-Headers: Content-Type, X-Amz-Date, Authorization, X-Api-Key, X-Amz-Security-Token Access-Control-Allow-Methods: GET, POST, PUT, DELETE, OPTIONS Access-Control-Allow-Origin: * (for dev, restrict in production) Part 8: Create the Second API - Chat API (WebSocket) Step 1: Create a WebSocket API Click \u0026ldquo;Create API\u0026rdquo; Select \u0026ldquo;WebSocket API\u0026rdquo; Click \u0026ldquo;Build\u0026rdquo; Step 2: Configure the WebSocket API API name: smoking-cessation-chat-api Description: WebSocket API for chat functionality Route Selection Expression: $request.body.action Click \u0026ldquo;Create API\u0026rdquo; ‚è≥ Wait for the API to be created\nStep 3: Create Routes Create the default routes:\n$default route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $connect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $disconnect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer Part 9: Deploy the APIs Step 1: Create a Deployment Stage For the User API:\nClick \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Stage description: Production environment Click \u0026ldquo;Deploy\u0026rdquo; Step 2: Note the API Endpoint After deployment, you\u0026rsquo;ll see:\nInvoke URL: https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod Save this URL Step 3: Deploy the Chat API Go to the Chat API Click \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Click \u0026ldquo;Deploy\u0026rdquo; Note the WebSocket Invoke URL Part 10: Test the REST API Endpoints Step 1: Test GET /admin/coaches In the API Gateway console:\nSelect the User API Click /admin/coaches ‚Üí \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: GET\nPath: /admin/coaches\nHeaders:\nAuthorization: Bearer {your-cognito-token} Click \u0026ldquo;Test\u0026rdquo;\nExpected result:\nStatus: 200 Body: JSON response from Lambda Step 2: Test POST /admin/coaches Click /admin/coaches ‚Üí \u0026ldquo;POST\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: POST Headers: Authorization: Bearer {your-cognito-token} Content-Type: application/json Body: { \u0026#34;name\u0026#34;: \u0026#34;Coach Name\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;coach@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; } Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with the created coach data Step 3: Test the /upload Endpoint Click /upload ‚Üí \u0026ldquo;POST\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: POST Headers: Authorization: Bearer {your-cognito-token} Content-Type: multipart/form-data Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with an S3 URL Step 4: Test with cURL (Optional) # Get a list of coaches curl -X GET \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; # Create a new coach curl -X POST \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Coach John\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; }\u0026#39; Part 11: Set up CloudWatch Logging Step 1: Enable Full Request/Response Logging Click \u0026ldquo;Settings\u0026rdquo; (left menu) CloudWatch log role ARN: Click \u0026ldquo;Edit\u0026rdquo; Select or create an IAM role for API Gateway logging The role should have logs:CreateLogGroup, logs:CreateLogStream, and logs:PutLogEvents permissions Click \u0026ldquo;Save changes\u0026rdquo; Step 2: Set the Log Level Go to \u0026ldquo;Stages\u0026rdquo; ‚Üí \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Logs\u0026rdquo; ‚úÖ \u0026ldquo;Enable CloudWatch Logs\u0026rdquo; Log level: INFO (or DEBUG for troubleshooting) Data trace enabled: ‚úÖ Full request/response data: ‚úÖ Click \u0026ldquo;Save changes\u0026rdquo; Step 3: View the Logs Search for \u0026ldquo;CloudWatch\u0026rdquo; Click the \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Logs\u0026rdquo; ‚Üí \u0026ldquo;Log groups\u0026rdquo; Search for API-Gateway-Execution-Logs_{api-id} View recent requests Part 12: Set up Rate Limiting (Usage Plans) Step 1: Create an API Key Left menu: Click \u0026ldquo;API Keys\u0026rdquo; Click \u0026ldquo;Create API Key\u0026rdquo; Name: mobile-app-key Description: API key for the mobile app Click \u0026ldquo;Create API Key\u0026rdquo; Copy and save the key Step 2: Create a Usage Plan Left menu: Click \u0026ldquo;Usage Plans\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: free-tier-plan Description: Free tier plan with rate limiting Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Throttling \u0026amp; Quota Rate: 100 requests per second Burst: 200 requests Quota: 1,000,000 requests per month Click \u0026ldquo;Next\u0026rdquo; Step 4: Associate the API with the Plan Associated API Stages: Select the User API Select the stage: prod Click \u0026ldquo;Next\u0026rdquo; Step 5: Associate the API Key with the Plan API Keys: Search for and select mobile-app-key Click \u0026ldquo;Finish\u0026rdquo; Part 13: Set up a Resource-Based Policy (Optional) To restrict API access to specific IAM users/roles:\nStep 1: Add a Resource Policy Left menu: Click \u0026ldquo;Resource Policy\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste the policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;execute-api:Invoke\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;execute-api:/*\u0026#34; } ] } Click \u0026ldquo;Save\u0026rdquo; Part 14: Enable API Caching (Optional) Step 1: Enable the Cache for GET Endpoints Go to the stage: \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Settings\u0026rdquo; Cache cluster enabled: ‚úÖ Cache cluster size: 0.5 (smallest) Click \u0026ldquo;Save changes\u0026rdquo; Step 2: Configure the Cache per Method Click on /admin/coaches ‚Üí \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Integration Response\u0026rdquo; Expand the \u0026ldquo;200\u0026rdquo; response Cache settings: ‚úÖ \u0026ldquo;Enable method caching\u0026rdquo; Cache time to live (TTL): 300 seconds (5 minutes) Click the checkmark Environment Variables Summary Save these URLs after API deployment:\n# User Management API USER_API_ENDPOINT=https://{api-id-1}.execute-api.ap-southeast-1.amazonaws.com/prod USER_API_ID={api-id-1} # Chat API (WebSocket) CHAT_API_ENDPOINT=wss://{api-id-2}.execute-api.ap-southeast-1.amazonaws.com/prod CHAT_API_ID={api-id-2} # Authorizer COGNITO_AUTHORIZER_ID=cognito-user-pool-authorizer # Rate Limiting API_KEY={your-api-key} Checklist User API (smoking-cessation-user-api) created /admin/coaches resource with GET, POST, PUT, and DELETE methods created /api/user-info resource with sub-resources created /upload resource with a POST method created Chat API (smoking-cessation-chat-api) created Cognito authorizer configured CORS enabled for all resources Request validators configured Both APIs deployed to the prod stage CloudWatch logging enabled Rate limiting with Usage Plans configured All endpoints tested successfully API endpoints saved to environment variables Ready for Module 6 (Create EC2 Instances \u0026amp; Databases) Troubleshooting CORS Errors in the Browser Issue: \u0026ldquo;Access to XMLHttpRequest blocked by CORS policy\u0026rdquo;\nSolution:\nVerify that CORS is enabled for the resource Check the Access-Control-Allow-Origin header For development, use the * wildcard For production, restrict to a specific domain 403 Unauthorized Errors Issue: \u0026ldquo;User is not authorized to perform: execute-api:Invoke\u0026rdquo;\nSolution:\nVerify the JWT token is valid Check that the authorizer is configured on the method Verify the user has the required role in Cognito Review the API resource policy Lambda Function Not Found Issue: \u0026ldquo;Invalid Lambda function ARN specified\u0026rdquo;\nSolution:\nVerify the Lambda function exists in the same region Check the Lambda function name spelling Verify the IAM role has Lambda invoke permissions Check the CloudWatch logs for integration errors Rate Limiting Not Working Issue: \u0026ldquo;Requests are not being throttled according to the plan\u0026rdquo;\nSolution:\nVerify the API key is passed in the request Check that the Usage Plan is associated with the stage Verify the API key is associated with the Usage Plan Wait for throttling to take effect (may take a few minutes) High Latency Issue: \u0026ldquo;API requests are taking too long\u0026rdquo;\nSolution:\nEnable caching for GET requests Increase the Lambda memory (Module 4) Check the database connection from Lambda (Module 6) Monitor CloudWatch metrics Next Steps Implement API Gateway request/response transformations (optional) Set up a WAF (Web Application Firewall) for security (optional) Configure CloudFront for API caching (Module 7) Set up API documentation (optional) Test the end-to-end flow with the frontend application What You Will Achieve After Module 5, you will have:\n‚úÖ 2 REST APIs created (User API \u0026amp; Chat API) ‚úÖ All resources \u0026amp; methods configured ‚úÖ Lambda integrations set up ‚úÖ Cognito authorization configured ‚úÖ CORS enabled for all endpoints ‚úÖ Request validators configured ‚úÖ Both APIs deployed to the prod stage ‚úÖ CloudWatch logging enabled ‚úÖ Rate limiting configured ‚úÖ All endpoints tested \u0026amp; verified ‚úÖ API endpoints documented ‚úÖ Ready for Module 6 (Create EC2 Instances \u0026amp; Databases) "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.5-week5/","title":"Worklog Week 5","tags":[],"description":"","content":"Week 5 Objectives Launch and manage EC2 instances. Create custom AMI for reusable deployments. Deploy applications on EC2. Understand EC2 access recovery and management. Tasks for this week Day Task Start Date Completion Date Reference 2 - Launched EC2 instance (t2.micro) in public subnet.\n- Generated and downloaded key pair for SSH access.\n- Configured security group with SSH, HTTP, HTTPS ports. 07/10/2025 07/10/2025 https://console.aws.amazon.com/ec2/ 3 - Installed packages on EC2 instance.\n- Created EBS snapshot of root volume.\n- Built custom AMI from snapshot for faster future deployments. 08/10/2025 08/10/2025 https://console.aws.amazon.com/ec2/ 4 - Deployed Node.js application on EC2.\n- Set up systemd service for application auto-start.\n- Configured logging and monitored application health. 09/10/2025 09/10/2025 https://console.aws.amazon.com/ec2/ 5 - Learned Session Manager as SSH alternative.\n- Created IAM role with SSM permissions.\n- Practiced access recovery without key pair. 10/10/2025 10/10/2025 https://console.aws.amazon.com/systems-manager/ 6 - Created Lightsail instance as alternative to EC2.\n- Deployed WordPress using Lightsail blueprint.\n- Compared Lightsail vs EC2 pricing and use cases. 11/10/2025 11/10/2025 https://lightsail.aws.amazon.com/ Week 5 Outcomes Successfully launched and configured EC2 instances. Created reusable custom AMI for consistent deployments. Deployed working Node.js application with auto-restart capability. Learned Session Manager for enhanced security and auditability. Understood Lightsail as viable alternative for simpler workloads. Applied least privilege IAM policies for EC2 access control. Key Learnings:\nCustom AMI saves deployment time and ensures consistency. Session Manager provides better security audit trail than SSH key pairs. Lightsail offers simpler, fixed-price alternative for appropriate workloads. Proper IAM roles eliminate need for credential management on instances. "},{"uri":"https://masterltb.github.io/profile/6-self-evaluation/","title":"Self-evaluation","tags":[],"description":"","content":"Throughout my internship at Amazon Web Services from September 8, 2025, to November 28, 2025, I had the valuable opportunity to apply theoretical knowledge to build and deploy a real-world project on the cloud platform.\nI participated in the \u0026ldquo;Cessation Support Platform\u0026rdquo; project, through which I improved and developed a range of critical skills, including:\nBackend Development: Developed microservices using Java (version 25), handling complex business logic such as progress tracking, user management, and assessment systems. Cloud Architecture: Designed and implemented infrastructure on AWS, utilizing core services like EC2, S3, VPC, IAM, and RDS (PostgreSQL). DevOps: Built an automated CI/CD pipeline using AWS CodePipeline, which automated the build, test, and deployment process, minimizing manual errors. Database Management: Designed and managed a relational database (PostgreSQL) for user data and a non-relational database (MongoDB) for social features. Analysis and Problem-Solving: Analyzed requirements from the proposal, faced technical challenges (e.g., query optimization, complex business logic), and found suitable solutions. Regarding my professional conduct, I always strove to complete assigned tasks well, adhered to team workflows, and actively communicated with colleagues to ensure the project progressed correctly.\nTo objectively reflect on my internship, I would like to self-evaluate based on the criteria below:\nNo. Criteria Description Good Fair Average 1 Technical Knowledge \u0026amp; Skills Applied knowledge of Java, AWS, and DevOps to the project. Quality of code and infrastructure design. ‚úÖ ‚òê ‚òê 2 Learning Ability Quickly absorbed new technologies (CDK, Cognito) and complex concepts. ‚úÖ ‚òê ‚òê 3 Proactiveness Independently researched solutions for technical issues, proposed improvements to the CI/CD pipeline. ‚úÖ ‚òê ‚òê 4 Sense of Responsibility Ensured assigned features were completed on time and operated stably. ‚úÖ ‚òê ‚òê 5 Discipline Adhered to schedules, reporting procedures, and general team rules. ‚òê ‚úÖ ‚òê 6 Eagerness to Improve Always listened to feedback from mentors and colleagues to improve code and skills. ‚úÖ ‚òê ‚òê 7 Communication Clearly presented work progress and technical issues in team meetings. ‚òê ‚úÖ ‚òê 8 Team Collaboration Effectively coordinated with other members to integrate microservices. ‚úÖ ‚òê ‚òê 9 Professional Conduct Respected colleagues and the professional work environment. ‚úÖ ‚òê ‚òê 10 Problem-Solving Mindset Analyzed bugs, optimized performance, and identified the root causes of issues. ‚òê ‚úÖ ‚òê 11 Contribution to Project/Org Completed assigned modules, contributing to the successful development of the project\u0026rsquo;s backend. ‚úÖ ‚òê ‚òê 12 Overall Performance General assessment of the entire internship and personal growth. ‚úÖ ‚òê ‚òê Areas for Improvement Time Management: Need to improve skills in estimating time for complex tasks to ensure more accurate timelines. In-depth Networking Knowledge: Although I have worked with VPC, I need to learn more about advanced topics like peering, VPN, and Direct Connect to design more complex systems. Testing Skills: Need to write more comprehensive tests (unit, integration) and automate them more effectively in the CI/CD pipeline. Non-Technical Communication: Improve the ability to explain technical solutions to non-technical stakeholders in an easy-to-understand manner. "},{"uri":"https://masterltb.github.io/profile/5-workshop/5.6-setup-rds-database/","title":"5.6 Setup RDS Database","tags":[],"description":"","content":"Module 6: Create EC2 Instances \u0026amp; Setup Databases Module Objectives Create 4 EC2 instances from scratch Set up PostgreSQL on the DB-PG instance Set up MongoDB on the DB-Mongo instance Configure security groups Create databases \u0026amp; users Test connectivity between instances Set up monitoring \u0026amp; backups Duration: 5-6 hours\nEC2 Instances Overview 4 instances will be created in ap-southeast-1 (t4g.small, ARM-based, cost-effective):\nInstance Name Type Purpose Database Port smoking-db-pg t4g.small PostgreSQL Server smoking_cessation 5432 smoking-db-mongo t4g.small MongoDB Server smoking_cessation 27017 smoking-app-user t4g.small User Cessation App (PostgreSQL) 8000 smoking-app-social t4g.small Social Media App (MongoDB) 8000 Part 1: Create Security Groups Step 1: Create the Database Security Group EC2 Console Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for database servers VPC: Default VPC (or your VPC) Click \u0026ldquo;Create security group\u0026rdquo; Step 2: Add Inbound Rules for DB-SG Click on the newly created security group \u0026ldquo;Inbound rules\u0026rdquo; ‚Üí \u0026ldquo;Edit inbound rules\u0026rdquo; Add these rules: Type: PostgreSQL (5432) Source: Custom ‚Üí 172.0.0.0/16 (internal VPC CIDR) Type: Custom TCP 27017 (MongoDB) Source: 172.0.0.0/16 Click \u0026ldquo;Save rules\u0026rdquo; Step 3: Create the Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for application servers Click \u0026ldquo;Create security group\u0026rdquo; Step 4: Add Inbound Rules for App-SG Click on the newly created security group \u0026ldquo;Inbound rules\u0026rdquo; ‚Üí \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: SSH (22) Source: My IP (or 0.0.0.0/0 if you don\u0026rsquo;t have a fixed IP) Type: Custom TCP 8000 (application) Source: 0.0.0.0/0 (or restrict to the NLB later) Click \u0026ldquo;Save rules\u0026rdquo; Step 5: Add Outbound Rules \u0026ldquo;Outbound rules\u0026rdquo; ‚Üí \u0026ldquo;Edit outbound rules\u0026rdquo; Verify: All traffic to smoking-db-sg (for database access) All traffic to the internet (for package downloads) The default rule should allow this Click \u0026ldquo;Save rules\u0026rdquo; Part 2: Create EC2 Instances Step 1: Launch the First Instance (PostgreSQL) EC2 Console Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-pg AMI: Amazon Linux 2023 (free tier eligible) Instance type: t4g.small Keypair: Create a new one or select an existing one Key pair name: smoking-cessation-key Click \u0026ldquo;Create key pair\u0026rdquo; Download \u0026amp; save it securely Click \u0026ldquo;Next\u0026rdquo; Step 2: Configure the Network VPC: Default VPC (or your VPC) Subnet: Any (or a specific subnet in us-southeast-1a) Auto-assign public IP: Disable (private subnet) Security group: smoking-db-sg Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Storage Size: 30 GB (enough for the databases) Volume type: gp3 (general purpose, cost-effective) Delete on termination: ‚úÖ Click \u0026ldquo;Next\u0026rdquo; Step 4: Add Tags Tag key: Name Tag value: smoking-db-pg Click \u0026ldquo;Launch instance\u0026rdquo; ‚è≥ Wait for the instance to be created (2-3 minutes)\nStep 5: Note the Private IP Address Wait for the instance status to be \u0026ldquo;running\u0026rdquo; Copy the Private IPv4 address (e.g., 172.0.8.55) Save it for later: PG_HOST=172.0.8.55 Step 6: Create the MongoDB Instance (Same Steps) Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-mongo Same configuration as PostgreSQL Security group: smoking-db-sg Launch the instance Note the IP address: MONGO_HOST=\u0026lt;ip\u0026gt; Step 7: Create the Application Instances Launch the instance: smoking-app-user\nSecurity group: smoking-app-sg Note the IP: APP_USER_HOST=\u0026lt;ip\u0026gt; Launch the instance: smoking-app-social\nSecurity group: smoking-app-sg Note the IP: APP_SOCIAL_HOST=\u0026lt;ip\u0026gt; All 4 instances should now be running.\nPart 3: Set up PostgreSQL on the DB-PG Instance Step 1: Connect to the Instance Using AWS Session Manager (recommended) or SSH:\n# Via SSH (if you have the keypair) ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PRIVATE_IP\u0026gt; # Or use Session Manager in the EC2 Console # Click the instance ‚Üí Connect ‚Üí Session Manager ‚Üí Connect Step 2: Update the System sudo yum update -y sudo yum upgrade -y Step 3: Install PostgreSQL # Add the PostgreSQL repository sudo tee /etc/yum.repos.d/pgdg.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [pgdg15] name=PostgreSQL 15 for RHEL/CentOS 9 - x86_64 baseurl=https://download.postgresql.org/pub/repos/yum/15/rhel/rhel-9-x86_64 enabled=1 gpgcheck=1 gpgkey=https://download.postgresql.org/pub/repos/yum/RPM-GPG-KEY-PGDG EOF # Install PostgreSQL sudo yum install -y postgresql15-server postgresql15-contrib Step 4: Initialize the Database Cluster # Initialize the cluster sudo /usr/pgsql-15/bin/initdb -D /var/lib/pgsql/15/data # Create a system user if needed sudo useradd postgres || true # Change permissions sudo chown -R postgres:postgres /var/lib/pgsql/15/data Step 5: Start the PostgreSQL Service # Enable the service to start on boot sudo systemctl enable postgresql-15 # Start the service sudo systemctl start postgresql-15 # Verify the status sudo systemctl status postgresql-15 Step 6: Configure PostgreSQL for Network Access # Edit the config file sudo nano /var/lib/pgsql/15/data/postgresql.conf # Find and change these lines: # listen_addresses = \u0026#39;localhost\u0026#39; ‚Üí listen_addresses = \u0026#39;*\u0026#39; # port = 5432 ‚Üí keep as is # Save: Ctrl+O, Enter, Ctrl+X Step 7: Configure Client Authentication # Edit pg_hba.conf sudo nano /var/lib/pgsql/15/data/pg_hba.conf # Add this line at the end (before any reject lines): # host all all 172.0.0.0/16 md5 # This allows connections from the VPC CIDR 172.0.0.0/16 Step 8: Restart PostgreSQL sudo systemctl restart postgresql-15 sudo systemctl status postgresql-15 Step 9: Create the smoking_cessation Database # Switch to the postgres user sudo su - postgres # Connect to psql psql # Create the database CREATE DATABASE smoking_cessation; # Create the application user CREATE USER app_user WITH PASSWORD \u0026#39;YourSecurePassword123!\u0026#39;; # Grant privileges GRANT ALL PRIVILEGES ON DATABASE smoking_cessation TO app_user; # Connect to the database \\c smoking_cessation # Grant schema privileges GRANT ALL ON SCHEMA public TO app_user; GRANT ALL ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO app_user; # Verify \\du # List users \\l # List databases # Exit \\q exit Step 10: Verify PostgreSQL is Listening # Check if listening on port 5432 sudo netstat -tlnp | grep 5432 # Or use the ss command sudo ss -tlnp | grep 5432 # The output should show: LISTEN ... 0.0.0.0:5432 or :::5432 Part 4: Set up MongoDB on the DB-Mongo Instance Step 1: Connect to the Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_PRIVATE_IP\u0026gt; # Or use Session Manager Step 2: Update the System sudo yum update -y sudo yum upgrade -y Step 3: Install MongoDB # Create the MongoDB repository sudo tee /etc/yum.repos.d/mongodb-org.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [mongodb-org-7.0] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/amazon/2023/mongodb-org/7.0/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-7.0.asc EOF # Install MongoDB sudo yum install -y mongodb-org Step 4: Configure MongoDB for Network Access # Edit the MongoDB config sudo nano /etc/mongod.conf # Find these sections and modify: # network: # port: 27017 # bindIp: localhost ‚Üí Change to bindIp: 0.0.0.0 # Save: Ctrl+O, Enter, Ctrl+X Step 5: Start the MongoDB Service # Enable the service to start on boot sudo systemctl enable mongod # Start the service sudo systemctl start mongod # Verify the status sudo systemctl status mongod Step 6: Create a MongoDB Database \u0026amp; User # Connect to MongoDB mongosh # Switch to the admin database use admin # Create an admin user db.createUser({ user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;YourAdminPassword123!\u0026#34;, roles: [\u0026#34;root\u0026#34;] }) # Exit mongosh exit # Restart with authentication sudo nano /etc/mongod.conf # Find the security section and uncomment: # security: # authorization: enabled # Save and restart sudo systemctl restart mongod Step 7: Create an Application Database \u0026amp; User # Connect with authentication mongosh -u admin -p YourAdminPassword123! # Switch to the smoking_cessation database use smoking_cessation # Create an application user db.createUser({ user: \u0026#34;app_user\u0026#34;, pwd: \u0026#34;AppPassword123!\u0026#34;, roles: [{role: \u0026#34;readWrite\u0026#34;, db: \u0026#34;smoking_cessation\u0026#34;}] }) # Verify the user was created show users # Exit exit Step 8: Verify MongoDB is Listening # Check if listening on port 27017 sudo netstat -tlnp | grep 27017 # Or sudo ss -tlnp | grep 27017 # The output should show LISTEN on port 27017 Part 5: Test Database Connectivity Step 1: Test PostgreSQL from the App Instance Connect to the application instance:\nssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; # Install the PostgreSQL client sudo yum install -y postgresql15 # Test the connection to PostgreSQL psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation -c \u0026#34;SELECT 1\u0026#34; # Expected output: Should show \u0026#34;1\u0026#34; (success) Step 2: Test MongoDB from the App Instance # Install MongoDB tools sudo yum install -y mongodb-mongosh # Test the connection to MongoDB mongosh --host \u0026lt;MONGO_HOST_IP\u0026gt;:27017 --username app_user --password AppPassword123! --authenticationDatabase smoking_cessation --eval \u0026#34;db.adminCommand(\u0026#39;ping\u0026#39;)\u0026#34; # Expected output: { ok: 1 } Step 3: Test Inter-Instance Ping # From any instance, test network connectivity ping -c 3 \u0026lt;TARGET_IP\u0026gt; # Expected: Low latency (\u0026lt; 5ms in the same VPC) Part 6: Create Database Tables (PostgreSQL) Step 1: Connect to the Database From the app instance or via psql:\n# Connect to the smoking_cessation database psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation Step 2: Create Tables -- Create the users table CREATE TABLE users ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), cognito_id VARCHAR(255) UNIQUE NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, name VARCHAR(255) NOT NULL, role VARCHAR(50) DEFAULT \u0026#39;user\u0026#39;, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create the coaches table CREATE TABLE coaches ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, specialization VARCHAR(255), bio TEXT, hourly_rate DECIMAL(10, 2), created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create the coaching_sessions table CREATE TABLE coaching_sessions ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, coach_id UUID REFERENCES coaches(id) ON DELETE SET NULL, status VARCHAR(50) DEFAULT \u0026#39;active\u0026#39;, started_at TIMESTAMP, ended_at TIMESTAMP, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create indexes for performance CREATE INDEX idx_users_cognito_id ON users(cognito_id); CREATE INDEX idx_users_email ON users(email); CREATE INDEX idx_coaches_user_id ON coaches(user_id); CREATE INDEX idx_sessions_user_id ON coaching_sessions(user_id); CREATE INDEX idx_sessions_coach_id ON coaching_sessions(coach_id); -- Grant permissions to app_user GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO app_user; -- Verify the tables \\dt Step 3: Exit psql \\q Part 7: Set up the Application Servers (EC2 Instances) Step 1: Connect to the Application Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; Step 2: Install Node.js \u0026amp; npm # Update the system sudo yum update -y # Install Node.js (Amazon Linux version) curl -fsSL https://rpm.nodesource.com/setup_20.x | sudo bash - sudo yum install -y nodejs # Verify the installation node --version npm --version Step 3: Create the Application Directory # Create the app directory sudo mkdir -p /opt/smoking-cessation sudo chown -R ec2-user:ec2-user /opt/smoking-cessation # Change to the directory cd /opt/smoking-cessation # Create a basic package.json cat \u0026gt; package.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; { \u0026#34;name\u0026#34;: \u0026#34;smoking-cessation-app\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Smoking cessation user app\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;server.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node server.js\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;nodemon server.js\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;^4.18.2\u0026#34;, \u0026#34;pg\u0026#34;: \u0026#34;^8.10.0\u0026#34; } } EOF # Install dependencies npm install Step 4: Create a Basic Express Server # Create server.js cat \u0026gt; server.js \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; const express = require(\u0026#39;express\u0026#39;); const { Pool } = require(\u0026#39;pg\u0026#39;); const app = express(); const port = 8000; // Database connection pool const pool = new Pool({ user: \u0026#39;app_user\u0026#39;, password: process.env.DB_PASSWORD || \u0026#39;AppPassword123!\u0026#39;, host: process.env.DB_HOST || \u0026#39;localhost\u0026#39;, port: 5432, database: \u0026#39;smoking_cessation\u0026#39; }); app.use(express.json()); // Health check endpoint app.get(\u0026#39;/health\u0026#39;, (req, res) =\u0026gt; { res.json({ status: \u0026#39;ok\u0026#39;, service: \u0026#39;user-app\u0026#39; }); }); // Test the database connection app.get(\u0026#39;/db-test\u0026#39;, async (req, res) =\u0026gt; { try { const result = await pool.query(\u0026#39;SELECT NOW()\u0026#39;); res.json({ message: \u0026#39;Database connected\u0026#39;, time: result.rows[0] }); } catch (error) { res.status(500).json({ error: error.message }); } }); app.listen(port, () =\u0026gt; { console.log(`App listening on port ${port}`); }); EOF Step 5: Test the Application # Start the server node server.js # In another terminal, test the endpoints curl http://localhost:8000/health curl http://localhost:8000/db-test # Ctrl+C to stop Step 6: Create a Systemd Service (Optional) # Create the service file sudo tee /etc/systemd/system/smoking-app.service \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [Unit] Description=Smoking Cessation Application After=network.target [Service] Type=simple User=ec2-user WorkingDirectory=/opt/smoking-cessation ExecStart=/usr/bin/node server.js Restart=on-failure RestartSec=10 [Install] WantedBy=multi-user.target EOF # Enable and start the service sudo systemctl daemon-reload sudo systemctl enable smoking-app sudo systemctl start smoking-app sudo systemctl status smoking-app Part 8: Set up Monitoring \u0026amp; CloudWatch Step 1: Enable Detailed Monitoring EC2 Console Select each instance Right-click ‚Üí \u0026ldquo;Monitoring and troubleshooting\u0026rdquo; Click \u0026ldquo;Enable detailed monitoring\u0026rdquo; This provides 1-minute metrics instead of the default 5-minute.\nStep 2: Create CloudWatch Alarms For high CPU on the database instances:\nCloudWatch Console \u0026ldquo;Alarms\u0026rdquo; ‚Üí \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: AWS/EC2 Metric: CPUUtilization Dimension: Instance ID (select DB-PG) Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 80% Notification: Create an SNS topic for alerts Click \u0026ldquo;Create alarm\u0026rdquo; Repeat for all instances.\nStep 3: Create a Dashboard CloudWatch ‚Üí Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-infrastructure Add widgets: EC2 CPU Utilization (all instances) Network In/Out Disk usage (if the CloudWatch agent is installed) Click \u0026ldquo;Create dashboard\u0026rdquo; Part 9: Set up Database Backups Step 1: Create a Backup Directory On each database instance:\n# Create a backup directory sudo mkdir -p /backups sudo chown -R postgres:postgres /backups # For PostgreSQL Step 2: PostgreSQL Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PG_HOST\u0026gt; # Create a backup script cat \u0026gt; ~/backup-pg.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_FILE=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP.sql\u0026#34; sudo -u postgres pg_dump -d smoking_cessation -h localhost \u0026gt; \u0026#34;$BACKUP_FILE\u0026#34; # Keep only the last 7 days of backups find $BACKUP_DIR -name \u0026#34;smoking_cessation_*.sql\u0026#34; -mtime +7 -delete echo \u0026#34;Backup completed: $BACKUP_FILE\u0026#34; EOF # Make it executable chmod +x ~/backup-pg.sh # Test the backup ./backup-pg.sh # Add to crontab for daily backups at 3 AM crontab -e # Add: 0 3 * * * /home/ec2-user/backup-pg.sh \u0026gt;\u0026gt; /var/log/postgres-backup.log 2\u0026gt;\u0026amp;1 Step 3: MongoDB Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_HOST\u0026gt; # Create a backup script cat \u0026gt; ~/backup-mongo.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_PATH=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP\u0026#34; mongodump --username=admin --password=\u0026#34;YourAdminPassword123!\u0026#34; --db smoking_cessation --out \u0026#34;$BACKUP_PATH\u0026#34; # Keep only the last 7 days find $BACKUP_DIR -maxdepth 1 -type d -mtime +7 -exec rm -rf {} \\; echo \u0026#34;MongoDB backup completed: $BACKUP_PATH\u0026#34; EOF # Make it executable chmod +x ~/backup-mongo.sh # Test the backup ./backup-mongo.sh # Add to crontab for daily backups at 4 AM crontab -e # Add: 0 4 * * * /home/ec2-user/backup-mongo.sh \u0026gt;\u0026gt; /var/log/mongo-backup.log 2\u0026gt;\u0026amp;1 Step 4: Upload Backups to S3 (Optional) To back up off-instance (safer):\n# Configure the AWS CLI on the instance (requires an IAM role) aws configure # Modify the backup scripts to upload to S3: # aws s3 cp $BACKUP_FILE s3://smoking-cessation-backups/ Environment Variables Summary Save these for the Lambda functions \u0026amp; applications:\n# PostgreSQL PG_HOST=\u0026lt;DB-PG_PRIVATE_IP\u0026gt; PG_USER=app_user PG_PASSWORD=AppPassword123! PG_DATABASE=smoking_cessation PG_PORT=5432 # MongoDB MONGO_HOST=\u0026lt;DB-Mongo_PRIVATE_IP\u0026gt; MONGO_USERNAME=app_user MONGO_PASSWORD=AppPassword123! MONGO_DATABASE=smoking_cessation MONGO_PORT=27017 MONGO_URI=mongodb://app_user:AppPassword123!@\u0026lt;MONGO_HOST\u0026gt;:27017/smoking_cessation # Application Instances APP_USER_HOST=\u0026lt;APP_USER_PRIVATE_IP\u0026gt; APP_SOCIAL_HOST=\u0026lt;APP_SOCIAL_PRIVATE_IP\u0026gt; Checklist 4 EC2 instances launched (DB-PG, DB-Mongo, App-User, App-Social) Security groups created with proper inbound/outbound rules PostgreSQL installed, configured, and accessible MongoDB installed, configured, and accessible smoking_cessation database created in both databases Application users created with proper permissions Database tables created (users, coaches, sessions) Application instances can connect to the databases Inter-instance connectivity tested (ping, port access) Node.js \u0026amp; npm installed on the app instances Express server created and tested CloudWatch detailed monitoring enabled CloudWatch alarms configured for high CPU CloudWatch dashboard created Database backup scripts created and tested Backup scripts added to crontab All database credentials saved securely Ready for Module 7 (Create S3 \u0026amp; CloudFront) Troubleshooting Cannot Connect to PostgreSQL Issue: Connection refused on port 5432\nSolution:\n# Check that PostgreSQL is running sudo systemctl status postgresql-15 # Check that it\u0026#39;s listening on port 5432 sudo netstat -tlnp | grep 5432 # Check that the security group rules allow 5432 # From the app instance, verify: telnet \u0026lt;PG_HOST\u0026gt; 5432 # Check that pg_hba.conf allows the VPC CIDR sudo nano /var/lib/pgsql/15/data/pg_hba.conf Cannot Connect to MongoDB Issue: Connection refused on port 27017\nSolution:\n# Check that MongoDB is running sudo systemctl status mongod # Check the port listening sudo netstat -tlnp | grep 27017 # Check that mongod.conf bindIp is correct sudo nano /etc/mongod.conf # Verify that authentication is enabled correctly mongosh -u admin -p \u0026lt;password\u0026gt; Network Connectivity Issues Issue: Instances cannot ping each other\nSolution:\nVerify all instances are in the same VPC Check that the security group rules allow traffic between groups Check that the Network ACLs don\u0026rsquo;t block traffic Verify the instances have route table entries High CPU on a Database Instance Issue: CPU Utilization \u0026gt; 80%\nSolution:\n# Check the top processes top -b -n 1 | head -20 # For PostgreSQL, check for long-running queries: psql -h localhost -U postgres -d smoking_cessation SELECT pid, usename, query, query_start FROM pg_stat_activity WHERE query != \u0026#39;autovacuum\u0026#39;; # Consider: Scaling up the instance type, optimizing queries, or adding replication Cost Analysis Current costs (4 √ó t4g.small at $0.0252/hour):\nCompute: ~$30/month (4 instances √ó 730 hours) Storage: ~$10/month (4 √ó 30GB EBS volumes) Data transfer: ~$5/month Total: ~$45/month Optimization options:\nUse Reserved Instances for 30% savings (~$31/month) Right-size if low usage (t4g.micro: ~$10/month) Consolidate to 2 instances if possible Next Steps Configure auto-scaling for the application instances (optional) Set up read replicas for PostgreSQL (optional) Enable database replication for high availability (optional) Configure point-in-time recovery (PITR) for the databases (optional) Set up monitoring alerts (Module 9) What You Will Achieve After Module 6, you will have:\n‚úÖ 4 EC2 instances created \u0026amp; running ‚úÖ Security groups configured with the proper rules ‚úÖ PostgreSQL server set up \u0026amp; database created ‚úÖ MongoDB server set up \u0026amp; database created ‚úÖ Application users created in both databases ‚úÖ Database tables created \u0026amp; indexed ‚úÖ Application server configuration completed ‚úÖ Inter-instance connectivity tested ‚úÖ CloudWatch monitoring enabled ‚úÖ CloudWatch alarms configured ‚úÖ Database backup scripts set up ‚úÖ All databases operational \u0026amp; accessible ‚úÖ Ready for Module 7 (Create S3 \u0026amp; CloudFront) "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.6-week6/","title":"Worklog Week 6","tags":[],"description":"","content":"Week 6 Objectives Set up RDS for application data persistence. Understand database backup and recovery. Configure high availability with Multi-AZ and Read Replicas. Implement database security best practices. Tasks for this week Day Task Start Date Completion Date Reference 2 - Reviewed RDS fundamentals and database engines.\n- Created RDS MySQL instance in private subnet. 14/10/2025 14/10/2025 https://console.aws.amazon.com/rds/ 3 - Enabled Multi-AZ for automatic failover capability.\n- Configured automated backups with 7-day retention. 15/10/2025 15/10/2025 https://console.aws.amazon.com/rds/ 4 - Created Read Replica for load distribution.\n- Tested read/write distribution across instances. 16/10/2025 16/10/2025 https://console.aws.amazon.com/rds/ 5 - Configured security group for database access from app tier.\n- Tested connectivity from EC2 instances. 17/10/2025 17/10/2025 https://console.aws.amazon.com/rds/ 6 - Performed backup and restore testing.\n- Monitored database performance and connection metrics. 18/10/2025 18/10/2025 https://console.aws.amazon.com/rds/ Week 6 Outcomes Successfully set up RDS MySQL instance with Multi-AZ enabled. Configured automated backup strategy with appropriate retention. Implemented Read Replica for query load distribution. Secured database with proper security group configuration. Tested backup/restore procedures for disaster recovery readiness. Verified connectivity and performance metrics. Key Learnings:\nMulti-AZ provides high availability with automatic failover. Read Replicas scale read operations without impacting primary writes. Automated backups enable point-in-time recovery. Database should always reside in private subnet for security. "},{"uri":"https://masterltb.github.io/profile/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment The working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better.\n2. Support from Mentor / Team Admin The mentor provides very detailed guidance, explains clearly when I don‚Äôt understand, and always encourages me to ask questions. The mentor team supports the issues I encounter to facilitate my work. I highly appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major The tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities During the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared many real-world experiences that helped me better orient my career path.\n5. Company Culture \u0026amp; Team Spirit The company culture is very positive: everyone respects each other, works seriously, and everyone strives together and supports one another.\n6. Internship Policies / Benefits The company supports creating conditions for flexible time when necessary. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? The most satisfying part was the last four weeks when I had the opportunity to build a complete microservices system (Program Service and Chat Service) from scratch. Witnessing the complex business logic I designed‚Äîsuch as the Streak system and the Slip/Relapse mechanism‚Äîoperate accurately was an incredibly satisfying feeling. It turned theoretical knowledge into a tangible, functional product.\nWhat do you think the company should improve for future interns? I think the internship program would be more effective if there were a structured training roadmap from the beginning, helping interns better understand the actual work of the company and their role in the project. Being guided specifically step-by-step, from workflows to how to implement actual tasks, would help interns integrate faster into the professional working environment.\nAdditionally, having a clearer orientation on necessary DevOps skills, as well as an overview of the AWS services the company is using, would allow interns to easily build a solid foundation for long-term development. I also hope the program can provide documentation or a detailed competency framework to guide those who want to pursue a DevOps position in the future.\nIf recommending to a friend, would you suggest they intern here? Why? Definitely. I would love to recommend it to my friends. This is not an internship where you only do menial tasks. You are entrusted with a real, challenging project and trusted to build it. The learning curve is steep, but the amount of practical experience you gain regarding cloud architecture, backend development, and professional software engineering processes is priceless. The dedicated support from the mentor creates a perfect environment for development.\nSuggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? I suggest expanding the office scale so that more people have the opportunity to exchange directly with each other and experience working in an office environment more.\nWould you like to continue this program in the future? Yes, I am very interested in continuing with FCJ, whether through an internship program or otherwise. I feel a strong connection to the project I built and the infrastructure deployed on AWS. I am very excited about the possibility of developing it further, possibly implementing features like flow optimization or Video Call as mentioned in the initial proposal, to develop myself and learn more interesting things.\nAny other comments (free sharing): I am truly grateful for this opportunity. This internship was a pivotal moment in my professional development. It not only strengthened my technical skills but also gave me the confidence to face complex software engineering challenges in the real world. Thank you to the mentor and the entire team for guiding and supporting me.\n"},{"uri":"https://masterltb.github.io/profile/5-workshop/5.7-setup-s3-cloudfront/","title":"5.7 Setup S3 + CloudFront","tags":[],"description":"","content":"Module 7: Create S3 Buckets \u0026amp; CloudFront Distribution Module Objectives Create an S3 bucket for the frontend Configure bucket properties \u0026amp; policies Create a CloudFront distribution Set up Origin Access Control (OAC) Configure caching \u0026amp; security Deploy the frontend application Test access \u0026amp; cache invalidation Duration: 3-4 hours\nS3 \u0026amp; CloudFront Overview 2 S3 buckets + 1 CloudFront distribution will be created:\nComponent Name Region Purpose S3 Bucket 1 smoking-cessation-frontend us-east-1 Frontend React app hosting S3 Bucket 2 smoking-cessation-backups ap-southeast-1 Database backups \u0026amp; logs CloudFront CF Distribution Global CDN for the frontend (edge caching) Part 1: Create the Frontend S3 Bucket Step 1: Access the S3 Console Log in to the AWS Console Search for \u0026ldquo;S3\u0026rdquo; Click the \u0026ldquo;S3\u0026rdquo; service Click \u0026ldquo;Create bucket\u0026rdquo; Step 2: Configure Bucket Details Bucket name: smoking-cessation-frontend Must be globally unique Use lowercase and hyphens only Region: us-east-1 (required for CloudFront SSL) Object Ownership: ACLs disabled (recommended) Click \u0026ldquo;Create bucket\u0026rdquo; ‚è≥ Wait for the bucket to be created (a few seconds)\nStep 3: Configure Versioning Click on the smoking-cessation-frontend bucket Click the \u0026ldquo;Properties\u0026rdquo; tab Scroll down to \u0026ldquo;Versioning\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Check \u0026ldquo;Enable\u0026rdquo; versioning Click \u0026ldquo;Save changes\u0026rdquo; This allows for rollbacks if needed.\nStep 4: Configure Server Access Logging Still in the Properties tab Scroll to \u0026ldquo;Server access logging\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Enable logging: ‚úÖ Target bucket: Create a new logging bucket Name: smoking-cessation-logs Click \u0026ldquo;Save changes\u0026rdquo; Step 5: Enable Static Website Hosting Properties tab Scroll to \u0026ldquo;Static website hosting\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Static website hosting: Enable Index document: index.html Error document: index.html (for SPA routing) Click \u0026ldquo;Save changes\u0026rdquo; Step 6: Block Public Access Click the \u0026ldquo;Permissions\u0026rdquo; tab Scroll to \u0026ldquo;Block public access\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; ‚úÖ All 4 options enabled (keep S3 private, CloudFront accesses via OAC) Click \u0026ldquo;Save changes\u0026rdquo; This ensures only CloudFront can access the bucket.\nPart 2: Create a Bucket Policy for CloudFront Access Step 1: Create an Origin Access Control (OAC) CloudFront Console Left menu: \u0026ldquo;Origin access control\u0026rdquo; Click \u0026ldquo;Create origin access control\u0026rdquo; Name: smoking-cessation-oac Origin type: S3 Signing behavior: Sign requests Click \u0026ldquo;Create\u0026rdquo; ‚è≥ Wait for the OAC to be created\nNote the OAC ID shown (e.g., E7DE5EADPNE96) - you\u0026rsquo;ll need this for the S3 bucket policy.\nStep 2: Create a Bucket Policy Go to the S3 bucket: smoking-cessation-frontend Click the \u0026ldquo;Permissions\u0026rdquo; tab Scroll to \u0026ldquo;Bucket policy\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste this policy (replace OAC_ID with your OAC ID): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Note: You\u0026rsquo;ll update the distribution ID after creating the CloudFront distribution.\nPart 3: Create the Backups S3 Bucket Step 1: Create the Second Bucket S3 Console Click \u0026ldquo;Create bucket\u0026rdquo; Bucket name: smoking-cessation-backups Region: ap-southeast-1 (same as the databases) Click \u0026ldquo;Create bucket\u0026rdquo; Step 2: Configure the Backup Bucket Click into the bucket Properties tab Versioning: Enable (to keep backup history) Encryption: Use server-side encryption Type: AES-256 Click \u0026ldquo;Save changes\u0026rdquo; Step 3: Create a Lifecycle Policy (Optional) To archive old backups after 30 days:\nManagement tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Rule name: archive-old-backups Scope: Apply to all objects Transitions: Transition to Glacier: 30 days Expiration: Delete after 90 days Click \u0026ldquo;Create rule\u0026rdquo; Part 4: Create a CloudFront Distribution Step 1: Go to the CloudFront Console Search for \u0026ldquo;CloudFront\u0026rdquo; Click the \u0026ldquo;CloudFront\u0026rdquo; service Click \u0026ldquo;Create distribution\u0026rdquo; Step 2: Configure the Origin Origin domain: Select smoking-cessation-frontend.s3.us-east-1.amazonaws.com S3 access: Enable Origin Access Control (OAC) Select: smoking-cessation-oac (created in Part 2) HTTP version: HTTP/2 and HTTP/1.1 Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure the Default Cache Behavior Viewer protocol policy: Redirect HTTP to HTTPS Allowed HTTP methods: GET, HEAD, OPTIONS Cache policy: CachingOptimized (recommended) TTL: 86400 seconds (1 day) for HTML TTL: 31536000 seconds (1 year) for assets (js, css) Compress objects automatically: ‚úÖ Click \u0026ldquo;Next\u0026rdquo; Step 4: Configure Distribution Settings Enabled: ‚úÖ Default root object: index.html Standard logging: Disabled (use CloudWatch instead) IPv6: ‚úÖ Enabled Comment: Smoking Cessation Frontend CDN Click \u0026ldquo;Create distribution\u0026rdquo; ‚è≥ Wait for the distribution to be created \u0026amp; deployed (5-10 minutes)\nThe deployment status will show \u0026ldquo;In Progress\u0026rdquo; ‚Üí \u0026ldquo;Deployed\u0026rdquo;.\nStep 5: Note the CloudFront Details After deployment, note:\nDistribution ID: (e.g., E1NREZDKTJH6Y9) Domain name: (e.g., d2yo2hr161ib8h.cloudfront.net) CNAME: (if a custom domain is configured) Part 5: Update the S3 Bucket Policy with the Distribution ID Step 1: Get the Distribution ARN CloudFront console Select your distribution Copy the Distribution ID Step 2: Update the Bucket Policy Go to the S3 bucket: smoking-cessation-frontend Permissions ‚Üí Bucket policy Update the policy with your Distribution ID: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;YOUR_DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Part 6: Configure a Custom Domain (Optional) Step 1: Request an ACM Certificate Important: The ACM certificate must be in the us-east-1 region for CloudFront!\nSwitch the region to us-east-1 (top right) Search for \u0026ldquo;ACM\u0026rdquo; Click \u0026ldquo;Certificate Manager\u0026rdquo; Click \u0026ldquo;Request certificate\u0026rdquo; Certificate type: Public certificate Domain names: yourdomain.com *.yourdomain.com Validation method: DNS Click \u0026ldquo;Request\u0026rdquo; ‚è≥ Wait for the certificate to be issued\nYou\u0026rsquo;ll need to validate it via DNS CNAME records.\nStep 2: Validate the Certificate (DNS Method) Go back to ACM certificates Click on your certificate Click \u0026ldquo;Create records in Route 53\u0026rdquo; (if you\u0026rsquo;re using Route 53) Or manually add CNAME records to your DNS provider Step 3: Add the Custom Domain to CloudFront Once the certificate is validated:\nGo to the CloudFront distribution Click \u0026ldquo;Edit\u0026rdquo; Alternate domain names (CNAMEs): yourdomain.com www.yourdomain.com Custom SSL certificate: Select your ACM certificate Click \u0026ldquo;Save changes\u0026rdquo; Step 4: Update DNS Records Route 53 or your external DNS provider Create CNAME records: yourdomain.com ‚Üí d2yo2hr161ib8h.cloudfront.net www.yourdomain.com ‚Üí d2yo2hr161ib8h.cloudfront.net Wait for DNS propagation (up to 24 hours) Part 7: Configure CORS for S3 (If Needed) Step 1: Enable CORS S3 bucket: smoking-cessation-frontend Permissions tab Scroll to \u0026ldquo;CORS\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste the CORS configuration: [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;Authorization\u0026#34;, \u0026#34;Content-Length\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;https://yourdomain.com\u0026#34;, \u0026#34;https://www.yourdomain.com\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] Click \u0026ldquo;Save changes\u0026rdquo; Part 8: Build \u0026amp; Deploy the Frontend Step 1: Build the React Application On your local machine:\n# Navigate to the frontend directory cd /path/to/frontend # Install dependencies npm install # Build for production npm run build # Output will be in the dist/ or build/ folder Step 2: Upload to S3 Option A: Using the AWS CLI\n# Configure AWS credentials aws configure # Sync the build folder to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Set index.html to not cache aws s3 cp s3://smoking-cessation-frontend/index.html s3://smoking-cessation-frontend/index.html \\ --metadata-directive REPLACE \\ --cache-control \u0026#34;max-age=0, no-cache, no-store, must-revalidate\u0026#34; Option B: Using the S3 Console\nS3 bucket: smoking-cessation-frontend Click \u0026ldquo;Upload\u0026rdquo; Select all files from the dist/ folder Click \u0026ldquo;Upload\u0026rdquo; Step 3: Verify the Files Were Uploaded S3 bucket content You should see: index.html assets/ *.js, *.css files Other static files Part 9: Test Frontend Access Step 1: Test the CloudFront URL Open a browser Navigate to https://\u0026lt;your-cloudfront-domain\u0026gt;.cloudfront.net You should see your React application loading Step 2: Test the Custom Domain (If Configured) Navigate to https://yourdomain.com Verify the page loads properly Check the browser console for errors Step 3: Test SPA Routing Navigate to an invalid path (e.g., /invalid) You should see a 404 from your React app (not an AWS 404) This confirms the index.html error document is working Step 4: Check the HTTPS Certificate Click the lock icon in your browser Verify the certificate is valid The hostname should match your domain Part 10: Set up Cache Invalidation Step 1: Create an Invalidation via the Console When you deploy new code:\nCloudFront distribution \u0026ldquo;Invalidations\u0026rdquo; tab Click \u0026ldquo;Create invalidation\u0026rdquo; Object paths: /* /index.html Click \u0026ldquo;Create invalidation\u0026rdquo; ‚è≥ Wait for the invalidation to complete (2-3 minutes)\nStep 2: Automate Invalidation (Optional) Create a deployment script:\n#!/bin/bash # deploy.sh # Build npm run build # Upload to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Invalidate CloudFront aws cloudfront create-invalidation \\ --distribution-id E1NREZDKTJH6Y9 \\ --paths \u0026#34;/*\u0026#34; echo \u0026#34;Deployment complete!\u0026#34; Make it executable:\nchmod +x deploy.sh # Run the deployment ./deploy.sh Part 11: Configure Security Headers Step 1: Add Response Headers via CloudFront CloudFront distribution \u0026ldquo;Behaviors\u0026rdquo; tab Click the default behavior Edit ‚Üí \u0026ldquo;Response headers policy\u0026rdquo; Select or create a custom policy: X-Frame-Options: DENY X-Content-Type-Options: nosniff X-XSS-Protection: 1; mode=block Strict-Transport-Security: max-age=31536000; includeSubDomains Content-Security-Policy: default-src \u0026lsquo;self\u0026rsquo; Click \u0026ldquo;Save changes\u0026rdquo; Step 2: Add a Cache Key Policy For optimal caching:\nBehaviors tab Click the default behavior Edit ‚Üí \u0026ldquo;Cache key and origin requests\u0026rdquo; Cache policy: CachingOptimized Origin request policy: All ViewerExcept CloudFront-Authorization Click \u0026ldquo;Save changes\u0026rdquo; Part 12: Set up Monitoring \u0026amp; Logging Step 1: Enable CloudFront Metrics CloudFront distribution \u0026ldquo;Monitoring\u0026rdquo; tab View the metrics: Requests (total per time period) Data transferred (GB) Cache hit rate (%) 4xx/5xx error rate Default metrics are available (no extra cost) Step 2: Create CloudWatch Alarms For 4xx errors:\nCloudWatch console \u0026ldquo;Alarms\u0026rdquo; ‚Üí \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: CloudFront Metric: 4xxErrorRate Distribution: Your distribution Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 5% Notification: Create an SNS topic Topic name: smoking-cessation-alerts Email: your@email.com Click \u0026ldquo;Create alarm\u0026rdquo; Verify the SNS subscription via email Step 3: Create a CloudFront Dashboard CloudWatch ‚Üí Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-cdn Add widgets: CloudFront requests Bytes transferred Cache hit rate Error rates (4xx/5xx) Save the dashboard Environment Variables \u0026amp; URLs Save these URLs:\n# Frontend URLs FRONTEND_CLOUDFRONT_URL=https://d2yo2hr161ib8h.cloudfront.net FRONTEND_CUSTOM_DOMAIN=https://yourdomain.com FRONTEND_BUCKET=smoking-cessation-frontend FRONTEND_DISTRIBUTION_ID=E1NREZDKTJH6Y9 # Backup S3 BACKUPS_BUCKET=smoking-cessation-backups Checklist Frontend S3 bucket created (smoking-cessation-frontend) Versioning enabled on the frontend bucket Static website hosting enabled Public access blocked Backup S3 bucket created (smoking-cessation-backups) Lifecycle policy configured for backups Origin Access Control (OAC) created CloudFront distribution created S3 bucket policy configured with the Distribution ID Frontend built \u0026amp; uploaded to S3 CloudFront URL is accessible via HTTPS Custom domain configured (optional) ACM certificate issued \u0026amp; validated CORS configured if needed Security headers configured Cache invalidation tested CloudWatch monitoring enabled CloudWatch alarms created CloudWatch dashboard created Ready for Module 8 (Create VPC \u0026amp; Security) Troubleshooting CloudFront Shows 403 Forbidden Issue: Getting a 403 error when accessing via CloudFront\nSolution:\nVerify the S3 bucket policy is correct with the Distribution ID Verify the OAC is properly configured Check the CloudFront distribution status (must be \u0026ldquo;Deployed\u0026rdquo;) Wait 5 minutes for the changes to propagate Try a cache invalidation: /* Files Return 404 from S3 Issue: Some files return a 404 when accessed directly\nSolution:\nEnsure all files were uploaded to S3 Check the file permissions (should be private) Verify index.html exists For an SPA, ensure the error document is index.html SPA Routes Don\u0026rsquo;t Work Issue: Navigating to /dashboard returns a 404\nSolution:\nVerify the error document is set to index.html This allows React Router to handle routing Invalidate the CloudFront cache: /* Browser cache: Hard refresh (Ctrl+Shift+R or Cmd+Shift+R) Slow Content Delivery Issue: Pages are loading slowly\nSolution:\nEnable compression in CloudFront (gzip, brotli) Check the cache policy TTL Verify assets are in the /assets folder Monitor the CloudFront metrics for the cache hit ratio Consider adding more edge locations (available in pricing) DNS Resolution Issues Issue: The custom domain is not resolving\nSolution:\nVerify the DNS records were created in Route 53 Check that the CNAME points to the CloudFront domain Verify the ACM certificate is issued \u0026amp; validated Wait for DNS TTL propagation (up to 24 hours) Use nslookup yourdomain.com to test Cost Analysis Monthly costs estimate:\nS3 storage: ~$0.50 (100GB frontend + backups) S3 data transfer: ~$2 (to CloudFront) CloudFront: ~$2-5 (based on traffic) Cache invalidation: ~$0.10 (20 invalidations) Total: ~$5-8/month (very economical!) Cost optimization:\nUse the CloudFront TTL effectively (fewer invalidations) Compress objects in S3 Use S3 lifecycle policies for backups Next Steps Integrate the frontend with the API Gateway endpoints (Module 5) Set up the authentication flow with Cognito (Module 3) Configure error boundaries in React Set up analytics (Google Analytics is optional) Monitor CloudFront performance metrics What You Will Achieve After Module 7, you will have:\n‚úÖ A frontend S3 bucket created \u0026amp; configured ‚úÖ A backup S3 bucket created with a lifecycle policy ‚úÖ Origin Access Control configured ‚úÖ A CloudFront distribution deployed globally ‚úÖ HTTPS/SSL certificates configured ‚úÖ A custom domain configured (optional) ‚úÖ A frontend application deployed \u0026amp; accessible ‚úÖ Cache invalidation set up ‚úÖ Security headers configured ‚úÖ CORS configuration applied ‚úÖ CloudWatch monitoring \u0026amp; alarms configured ‚úÖ A CDN optimized for performance ‚úÖ Ready for Module 8 (Create VPC \u0026amp; Security) "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.7-week7/","title":"Worklog Week 7","tags":[],"description":"","content":"Week 7 Objectives Master AWS CLI for infrastructure automation. Set up Cloud9 IDE for development. Create automation scripts for routine tasks. Prepare for advanced AWS services. Tasks for this week Day Task Start Date Completion Date Reference 2 - Created Cloud9 environment within VPC.\n- Installed AWS CLI v2 in Cloud9.\n- Tested basic AWS CLI commands. 21/10/2025 21/10/2025 https://console.aws.amazon.com/cloud9/ 3 - Installed AWS CLI on local machine.\n- Configured multiple CLI profiles for different accounts.\n- Tested profile switching and commands. 22/10/2025 22/10/2025 https://aws.amazon.com/cli/ 4 - Used AWS CLI to list and manage EC2 instances.\n- Managed S3 buckets via CLI commands.\n- Created and managed IAM users via CLI. 23/10/2025 23/10/2025 https://console.aws.amazon.com/ec2/ 5 - Created bash scripts for automation.\n- Scripted backup procedures and cost analysis.\n- Set up CloudWatch alarms via CLI. 24/10/2025 24/10/2025 https://console.aws.amazon.com/systems-manager/ 6 - Analyzed cost and usage data via AWS CLI.\n- Created reports for monthly spending by service.\n- Identified cost optimization opportunities. 25/10/2025 25/10/2025 https://console.aws.amazon.com/ce/ Week 7 Outcomes Successfully set up Cloud9 IDE for cloud-based development. Configured AWS CLI with multiple profiles for different environments. Demonstrated proficiency with EC2, S3, and IAM management via CLI. Created automation scripts for routine backup and maintenance tasks. Analyzed cost data and identified optimization opportunities. Prepared foundation for advanced AWS service exploration. Key Learnings:\nCloud9 provides browser-based IDE with built-in terminal and IAM integration. AWS CLI is faster and more scriptable than console for repeated tasks. Multiple profiles enable management of different AWS accounts/environments. Automation scripts reduce manual errors and ensure consistent operations. Cost analysis enables proactive identification of waste and optimization. "},{"uri":"https://masterltb.github.io/profile/5-workshop/5.8-setup-vpc-security/","title":"5.8 Setup VPC &amp; Security","tags":[],"description":"","content":"Module 8: Create VPC, Subnets, Security Groups \u0026amp; NLB Module Objectives Create a new VPC from scratch Create public \u0026amp; private subnets Configure an Internet Gateway \u0026amp; a NAT Gateway Create 3 Security Groups Create a Network Load Balancer (NLB) for WebSocket Configure IAM policies Set up VPC Flow Logs \u0026amp; security monitoring Duration: 4-5 hours\nVPC \u0026amp; Network Overview The VPC architecture will be created in ap-southeast-1:\nVPC: smoking-cessation-vpc (172.0.0.0/16) ‚îú‚îÄ‚îÄ Public Subnets (Internet-facing) ‚îÇ ‚îú‚îÄ‚îÄ ap-southeast-1a: 172.0.0.0/24 ‚îÇ ‚îî‚îÄ‚îÄ ap-southeast-1b: 172.0.1.0/24 ‚îú‚îÄ‚îÄ Private Subnets (Database \u0026amp; Lambda) ‚îÇ ‚îú‚îÄ‚îÄ ap-southeast-1a: 172.0.10.0/24 ‚îÇ ‚îú‚îÄ‚îÄ ap-southeast-1b: 172.0.11.0/24 ‚îÇ ‚îî‚îÄ‚îÄ ap-southeast-1c: 172.0.12.0/24 ‚îú‚îÄ‚îÄ Internet Gateway: smoking-igw ‚îú‚îÄ‚îÄ NAT Gateway: smoking-nat (in a public subnet) ‚îú‚îÄ‚îÄ NLB: smoking-nlb (WebSocket endpoint) ‚îî‚îÄ‚îÄ 3 Security Groups: ‚îú‚îÄ‚îÄ smoking-nlb-sg (NLB) ‚îú‚îÄ‚îÄ smoking-app-sg (EC2 Applications) ‚îî‚îÄ‚îÄ smoking-db-sg (EC2 Databases) Part 1: Create a VPC Step 1: Access the VPC Console Log in to the AWS Console Search for \u0026ldquo;VPC\u0026rdquo; Click the \u0026ldquo;VPC\u0026rdquo; service Select the region: ap-southeast-1 Click \u0026ldquo;Create VPC\u0026rdquo; Step 2: Configure VPC Details Name tag: smoking-cessation-vpc IPv4 CIDR block: 172.0.0.0/16 Large enough for all subnets (65,536 addresses) IPv6 CIDR block: Leave empty Tenancy: Default Click \u0026ldquo;Create VPC\u0026rdquo; ‚è≥ Wait for the VPC to be created (a few seconds)\nStep 3: Note the VPC Details After creation, note:\nVPC ID: (e.g., vpc-049ff1c1372e1f3b8) VPC CIDR: 172.0.0.0/16 Part 2: Create an Internet Gateway Step 1: Create the IGW VPC Console Left menu: \u0026ldquo;Internet Gateways\u0026rdquo; Click \u0026ldquo;Create Internet gateway\u0026rdquo; Name: smoking-igw Click \u0026ldquo;Create internet gateway\u0026rdquo; ‚è≥ Wait for the IGW to be created\nStep 2: Attach the IGW to the VPC Click on the newly created IGW Click \u0026ldquo;Attach to VPC\u0026rdquo; Select VPC: smoking-cessation-vpc Click \u0026ldquo;Attach internet gateway\u0026rdquo; Part 3: Create Subnets Step 1: Create Public Subnet 1a VPC Console Left menu: \u0026ldquo;Subnets\u0026rdquo; Click \u0026ldquo;Create subnet\u0026rdquo; VPC ID: smoking-cessation-vpc Subnet name: smoking-public-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.0.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Step 2: Create Public Subnet 1b Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-public-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.1.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Step 3: Create Private Subnet 1a Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.10.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Step 4: Create Private Subnet 1b Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.11.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Step 5: Create Private Subnet 1c Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1c Availability Zone: ap-southeast-1c IPv4 CIDR block: 172.0.12.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Result: 5 subnets created (2 public + 3 private)\nPart 4: Create \u0026amp; Configure Route Tables Step 1: Create a Public Route Table Left menu: \u0026ldquo;Route tables\u0026rdquo; Click \u0026ldquo;Create route table\u0026rdquo; Name: smoking-public-rt VPC: smoking-cessation-vpc Click \u0026ldquo;Create route table\u0026rdquo; Step 2: Add an Internet Gateway Route to the Public RT Click on the public route table \u0026ldquo;Routes\u0026rdquo; tab ‚Üí \u0026ldquo;Edit routes\u0026rdquo; Click \u0026ldquo;Add route\u0026rdquo; Destination: 0.0.0.0/0 Target: Internet Gateway ‚Üí smoking-igw Click \u0026ldquo;Save routes\u0026rdquo; Step 3: Associate the Public RT with the Public Subnets \u0026ldquo;Subnet associations\u0026rdquo; tab ‚Üí \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-public-1a smoking-public-1b Click \u0026ldquo;Save associations\u0026rdquo; Step 4: Create a Private Route Table Click \u0026ldquo;Create route table\u0026rdquo; Name: smoking-private-rt VPC: smoking-cessation-vpc Click \u0026ldquo;Create route table\u0026rdquo; Step 5: Associate the Private RT with the Private Subnets Click on the private route table \u0026ldquo;Subnet associations\u0026rdquo; ‚Üí \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-private-1a smoking-private-1b smoking-private-1c Click \u0026ldquo;Save associations\u0026rdquo; Note: Private subnets route traffic via a NAT Gateway (which will be configured after the NAT is created).\nPart 5: Create a NAT Gateway Step 1: Create an Elastic IP for the NAT Left menu: \u0026ldquo;Elastic IPs\u0026rdquo; Click \u0026ldquo;Allocate Elastic IP address\u0026rdquo; Region: ap-southeast-1 Click \u0026ldquo;Allocate\u0026rdquo; Note the Elastic IP address Step 2: Create a NAT Gateway Left menu: \u0026ldquo;NAT Gateways\u0026rdquo; Click \u0026ldquo;Create NAT gateway\u0026rdquo; Name: smoking-nat Subnet: smoking-public-1a (place in a public subnet) Elastic IP allocation ID: Select the IP created in Step 1 Click \u0026ldquo;Create NAT gateway\u0026rdquo; ‚è≥ Wait for the NAT Gateway to be created (1-2 minutes)\nStep 3: Add a NAT Gateway Route to the Private RT Go to \u0026ldquo;Route tables\u0026rdquo; Click the private route table: smoking-private-rt \u0026ldquo;Routes\u0026rdquo; tab ‚Üí \u0026ldquo;Edit routes\u0026rdquo; Click \u0026ldquo;Add route\u0026rdquo; Destination: 0.0.0.0/0 Target: NAT Gateway ‚Üí smoking-nat Click \u0026ldquo;Save routes\u0026rdquo; Now the private subnets can reach the internet via the NAT Gateway.\nPart 6: Create Security Groups Step 1: Create the NLB Security Group Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-nlb-sg Description: Security group for the Network Load Balancer VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: Click on the newly created SG \u0026ldquo;Inbound rules\u0026rdquo; ‚Üí \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: HTTPS (443) Source: 0.0.0.0/0 (allow all for WebSocket) Type: HTTP (80) Source: 0.0.0.0/0 (for redirecting to HTTPS) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: The default allows all traffic ‚úÖ Step 2: Create the Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for the application servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; ‚Üí \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: Custom TCP 8000 Source: smoking-nlb-sg (allow from the NLB) Type: Custom TCP 22 (SSH) Source: My IP or 0.0.0.0/0 (for admin access) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Allow all traffic to the private subnets \u0026amp; databases Step 3: Create the Database Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for the database servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; ‚Üí \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: PostgreSQL (5432) Source: smoking-app-sg (allow from the app servers) Type: Custom TCP 27017 (MongoDB) Source: smoking-app-sg (allow from the app servers) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: The default allows all ‚úÖ Result: 3 security groups created with the proper rules\nPart 7: Create a Network Load Balancer Step 1: Go to Load Balancers Left menu: \u0026ldquo;Load Balancers\u0026rdquo; (under EC2) Click \u0026ldquo;Create load balancer\u0026rdquo; Select Network Load Balancer Click \u0026ldquo;Create\u0026rdquo; Step 2: Configure NLB Basic Settings Name: smoking-nlb Scheme: Internet-facing (accessible from the internet) IP address type: IPv4 VPC: smoking-cessation-vpc Subnets: - Select both public subnets: smoking-public-1a, smoking-public-1b Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Security Groups Security groups: Select smoking-nlb-sg Click \u0026ldquo;Next\u0026rdquo; Step 4: Configure Listeners and Routing Protocol: TCP Port: 443 (HTTPS for WebSocket) Default action: Forward to a target group Click \u0026ldquo;Create target group\u0026rdquo; Create a Target Group: Name: smoking-ws-targets Protocol: TCP Port: 8000 (where the apps listen) VPC: smoking-cessation-vpc Health check: - Protocol: TCP - Port: 8000 - Interval: 30 seconds - Healthy threshold: 2 Click \u0026ldquo;Create\u0026rdquo; Step 5: Register Targets After the target group is created, add targets: - Application instances (smoking-app-user, smoking-app-social) - Port: 8000 Click \u0026ldquo;Register targets\u0026rdquo; Step 6: Review \u0026amp; Create Review all settings Click \u0026ldquo;Create load balancer\u0026rdquo; ‚è≥ Wait for the NLB to be created \u0026amp; deployed (3-5 minutes)\nNote the NLB DNS name: (e.g., smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com)\nPart 8: Configure the NLB with HTTPS/TLS (Optional) Step 1: Request an ACM Certificate Search for \u0026ldquo;ACM\u0026rdquo; (Certificate Manager) Click \u0026ldquo;Request certificate\u0026rdquo; Domain names: yourdomain.com (if you have a custom domain) Or use the NLB DNS name Validation method: DNS Click \u0026ldquo;Request\u0026rdquo; Step 2: Create an HTTPS Listener Go to the NLB \u0026ldquo;Listeners\u0026rdquo; tab ‚Üí \u0026ldquo;Add listener\u0026rdquo; Protocol: TLS Port: 443 Default action: Forward to the target group smoking-ws-targets SSL certificate: Select your ACM certificate Click \u0026ldquo;Add\u0026rdquo; Step 3: Create an HTTP ‚Üí HTTPS Redirect (Optional) Add another listener: Protocol: TCP Port: 80 Default action: Redirect to port 443 (HTTPS) Part 9: Configure IAM Policies for Lambda VPC Access Step 1: Update the Lambda Execution Role Lambda functions that connect to a database need IAM permissions:\nGo to the IAM Console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; ‚Üí \u0026ldquo;Create inline policy\u0026rdquo; Select the \u0026ldquo;JSON\u0026rdquo; tab Paste the policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:DescribeNetworkInterfaces\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:AssignPrivateIpAddresses\u0026#34;, \u0026#34;ec2:UnassignPrivateIpAddresses\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-southeast-1:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:ap-southeast-1:*:secret:smoking-cessation/*\u0026#34; } ] } Click \u0026ldquo;Review policy\u0026rdquo; Policy name: lambda-vpc-policy Click \u0026ldquo;Create policy\u0026rdquo; Step 2: Configure the Lambda Functions for the VPC For each Lambda function that accesses a database:\nGo to the Lambda Console Click the function name Click the \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;VPC\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; VPC: smoking-cessation-vpc Subnets: Select the private subnets smoking-private-1a smoking-private-1b Security groups: smoking-app-sg Click \u0026ldquo;Save\u0026rdquo; This allows Lambda to access the EC2 database instances.\nPart 10: Set up VPC Flow Logs Step 1: Enable VPC Flow Logs Go to the VPC Console Click \u0026ldquo;VPCs\u0026rdquo; Select smoking-cessation-vpc Click the \u0026ldquo;Flow logs\u0026rdquo; tab Click \u0026ldquo;Create flow log\u0026rdquo; Step 2: Configure Flow Logs Name: smoking-vpc-flow-logs Traffic type: All (capture all traffic) Log destination: CloudWatch Logs Log group name: /aws/vpc/smoking-cessation-vpc IAM role: Create a new role Role name: vpc-flow-logs-role Click \u0026ldquo;Create flow log\u0026rdquo; ‚è≥ Wait for the flow logs to be enabled\nNow all VPC traffic will be logged to CloudWatch!\nPart 11: Enable GuardDuty (Threat Detection) Step 1: Enable GuardDuty Search for \u0026ldquo;GuardDuty\u0026rdquo; Click the \u0026ldquo;GuardDuty\u0026rdquo; service Click \u0026ldquo;Enable GuardDuty\u0026rdquo; Read and confirm the disclaimer Click \u0026ldquo;Enable GuardDuty\u0026rdquo; ‚è≥ Wait for GuardDuty to be enabled (a few minutes)\nGuardDuty will analyze the VPC Flow Logs for threats.\nPart 12: Test Network Connectivity Step 1: Test Public Subnet Connectivity From an EC2 instance in a public subnet:\n# Test internet connectivity ping 8.8.8.8 # Check the routing table route -n # You should see: # Destination Gateway # 172.0.0.0/16 0.0.0.0 (local) # 0.0.0.0/0 Internet Gateway Step 2: Test Private Subnet Connectivity From an EC2 instance in a private subnet:\n# Test the NAT Gateway (internet via NAT) curl https://ip.nslookup.com # Test database connectivity psql -h \u0026lt;DB_IP\u0026gt; -U postgres -d smoking_cessation # Test MongoDB mongosh --host \u0026lt;MONGO_IP\u0026gt;:27017 Step 3: Test the Security Group Rules # From the app server, test database access nc -zv \u0026lt;POSTGRES_IP\u0026gt; 5432 # Should be successful nc -zv \u0026lt;MONGO_IP\u0026gt; 27017 # Should be successful # From the internet, try to SSH to the app server ssh -i key.pem ec2-user@\u0026lt;NLB_DNS\u0026gt; # May time out (not open for SSH) Environment Variables \u0026amp; Networking Info Save these for future use:\n# VPC VPC_ID=vpc-046dc916dde2fb93f VPC_CIDR=172.0.0.0/16 # Subnets PUBLIC_SUBNET_1A=subnet-xxx PUBLIC_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1A=subnet-xxx PRIVATE_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1C=subnet-xxx # Gateways IGW_ID=igw-xxx NAT_EIP=\u0026lt;elastic-ip\u0026gt; NAT_GW_ID=nat-xxx # Security Groups NLB_SG_ID=sg-xxx APP_SG_ID=sg-xxx DB_SG_ID=sg-xxx # Load Balancer NLB_DNS=smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com NLB_ARN=arn:aws:elasticloadbalancing:ap-southeast-1:xxx Checklist VPC created (smoking-cessation-vpc) 5 subnets created (2 public + 3 private) Internet Gateway created \u0026amp; attached Public route table created \u0026amp; configured NAT Gateway created Private route table created \u0026amp; configured with the NAT 3 Security Groups created (NLB, App, DB) Security Group rules configured Network Load Balancer created Target group configured with health checks Application targets registered with the NLB HTTPS/TLS listener configured (optional) Lambda functions configured for VPC access Lambda IAM policy updated VPC Flow Logs enabled GuardDuty enabled Network connectivity tested Database access from apps verified Ready for Module 9 (CloudWatch Monitoring) Troubleshooting Instances Cannot Access the Internet Issue: A private subnet instance cannot reach the internet\nSolution:\nVerify the NAT Gateway is running (not failed) Check that the private route table has a NAT route: 0.0.0.0/0 ‚Üí NAT Gateway Verify an Elastic IP is allocated Check the security group outbound rules Lambda Cannot Connect to the Database Issue: Lambda times out when connecting to the database\nSolution:\nVerify the Lambda is in a VPC with private subnets Check that the database security group allows inbound traffic from the app SG Verify the database instances have the correct SG Test from an EC2 instance first to isolate the issue Check that the database is actually running NLB Health Checks Failing Issue: Target instances are marked as unhealthy\nSolution:\nVerify the target group health check port: 8000 Verify the application is listening on port 8000 Check the security group (NLB-SG ‚Üí App-SG) allows traffic SSH to the instance and test: curl http://localhost:8000/health Check the application logs for errors Cost Analysis VPC costs (mostly free, some charges):\nVPC: Free Subnets: Free IGW: Free NAT Gateway: ~$32/month (data processing charge) NLB: ~$16/month (hourly) + $0.006 per LCU VPC Flow Logs: ~$5/month (CloudWatch Logs storage) Total: ~$50-60/month Next Steps Connect the EC2 instances to the NLB targets Set up auto-scaling groups (optional) Configure CloudFront to front the NLB (optional) Set up a WAF for the NLB (optional) Monitor with CloudWatch (Module 9) What You Will Achieve After Module 8, you will have:\n‚úÖ A VPC created with the CIDR 172.0.0.0/16 ‚úÖ 5 subnets (2 public + 3 private) ‚úÖ An Internet Gateway attached ‚úÖ A NAT Gateway for private subnet internet access ‚úÖ Public \u0026amp; private route tables configured ‚úÖ 3 Security Groups with the proper rules ‚úÖ A Network Load Balancer that is operational ‚úÖ Lambda functions integrated with the VPC ‚úÖ VPC Flow Logs capturing all traffic ‚úÖ GuardDuty monitoring for threats ‚úÖ Network security fully configured ‚úÖ Ready for Module 9 (CloudWatch Monitoring \u0026amp; Alarms) "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.8-week8/","title":"Worklog Week 8","tags":[],"description":"","content":"Week 8 Objectives Review 4 core domains from OJT program: Security, Resilience, Performance, Cost Optimization. Connect labs from Weeks 2-7 to architecture patterns and exam scenarios. Prepare for AWS SAA-C03 certification exam on 31/10/2025. Tasks for this week Day Task Start Date Completion Date Reference 2 - Review Security concepts: IAM, MFA, encryption, KMS, Security Groups.\n- Apply security best practices from Weeks 3-4 labs. 27/10/2025 27/10/2025 https://aws.amazon.com/security/ 3 - Review Resilience: Multi-AZ, Auto Scaling, Load Balancers, Route 53.\n- Apply failover and scaling patterns from Weeks 4-5. 28/10/2025 28/10/2025 https://docs.aws.amazon.com/wellarchitected/ 4 - Review Performance: EC2, Lambda, S3, caching, CloudFront.\n- Apply optimization patterns from Weeks 5-6. 29/10/2025 29/10/2025 https://aws.amazon.com/architecture/well-architected/ 5 - Review Cost Optimization: Reserved Instances, Budgets, lifecycle policies.\n- Apply cost controls from Week 3 labs. 30/10/2025 30/10/2025 https://console.aws.amazon.com/ce/ 6 - Practice full exam: 65 questions covering all 4 domains.\n- Review weak areas and reinforce understanding. 30/10/2025 30/10/2025 https://skillbuilder.aws/ - - AWS SAA-C03 Certification Exam. 31/10/2025 31/10/2025 ‚Äî Week 8 Outcomes Mastered 4 core domains required for AWS SAA-C03 certification. Connected OJT hands-on labs (Weeks 2-7) to architecture patterns and exam scenarios. Understood AWS Well-Architected Framework: Security, Reliability, Performance Excellence, Cost Optimization. Prepared comprehensive exam strategy for 31/10/2025. Ready to apply AWS knowledge to real-world architecture decisions. Key Learnings:\nSecurity Domain: IAM roles ‚Üí least privilege | Encryption (KMS/TLS) ‚Üí data protection | VPC security ‚Üí network isolation | MFA ‚Üí access control Resilience Domain: Multi-AZ ‚Üí failover | Auto Scaling ‚Üí elasticity | Load Balancers ‚Üí traffic distribution | Route 53 ‚Üí DNS failover Performance Domain: Auto Scaling ‚Üí handle spikes | Lambda ‚Üí serverless compute | S3/EFS/EBS ‚Üí storage optimization | Caching ‚Üí reduced latency Cost Domain: Reserved Instances ‚Üí 30-70% savings | Budgets ‚Üí spending control | Lifecycle policies ‚Üí storage optimization | Right-sizing ‚Üí efficient resources "},{"uri":"https://masterltb.github.io/profile/5-workshop/5.9-monitoring-logging/","title":"5.9 Monitoring &amp; Logging","tags":[],"description":"","content":"Module 9: Setup CloudWatch Monitoring, Logging \u0026amp; Alerts Module Objectives Create CloudWatch Log Groups for all services Create a CloudWatch Dashboard to track metrics Create CloudWatch Alarms with SNS notifications Enable CloudTrail for audit logging Enable X-Ray for distributed tracing Set up Cost Monitoring \u0026amp; Budget Alerts Create CloudWatch Synthetics (health checks) Document incident response runbooks Duration: 3-4 hours\nMonitoring \u0026amp; Observability Architecture The infrastructure monitoring will cover:\nCloudWatch Monitoring: ‚îú‚îÄ‚îÄ Logs (CloudWatch Logs) ‚îÇ ‚îú‚îÄ‚îÄ /aws/lambda/functions ‚îÇ ‚îú‚îÄ‚îÄ /aws/apigateway/apis ‚îÇ ‚îú‚îÄ‚îÄ /aws/ec2/databases ‚îÇ ‚îú‚îÄ‚îÄ /aws/vpc/flow-logs ‚îÇ ‚îî‚îÄ‚îÄ /aws/s3/access-logs ‚îú‚îÄ‚îÄ Metrics \u0026amp; Dashboards ‚îÇ ‚îú‚îÄ‚îÄ EC2 (CPU, Network, Disk) ‚îÇ ‚îú‚îÄ‚îÄ Lambda (Invocations, Errors, Duration) ‚îÇ ‚îú‚îÄ‚îÄ API Gateway (Requests, Errors, Latency) ‚îÇ ‚îú‚îÄ‚îÄ CloudFront (Requests, Cache Hit Rate) ‚îÇ ‚îî‚îÄ‚îÄ NLB (Connections, Target Health) ‚îú‚îÄ‚îÄ Alarms (SNS Notifications) ‚îÇ ‚îú‚îÄ‚îÄ High error rates ‚îÇ ‚îú‚îÄ‚îÄ High latency ‚îÇ ‚îú‚îÄ‚îÄ Resource exhaustion ‚îÇ ‚îî‚îÄ‚îÄ Cost anomalies ‚îî‚îÄ‚îÄ Audit Trail ‚îú‚îÄ‚îÄ CloudTrail (API calls) ‚îî‚îÄ‚îÄ X-Ray (Request tracing) Part 1: Create CloudWatch Log Groups Step 1: Create Lambda Log Groups CloudWatch Console Left menu: \u0026ldquo;Logs\u0026rdquo; ‚Üí \u0026ldquo;Log groups\u0026rdquo; Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/lambda/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; ‚è≥ Wait for the log group to be created\nNote: Lambda functions automatically create their own log streams, but creating a parent log group allows for custom configuration.\nStep 2: Create API Gateway Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/apigateway/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Step 3: Create EC2 Databases Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/ec2/databases Click \u0026ldquo;Create log group\u0026rdquo; Step 4: Create a VPC Flow Logs Group Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/vpc/flow-logs Click \u0026ldquo;Create log group\u0026rdquo; Step 5: Create CloudFront Log Groups (Optional) Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/cloudfront/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Result: 5 log groups created for centralized logging\nStep 6: Configure Log Retention Policies For each log group:\nClick on the log group name Actions ‚Üí \u0026ldquo;Edit retention settings\u0026rdquo; Retention: 30 days Balances cost vs. historical data Click \u0026ldquo;Save\u0026rdquo; This prevents logs from consuming unlimited storage.\nPart 2: Create a CloudWatch Dashboard Step 1: Create a Dashboard CloudWatch Console Left menu: \u0026ldquo;Dashboards\u0026rdquo; Click \u0026ldquo;Create dashboard\u0026rdquo; Dashboard name: smoking-cessation-monitoring Click \u0026ldquo;Create dashboard\u0026rdquo; ‚è≥ Wait for the dashboard to be created\nStep 2: Add a Lambda Metrics Widget Click \u0026ldquo;Add widget\u0026rdquo; Choose a Line chart Metric selection: Namespace: AWS/Lambda Metric: Invocations Statistics: Sum Add multiple metrics: Invocations Duration (Average) Errors (Sum) Throttles (Sum) Widget name: Lambda Performance Click \u0026ldquo;Create widget\u0026rdquo; Step 3: Add API Gateway Metrics Click \u0026ldquo;Add widget\u0026rdquo; ‚Üí Line chart Metric selection: Namespace: AWS/ApiGateway Metrics: Count (total requests) 4XXError 5XXError Latency (p99) Widget name: API Gateway Metrics Click \u0026ldquo;Create widget\u0026rdquo; Step 4: Add EC2 Database Metrics Click \u0026ldquo;Add widget\u0026rdquo; ‚Üí Line chart Metric selection: Namespace: AWS/EC2 Filter by instances: DB-PG, DB-Mongo Metrics: CPUUtilization NetworkPacketsIn NetworkPacketsOut DiskReadBytes Widget name: Database Performance Click \u0026ldquo;Create widget\u0026rdquo; Step 5: Add CloudFront Metrics Click \u0026ldquo;Add widget\u0026rdquo; ‚Üí Number widget Metric selection: Namespace: AWS/CloudFront Metrics: Requests (Sum) BytesDownloaded CacheHitRate 4xxErrorRate 5xxErrorRate Widget name: CDN Performance Click \u0026ldquo;Create widget\u0026rdquo; Step 6: Add NLB Metrics Click \u0026ldquo;Add widget\u0026rdquo; ‚Üí Line chart Metric selection: Namespace: AWS/NetworkELB Metrics: ActiveFlowCount HealthyHostCount UnHealthyHostCount ProcessedBytes Widget name: Load Balancer Health Click \u0026ldquo;Create widget\u0026rdquo; Step 7: Configure Dashboard Settings Dashboard settings (gear icon) Auto-refresh: 1 minute Save dashboard Now you have a real-time monitoring dashboard!\nPart 3: Create an SNS Topic for Notifications Step 1: Create an SNS Topic Search for \u0026ldquo;SNS\u0026rdquo; Click the \u0026ldquo;SNS\u0026rdquo; service Left menu: \u0026ldquo;Topics\u0026rdquo; Click \u0026ldquo;Create topic\u0026rdquo; Type: Standard Name: smoking-cessation-alerts Click \u0026ldquo;Create topic\u0026rdquo; ‚è≥ Wait for the topic to be created\nStep 2: Create an Email Subscription Click on the newly created topic \u0026ldquo;Subscriptions\u0026rdquo; tab ‚Üí \u0026ldquo;Create subscription\u0026rdquo; Protocol: Email Endpoint: your-email@example.com Click \u0026ldquo;Create subscription\u0026rdquo; ‚è≥ Wait for the email confirmation\nCheck your email inbox and click the confirmation link!\nStep 3: Create an SMS Subscription (Optional) Click \u0026ldquo;Create subscription\u0026rdquo; Protocol: SMS Endpoint: +1234567890 (your phone number) Click \u0026ldquo;Create subscription\u0026rdquo; Now you\u0026rsquo;ll get SMS alerts for critical issues!\nPart 4: Create CloudWatch Alarms Step 1: Create a Lambda Error Alarm CloudWatch ‚Üí Alarms ‚Üí \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/Lambda Metric: Errors Statistics: Sum Conditions: Threshold: \u0026gt; 5 errors Period: 5 minutes Evaluation periods: 1 Click \u0026ldquo;Next\u0026rdquo; Notification: Select the SNS topic smoking-cessation-alerts Alarm name: smoking-lambda-errors Alarm description: Alert when Lambda errors exceed the threshold Click \u0026ldquo;Create alarm\u0026rdquo; Step 3: Create an EC2 Database CPU Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/EC2 Metric: CPUUtilization Instance: DB-PG Conditions: Threshold: \u0026gt; 80% Period: 5 minutes Evaluation periods: 2 Click \u0026ldquo;Next\u0026rdquo; Notification: smoking-cessation-alerts Alarm name: smoking-db-pg-high-cpu Click \u0026ldquo;Create alarm\u0026rdquo; Step 4: Create Similar Alarms for Other Services Repeat for:\nDB-Mongo CPU \u0026gt; 80% Application servers CPU \u0026gt; 75% CloudFront 4xx errors \u0026gt; 5% CloudFront 5xx errors \u0026gt; 1% NLB unhealthy targets \u0026gt; 0 Step 5: Create a Composite Alarm (Optional) Combine multiple alarms into one:\nClick \u0026ldquo;Create alarm\u0026rdquo; Alarm type: Composite alarm Alarm rule: (smoking-lambda-errors OR smoking-apigateway-errors OR smoking-db-pg-high-cpu OR smoking-db-mongo-high-cpu) This triggers if ANY service has issues. Click \u0026ldquo;Create alarm\u0026rdquo; Result: A comprehensive alerting system is now active!\nPart 5: Enable CloudTrail Audit Logging Step 1: Create a CloudTrail Search for \u0026ldquo;CloudTrail\u0026rdquo; Click the \u0026ldquo;CloudTrail\u0026rdquo; service Click \u0026ldquo;Create trail\u0026rdquo; Trail name: smoking-cessation-audit Enable for all AWS regions: ‚úÖ (recommended) Click \u0026ldquo;Next\u0026rdquo; Step 2: Configure S3 for CloudTrail Logs S3 bucket: Create a new bucket: ‚úÖ Bucket name: smoking-cessation-cloudtrail-logs S3 key prefix (optional): cloudtrail-logs/ Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure CloudTrail Events Management events: ‚úÖ All (captures API calls) Data events: (Optional - more expensive) Insights: ‚úÖ CloudTrail Insights (detects unusual activity) Click \u0026ldquo;Next\u0026rdquo; Step 4: Review \u0026amp; Create Review all settings Click \u0026ldquo;Create trail\u0026rdquo; ‚è≥ Wait for the trail to be created\nStep 5: Start Logging Trail created ‚Üí click \u0026ldquo;Start logging\u0026rdquo; The trail status will change to \u0026ldquo;Logging\u0026rdquo; Now all API calls are being audited!\nStep 6: View CloudTrail Events CloudTrail ‚Üí Event history Filter by: Event name: (e.g., PutFunction for Lambda code updates) Resource type: (e.g., AWS::Lambda::Function) Time range: Last 24 hours View the event details (JSON format) This helps with:\nSecurity audits Compliance investigations Troubleshooting IAM issues Cost allocation Part 6: Enable X-Ray for Distributed Tracing Step 1: Create an X-Ray Sampling Rule Search for \u0026ldquo;X-Ray\u0026rdquo; Click the \u0026ldquo;X-Ray\u0026rdquo; service Left menu: \u0026ldquo;Sampling rules\u0026rdquo; Click \u0026ldquo;Create sampling rule\u0026rdquo; Rule name: smoking-cessation-sampling Priority: 1000 (lower = higher priority) Reservoir: 1 (always sample at least 1 per second) Fixed rate: 0.1 (10% of requests) Click \u0026ldquo;Create sampling rule\u0026rdquo; This controls how many traces are recorded (reducing cost).\nStep 2: Enable X-Ray for the Lambda Functions For each Lambda function:\nLambda Console Click the function name Configuration tab Click \u0026ldquo;General configuration\u0026rdquo; ‚Üí Edit Under \u0026ldquo;Monitoring tools\u0026rdquo;: ‚úÖ Check \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for all 5 Lambda functions.\nStep 3: Enable X-Ray for API Gateway API Gateway Console Select the API: smoking-cessation-user-api Logging ‚Üí Settings ‚úÖ Check \u0026ldquo;X-Ray request tracing enabled\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for the chat API Step 4: Update the Lambda IAM Role for X-Ray IAM Console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Add permissions ‚Üí Attach policies directly Search for: AWSXRayWriteAccess Check ‚úÖ Click \u0026ldquo;Attach policies\u0026rdquo; Now Lambda can write X-Ray traces!\nStep 5: View the Service Map X-Ray Console Left menu: \u0026ldquo;Service map\u0026rdquo; You\u0026rsquo;ll see a map showing: API Gateway ‚Üí Lambda ‚Üí EC2 (databases) Lambda ‚Üí S3 Lambda ‚Üí CloudFront Data flow between services As requests flow through the system, traces are recorded!\nStep 6: Analyze Traces X-Ray ‚Üí Traces Click on a trace to view: The service timeline A latency breakdown per service Errors and exceptions Database query details Use this to identify performance bottlenecks Part 7: Set up Cost Monitoring Step 1: Create an AWS Budget Billing Console Left menu: \u0026ldquo;Budgets\u0026rdquo; Click \u0026ldquo;Create budget\u0026rdquo; Budget type: Cost budget Period: Monthly Amount: $500/month Alerts: When actual \u0026gt; 80% ($400): Email When forecasted \u0026gt; 100% ($500): Email Click \u0026ldquo;Create budget\u0026rdquo; This prevents surprise bills!\nStep 2: Set up Cost Anomaly Detection Cost Management Console Left menu: \u0026ldquo;Anomaly Detection\u0026rdquo; Click \u0026ldquo;Create detector\u0026rdquo; Name: smoking-cessation-cost-anomaly Monitor: All AWS Services Frequency: Daily Alert frequency: Instant SNS topic: smoking-cessation-alerts Click \u0026ldquo;Create detector\u0026rdquo; Now you\u0026rsquo;ll be alerted if costs spike unexpectedly!\nStep 3: Use Cost Explorer Cost Explorer View costs by: Service: See which services cost the most Region: Compare regions Time: Identify trends Filter: Linked account Cost category Granularity: Daily or Monthly Common cost optimization findings:\nNAT Gateway data processing \u0026gt; 50% of the bill EC2 instances running 24/7 \u0026gt; 30% of the bill CloudFront data transfer \u0026gt; 10% of the bill Part 8: Create CloudWatch Synthetics (Health Checks) Step 1: Create an API Canary CloudWatch Console Left menu: \u0026ldquo;Synthetics\u0026rdquo; ‚Üí \u0026ldquo;Canaries\u0026rdquo; Click \u0026ldquo;Create canary\u0026rdquo; Canary type: API canary Name: smoking-api-health-check Endpoint: Your API Gateway URL https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/health Method: GET Schedule: 5 minutes Click \u0026ldquo;Next\u0026rdquo; Step 2: Configure Success Criteria Status codes: 200 Response time: \u0026lt; 1000ms Click \u0026ldquo;Next\u0026rdquo; Step 3: Set S3 Storage S3 location: Create a new bucket or select an existing one Bucket name: smoking-canary-results Click \u0026ldquo;Create canary\u0026rdquo; ‚è≥ Wait for the canary to be created\nStep 4: Monitor Canary Results Synthetics ‚Üí Canaries Click smoking-api-health-check View: The success rate Latency graphs Failed requests If there are failures, create a CloudWatch alarm. This continuously tests API availability!\nPart 9: Create Incident Response Runbooks Step 1: Document a High Error Rate Response Create a file or document:\nINCIDENT: High Lambda Error Rate (\u0026gt; 5 errors/5min) Detection: CloudWatch Alarm \u0026#34;smoking-lambda-errors\u0026#34; triggered Immediate Actions: 1. Check CloudWatch Logs: - Go to CloudWatch ‚Üí Logs ‚Üí Log groups - Select `/aws/lambda/smoking-cessation` - Search for \u0026#34;error\u0026#34; or \u0026#34;Error\u0026#34; - Note the error message \u0026amp; frequency 2. Identify the Affected Function: - From the alarm, determine which function - Check the recent CloudTrail logs - Verify there were no recent code deployments 3. Database Connectivity Check: - If it\u0026#39;s a DB error: - EC2 ‚Üí Instances - Check the DB-PG and DB-Mongo status - Check that the security groups allow traffic - If it\u0026#39;s not a DB error, check the Lambda timeout configuration 4. Escalation: - If not resolved in 15 min, page the on-call engineer - If there\u0026#39;s a risk of data loss, initiate disaster recovery Resolution: - Roll back recent deployments if applicable - Scale up database resources if overloaded - Increase Lambda memory if there are timeout issues - Update database connection pooling Post-Incident: - Document the root cause - Update monitoring to catch it earlier - Schedule a post-mortem meeting Step 2: Create a High API Latency Runbook INCIDENT: High API Latency (\u0026gt; 1000ms p99) Actions: 1. Check the X-Ray service map to identify the slow service 2. If Lambda is slow: - Increase the memory (more CPU) - Check the CloudWatch Logs for errors 3. If the database is slow: - Monitor the EC2 instance CPU/Memory - Check the slow query logs 4. If API Gateway is slow: - Check the request volume - Verify the cache hit rate (CloudFront) 5. Resolution: - Scale resources up - Optimize queries/code - Add a caching layer Step 3: Create a Database Disk Full Runbook INCIDENT: Database Disk Full (\u0026gt; 90%) Actions: 1. SSH to the DB instance (EC2) 2. Check disk usage: df -h /var 3. Clean up: - Remove old logs: find /var/log -mtime +30 -delete - Archive old data from PostgreSQL - Delete old MongoDB collections 4. If it\u0026#39;s still full: - Add an EBS volume or expand the existing one - Migrate to a larger instance type 5. Configure auto-cleanup for the future Environment Variables \u0026amp; Monitoring Info Save these for reference:\n# CloudWatch DASHBOARD_NAME=smoking-cessation-monitoring LOG_GROUP_LAMBDA=/aws/lambda/smoking-cessation LOG_GROUP_APIGATEWAY=/aws/apigateway/smoking-cessation LOG_GROUP_VPC=/aws/vpc/flow-logs LOG_RETENTION=30 # days # Alarms \u0026amp; Notifications SNS_TOPIC_ARN=arn:aws:sns:ap-southeast-1:xxx:smoking-cessation-alerts ALARM_LAMBDA_ERRORS=smoking-lambda-errors ALARM_APIGATEWAY_ERRORS=smoking-apigateway-errors ALARM_DB_CPU_HIGH=smoking-db-cpu-high # Audit \u0026amp; Tracing CLOUDTRAIL_BUCKET=smoking-cessation-cloudtrail-logs XRAY_SAMPLING_RATE=0.1 SYNTHETICS_BUCKET=smoking-canary-results # Budget MONTHLY_BUDGET=$500 ALERT_THRESHOLD=80% # $400 Checklist CloudWatch Log Groups created for all services Log retention set to 30 days CloudWatch Dashboard created with key metrics SNS topic created for notifications Email subscription verified CloudWatch Alarms created: Lambda errors API Gateway errors EC2 database high CPU CloudFront errors NLB health CloudTrail enabled \u0026amp; logging CloudTrail S3 bucket created X-Ray sampling rule configured X-Ray enabled on the Lambda functions X-Ray enabled on API Gateway The Lambda IAM role has X-Ray permissions AWS Budget configured ($500/month) Cost Anomaly Detection enabled CloudWatch Synthetics canary created Incident response runbooks documented Team trained on the monitoring tools WORKSHOP COMPLETE ‚úÖ Monitoring Best Practices Alert Fatigue Prevention Set thresholds based on historical baselines Use composite alarms for multiple conditions Implement alert deduplication Log Management Set the appropriate retention (30 days is a good balance) Use filters to reduce noise Archive to S3 Glacier for long-term storage Cost Optimization Review CloudWatch costs monthly Use Log Insights selectively Archive old logs to S3 Security Enable CloudTrail multi-region Review CloudTrail logs weekly Monitor for suspicious IAM activity Cost Analysis Monitoring costs (estimated monthly):\nCloudWatch Logs: ~$20 (log ingestion + storage) CloudWatch Alarms: ~$5 (10 alarms √ó $0.50) CloudTrail: ~$3 (multi-region trail) X-Ray: ~$2 (10% sampling rate) Cost Explorer: Free Synthetics: ~$1 (1 canary every 5 min) Total: ~$31/month Next Steps Monitor the dashboard daily during the initial rollout Adjust alarm thresholds based on actual metrics Review the CloudTrail logs for security Optimize costs based on Cost Explorer findings Plan disaster recovery based on the CloudTrail audit trail Schedule monthly post-mortems for any incidents What You Will Achieve After Module 9, you will have:\n‚úÖ CloudWatch Log Groups for all services ‚úÖ Centralized logging with 30-day retention ‚úÖ A real-time monitoring dashboard ‚úÖ Automated SNS alerts for critical issues ‚úÖ Email/SMS notifications working ‚úÖ CloudWatch Alarms monitoring performance ‚úÖ CloudTrail enabled for compliance auditing ‚úÖ X-Ray for distributed tracing and debugging ‚úÖ A service map showing the architecture ‚úÖ Cost monitoring \u0026amp; budgets configured ‚úÖ CloudWatch Synthetics for continuous health checks ‚úÖ Incident response runbooks documented ‚úÖ Complete observability of the infrastructure ‚úÖ üéâ AWS WORKSHOP 100% COMPLETE üéâ Workshop Summary You have successfully built a complete AWS infrastructure for the Smoking Cessation Platform:\nModules Completed (9 Total): Modules 1-2: Prerequisites \u0026amp; AWS Account Setup ‚úÖ Module 3: Cognito Authentication ‚úÖ Module 4: Lambda Functions ‚úÖ Module 5: API Gateway REST APIs ‚úÖ Module 6: EC2 Instances \u0026amp; Databases ‚úÖ Module 7: S3 Frontend \u0026amp; CloudFront CDN ‚úÖ Module 8: VPC, Security, \u0026amp; Load Balancing ‚úÖ Module 9: Monitoring, Logging \u0026amp; Alerts ‚úÖ Architecture Highlights: ‚úÖ Secure authentication (Cognito) ‚úÖ Serverless compute (Lambda) ‚úÖ RESTful APIs (API Gateway) ‚úÖ Hybrid databases (PostgreSQL + MongoDB on EC2) ‚úÖ Global content delivery (CloudFront) ‚úÖ High-availability networking (VPC, NLB) ‚úÖ Comprehensive monitoring (CloudWatch, X-Ray) ‚úÖ A complete audit trail (CloudTrail) Estimated Monthly Cost: $320-350 EC2 (4 instances): $120 Lambda: $10 API Gateway: $5 S3 + CloudFront: $10 NAT Gateway: $32 NLB: $16 CloudWatch/Logs: $30 Other services: $30 Your infrastructure is production-ready! üöÄ\n"},{"uri":"https://masterltb.github.io/profile/1-worklog/1.9-week9/","title":"Worklog Week 9","tags":[],"description":"","content":"Week 9 Objectives Dual-Service Kick-off: Scaffold both Program Service and Chat Service using Java 25 and Spring Boot. DB Design: Design and implement the database schemas for both services. Initial Logic: Build the Assessment \u0026amp; Recommendation flow for the Program Service and apply a shared security layer. Tasks for this week Day Task Start Date Completion Date Reference 2 - Program Service: Initialized Spring Boot project and designed ERD for Programs, Quizzes. - Chat Service: Designed ERD for ChatRooms, Messages. 03/11/2025 03/11/2025 https://start.spring.io/ 3 - Program Service: Implemented MeQuizController to classify addiction levels. - Chat Service: Initialized Spring Boot project and created Entity classes (ChatRoom, Message). 04/11/2025 04/11/2025 ‚Äî 4 - Program Service: Seeded ProgramTemplates data and developed the Recommendation Engine. - Database: Applied schemas for both services using Flyway. 05/11/2025 05/11/2025 https://flywaydb.org/ 5 - Program Service: Built the User Enrollment API. - Shared Security: Integrated a reusable JWT authentication filter for both services. 06/11/2025 06/11/2025 https://spring.io/guides/gs/securing-web/ 6 - Testing: Used Postman to test the Assessment \u0026amp; Enrollment flow of the Program Service. - Review: Code review of both project structures, ensuring consistency. 07/11/2025 07/11/2025 ‚Äî Week 9 Outcomes Successfully scaffolded both services: Program Service and Chat Service. Completed Database Schema implementation for both services in PostgreSQL, managed by Flyway. Program Service: A functional Assessment \u0026amp; Recommendation system is operational, allowing user classification and program suggestions. Security: A JWT security layer has been integrated and is ready to protect future APIs. Key Learnings:\nMicroservices Architecture: Understood how to set up and manage multiple services within the same system. DB Schema Management: Using Flyway makes managing and deploying database changes safe and automated. Reusability: Designing shared components (like the security layer) that can be applied across multiple services to avoid code duplication. "},{"uri":"https://masterltb.github.io/profile/5-workshop/5.10-cleanup/","title":"5.10 Cleanup &amp; Cost Optimization","tags":[],"description":"","content":"Module 10: Cleanup \u0026amp; Cost Optimization Module Objectives Identify unused/underutilized resources Delete test resources Optimize costs Archive important data Back up before deletion Document lessons learned Part 1: Resource Inventory \u0026amp; Assessment Current AWS Resources List all resources from the AWS Console:\nLambda Functions:\nGo to the Lambda console List functions in each region (us-east-1, ap-southeast-1) Note: Function names, creation dates, memory allocation API Gateways:\nGo to the API Gateway console List all REST APIs in ap-southeast-1 Note: API names, deployment status EC2 Database Instances:\nGo to the EC2 console List all instances in ap-southeast-1 Filter for database instances (DB-PG, DB-Mongo) Note: Instance IDs, instance types, IPs, creation dates S3 Buckets:\nGo to the S3 console List all buckets Note: Bucket names, creation dates, storage used CloudFront Distributions:\nGo to the CloudFront console List all distributions Note: Domain names, distribution IDs VPC Resources:\nGo to the VPC console List all VPCs in ap-southeast-1 Note: VPC IDs, CIDR ranges Create an inventory spreadsheet:\nResource name \u0026amp; type Region Creation date Current usage Estimated monthly cost Part 2: Identify Unused Resources Check Resource Usage Lambda Functions To check Lambda invocations:\nGo to the CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; ‚Üí \u0026ldquo;Lambda\u0026rdquo; Select each function Choose the metric: \u0026ldquo;Invocations\u0026rdquo; Set the time range: Last 7 days Check if Sum = 0 (unused function) If there are no invocations in the last 7 days, it\u0026rsquo;s an unused function (consider deletion).\nAPI Gateways To check the API request count:\nGo to the CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; ‚Üí \u0026ldquo;API Gateway\u0026rdquo; Select your API Choose the metric: \u0026ldquo;Count\u0026rdquo; Set the time range: Last 30 days Check if Sum = 0 (unused API) S3 Buckets To check bucket sizes:\nGo to the S3 console Click on each bucket Go to the \u0026ldquo;Storage\u0026rdquo; tab See the \u0026ldquo;Storage used\u0026rdquo; value Review the storage class (Standard, Infrequent Access, Glacier) Consider moving old objects to cheaper storage classes S3 storage class pricing:\nStandard: $0.023/GB/month Infrequent Access: $0.0125/GB/month Glacier: $0.004/GB/month CloudFront To check the cache hit ratio:\nGo to the CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; ‚Üí \u0026ldquo;CloudFront\u0026rdquo; Select your distribution Choose the metric: \u0026ldquo;CacheHitRate\u0026rdquo; Set the time range: Last 30 days If the cache hit ratio is \u0026lt; 50%, it may need optimization. EC2 Database Instances To check CPU \u0026amp; memory usage:\nGo to the CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; ‚Üí \u0026ldquo;EC2\u0026rdquo; Select your database instance (DB-PG or DB-Mongo) Choose the metric: \u0026ldquo;CPUUtilization\u0026rdquo; Set the time range: Last 30 days Check the Average and Maximum values If the CPU is \u0026lt; 10% consistently, you may be able to downsize the instance type (saving money on EC2).\nPart 3: Cost Optimization Strategies 1. Right-Sizing EC2 Database Instances Current: t4g.small EC2 instances (PostgreSQL + MongoDB) Cost: ~$30-40/month per instance\nOptions:\nt4g.nano: ~$3-5/month (for test/dev) t4g.micro: ~$8-10/month (for light production) t4g.small: Keep as-is (recommended for production) Check: If EC2 CPU is \u0026lt; 10% on average, downsize to save money.\n2. Reserve Capacity (if usage is stable) For production, consider AWS EC2 Reserved Instances:\n1-year: ~30% discount 3-year: ~50% discount To purchase reserved EC2 instances:\nGo to the EC2 console Click \u0026ldquo;Reserved Instances\u0026rdquo; (left menu) Click \u0026ldquo;Purchase Reserved Instances\u0026rdquo; Configure: Instance type: t4g.small Term length: 1-year or 3-year Click \u0026ldquo;Purchase\u0026rdquo; 3. Optimize Data Transfer Costs:\nS3 to CloudFront: Free S3 to the Internet: $0.09/GB S3 to Lambda (same region): Free Recommendation: Keep CloudFront caching enabled.\n4. Lambda Optimization Current: 256 MB average Cost: ~$0.0000002 per invocation\nIf the invocation rate is high:\nUse Lambda provisioned concurrency: Higher cost but predictable Monitor: Check if a memory increase helps reduce the duration (saves cost) 5. Database Optimization Recommendations:\nEnable automated backups (already done) Set up read replicas if you\u0026rsquo;re scaling reads (cost: ~50% of the main instance) Archive old logs (CloudWatch retention is 30 days by default) 6. CloudFront Optimization If the cache hit ratio is \u0026lt; 50%:\nIncrease the TTL for static assets Add more cache behaviors Use cache policies with parameters Part 4: Backup \u0026amp; Archive Step 1: Back up the EC2 Databases To back up PostgreSQL and MongoDB on EC2:\nPostgreSQL (DB-PG: 172.0.8.55):\nSSH into the EC2 instance Create a backup: pg_dump smokingcessation \u0026gt; backup_$(date +%Y%m%d).sql Compress it: gzip backup_*.sql MongoDB (DB-Mongo: 172.0.8.124):\nSSH into the EC2 instance Create a backup: mongodump --db smokingcessation --out backup_$(date +%Y%m%d) Compress it: tar czf backup_*.tar backup_* Step 2: Upload the Database Backups to S3 To export the database backups for archival:\nSSH into the database EC2 instance Upload to S3: Via the AWS CLI (if configured): aws s3 sync /backups s3://smoking-cessation-backups/ Or manually download and upload via the S3 console Step 3: Archive S3 Data For old data (\u0026gt; 90 days), set up lifecycle policies:\nGo to the S3 console Click on the bucket name (e.g., \u0026ldquo;leaflungs-images\u0026rdquo;) Go to the \u0026ldquo;Management\u0026rdquo; tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Configure: Name: \u0026ldquo;archive-old-data\u0026rdquo; Filter: Prefix \u0026ldquo;chat/\u0026rdquo; Transitions: Move to Glacier after 90 days Expiration: Delete after 365 days Click \u0026ldquo;Create rule\u0026rdquo; Part 5: Test Resource Cleanup (Non-Production) Step 1: Delete Test Lambda Functions If any test functions exist:\nGo to the Lambda console Click on the test function name Click \u0026ldquo;Actions\u0026rdquo; ‚Üí \u0026ldquo;Delete\u0026rdquo; Type the function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Step 2: Delete an Unused API Gateway If you have multiple APIs for testing:\nGo to the API Gateway console Click on the API name Click \u0026ldquo;Actions\u0026rdquo; ‚Üí \u0026ldquo;Delete API\u0026rdquo; Confirm the deletion Step 3: Delete Empty S3 Buckets To delete a bucket:\nGo to the S3 console Click on the bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once it\u0026rsquo;s empty, click the \u0026ldquo;Delete\u0026rdquo; button Type the bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Step 4: Delete an Unused CloudFront Distribution To delete a CloudFront distribution:\nGo to the CloudFront console Click on the distribution Click \u0026ldquo;Disable\u0026rdquo; (if it\u0026rsquo;s enabled) Wait 15 minutes for propagation Once the status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm the deletion Part 6: Delete Production Resources (if shutting down) WARNING: This is destructive and cannot be undone!\nBackup Checklist Before Deletion PostgreSQL data backed up (pg_dump) MongoDB data backed up (mongodump) Database backups uploaded to S3 S3 data backed up externally (if needed) CloudTrail logs reviewed \u0026amp; archived Code backed up to GitHub DNS records updated (if redirecting) Team notified Step 1: Delete the EC2 Database Instances To delete the database EC2 instances:\nGo to the EC2 console Click \u0026ldquo;Instances\u0026rdquo; Select a database instance (DB-PG or DB-Mongo) Click \u0026ldquo;Instance State\u0026rdquo; ‚Üí \u0026ldquo;Terminate\u0026rdquo; Confirm the termination Wait for the instance to terminate Verify the EBS volumes are deleted (optional: create snapshots first if needed) Repeat for the second database instance Step 2: Delete the Lambda Functions To delete each Lambda function:\nGo to the Lambda console Click on the function name Click \u0026ldquo;Actions\u0026rdquo; ‚Üí \u0026ldquo;Delete\u0026rdquo; Type the function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Repeat for each function Step 3: Delete the API Gateways To delete each API Gateway:\nGo to the API Gateway console Click on the API name (e.g., \u0026ldquo;LeafLungs-UserInfo-API\u0026rdquo;) Click \u0026ldquo;Actions\u0026rdquo; ‚Üí \u0026ldquo;Delete API\u0026rdquo; Confirm the deletion Repeat for the second API (leaflungs-chat-api) Step 4: Delete the Cognito User Pool To delete the Cognito User Pool:\nGo to the Cognito console Click \u0026ldquo;User pools\u0026rdquo; Click on your user pool Click \u0026ldquo;Delete user pool\u0026rdquo; (bottom right) Type the user pool name to confirm Click \u0026ldquo;Delete\u0026rdquo; Step 5: Delete the S3 Buckets (and their contents) To delete each S3 bucket:\nGo to the S3 console For each bucket (leaflungs-frontend-new, leaflungs-images, leaflungs-images-sg): Click on the bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once it\u0026rsquo;s empty, click the \u0026ldquo;Delete\u0026rdquo; button Type the bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Step 6: Delete the CloudFront Distribution To delete the CloudFront distribution:\nGo to the CloudFront console Click on the distribution (if it\u0026rsquo;s not already disabled) If it\u0026rsquo;s enabled, click \u0026ldquo;Disable\u0026rdquo; first Wait 15 minutes for propagation Once the status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm the deletion Part 7: Cost Analysis \u0026amp; Reporting Monthly Cost Breakdown Typical costs for this architecture:\nService Usage Cost Lambda 100K invocations/month ~$2 API Gateway 10M requests/month ~$50 EC2 (2x DB instances) 2 x t4g.small for PostgreSQL + MongoDB ~$60-70 EC2 (2x App instances) 2 x t4g.small for applications ~$60-70 S3 100 GB storage ~$2 CloudFront 1 TB/month transfer ~$85 Cognito 1K users ~$0 (free tier) NAT Gateway 10 GB transfer ~$5 Total ~$300-350/month Cost optimization opportunities:\nUse t4g.nano/micro for light databases: Saves ~$20-30/month Cache more aggressively: Saves ~$30/month Reserved EC2 instances: Saves ~$60-80/month Total savings: ~$110-140/month (35-40% reduction) AWS Cost Explorer AWS Console ‚Üí Billing ‚Üí Cost Explorer View costs by: Service Linked account Region Usage type Set up cost anomaly detection Review trends Part 8: Documentation \u0026amp; Lessons Learned Create a Post-Mortem Document # Workshop Completion Report ## Architecture Summary - Services deployed: Lambda, API Gateway, EC2 (PostgreSQL + MongoDB), S3, CloudFront, Cognito, NLB - Regions: us-east-1 (Cognito), ap-southeast-1 (main) - Total users: 1000+ - Monthly costs: $300-350 ## Key Learnings 1. Regional considerations - Cognito must be in us-east-1 for CloudFront - Main services are in ap-southeast-1 for latency 2. Security best practices implemented - VPC isolation - Security group restrictions - IAM least-privilege - Secrets Manager for credentials 3. Cost optimization - CloudFront caching is important - EC2 instances can be right-sized or use Reserved Instances - Reserved instances save 30-50% 4. Monitoring is critical - CloudWatch alarms prevented many issues - X-Ray helped debug performance ## Recommendations for the Next Phase 1. Set up automated backups for the EC2 databases (pg_dump/mongodump cronjobs) 2. Implement CI/CD for automated deployments 3. Add a comprehensive test suite 4. Set up an on-call rotation \u0026amp; runbooks 5. Schedule quarterly cost reviews Checklist - Cleanup Decision Before the final cleanup, verify:\nAll data is backed up Snapshots are created CloudTrail logs are archived Code is pushed to GitHub Cost analysis is completed The team is trained on the infrastructure Documentation is complete Stakeholders have approved A DNS cutover plan exists (if applicable) A rollback plan is documented Final Recommendations Keep the infrastructure running (you\u0026rsquo;ve built it correctly) Implement automated scaling if needed Set up a CI/CD pipeline for updates Add comprehensive testing Plan quarterly cost reviews Train the team on operational procedures Consider a disaster recovery plan Summary \u0026amp; Next Steps Congratulations! You\u0026rsquo;ve successfully:\n‚úì Verified/set up Cognito authentication ‚úì Verified/set up Lambda functions ‚úì Verified/set up API Gateways ‚úì Verified the EC2 databases (PostgreSQL + MongoDB) ‚úì Verified S3 \u0026amp; CloudFront ‚úì Verified the VPC \u0026amp; Security ‚úì Implemented monitoring \u0026amp; logging ‚úì Optimized costs This infrastructure can support:\n1000+ concurrent users 100K+ requests/day Highly available (multi-AZ capable) Scalable (auto-scale Lambda, upgrade EC2 instance types) Secure (VPC isolation, encryption, IAM) Observable (comprehensive logging \u0026amp; monitoring) What You Will Achieve After Module 10:\nResource inventory \u0026amp; usage analyzed Cost optimization strategies identified Unused resources identified for cleanup Backup procedures implemented A cost reduction plan created (up to 36% savings possible) A post-mortem \u0026amp; lessons learned documented Recommendations for the next phase The workshop is complete \u0026amp; the infrastructure is production-ready "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.10-week10/","title":"Worklog Week 10","tags":[],"description":"","content":"Week 10 Objectives Program Service: Implement core logic (Daily Routine, Streak Tracking, Smoke Events). Chat Service: Prepare the Data Access Layer. Tasks for this week Day Task Start Date Completion Date Reference 2 - Program Service: Implemented logic to generate 4 daily steps for users. - Chat Service: Created ChatRoomRepository and MessageRepository interfaces. 10/11/2025 10/11/2025 ‚Äî 3 - Program Service: Built APIs for step completion and implemented the StreakService. - Chat Service: Wrote custom JPQL queries to find messages by chat room with pagination. 11/11/2025 11/11/2025 ‚Äî 4 - Program Service: Developed the \u0026ldquo;Smoke Event\u0026rdquo; trigger and \u0026ldquo;Soft Reset\u0026rdquo; logic (Status: PENDING_RECOVERY). 12/11/2025 12/11/2025 ‚Äî 5 - Program Service: Implemented the recovery logic: assign a \u0026ldquo;Recovery Quiz\u0026rdquo; and handle the outcome (max 3 attempts). 13/11/2025 13/11/2025 ‚Äî 6 - Program Service: Wrote Unit Tests for StreakService and performed integration testing for the entire flow. 14/11/2025 14/11/2025 https://junit.org/junit5/ Week 10 Outcomes Program Service: The Daily Routine engine and Streak System are fully functional. The Recovery Mechanism successfully handles \u0026ldquo;Smoke Events\u0026rdquo; in a humane way. Chat Service: The Data Access Layer (Repository) has been defined and is ready for implementation in the next week. Key Learnings:\nComplex State Management: Handling user states (Active, Pending Recovery) requires a robust state machine logic. Focusing on One Service: Dedicating the majority of time to a complex service ensures quality and progress, while still allowing for preparatory work on other services. JPQL for Custom Queries: Using JPQL is a powerful way to write complex queries that are not automatically supported by Spring Data JPA. "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.11-week11/","title":"Worklog Week 11","tags":[],"description":"","content":"Week 11 Objectives Chat Service: Implement core APIs (get chat rooms, message history). Program Service: Refine business logic (Slip/Relapse) and add administrative features. Tasks for this week Day Task Start Date Completion Date Reference 2 - Chat Service: Implemented ChatController and the GET /api/v1/chat-rooms/me API to get a user\u0026rsquo;s chat rooms. 17/11/2025 17/11/2025 ‚Äî 3 - Chat Service: Implemented the GET /api/v1/chat-rooms/{roomId}/messages API with pagination and sorting. - Chat Service: Implemented the internal POST /internal/api/v1/chat-rooms API. 18/11/2025 18/11/2025 ‚Äî 4 - Program Service: Implemented the logic to differentiate between Slip (immediate recovery) and Relapse (hard reset). - Program Service: Added Flyway to manage schema changes. 19/11/2025 19/11/2025 https://flywaydb.org/ 5 - Program Service: Built Admin APIs (CRUD) for Quiz Templates. - Program Service: Optimized the reset counter logic (max 3 recoveries). 20/11/2025 20/11/2025 ‚Äî 6 - Program Service: Developed the @Scheduled job for Weekly Assessments. - Testing: Used Postman to test the new Chat Service APIs. 21/11/2025 21/11/2025 https://spring.io/guides/gs/scheduling-tasks/ Week 11 Outcomes Chat Service: Core APIs for retrieving chat rooms and message history are functional. The internal API for creating chat rooms is ready for other services to call. Program Service: The Slip vs Relapse logic is complete, allowing the system to handle failure scenarios flexibly. The Admin Module allows for independent management of Quiz content. The Weekly Assessment system is automated. Key Learnings:\nAPI Pagination Design: The importance of implementing effective pagination for APIs that return large lists (message history). Scheduling: Using Spring Scheduler is an efficient way to run periodic jobs without complex configurations. Task Switching: Shifting focus between services within a sprint/week helps maintain balanced progress for the entire system. "},{"uri":"https://masterltb.github.io/profile/1-worklog/1.12-week12/","title":"Worklog Week 12","tags":[],"description":"","content":"Week 12 Objectives System-Wide Quality Assurance: Conduct Unit \u0026amp; Integration Testing for both Program Service and Chat Service. Performance Optimization: Analyze and optimize PostgreSQL queries across both services. Finalization \u0026amp; Handover: Complete API documentation and prepare for system handover. Tasks for this week Day Task Start Date Completion Date Reference 2 - Program Service: Wrote Unit Tests for StreakService and QuizService. - Chat Service: Wrote Unit Tests for ChatService to verify message retrieval logic. 24/11/2025 24/11/2025 https://site.mockito.org/ 3 - Program Service: Wrote Integration Tests for the \u0026ldquo;Smoke Event -\u0026gt; Recovery\u0026rdquo; flow. - Chat Service: Wrote Integration Tests for the \u0026ldquo;Get Chat Rooms -\u0026gt; Get History\u0026rdquo; flow. 25/11/2025 25/11/2025 ‚Äî 4 - Optimization: Used EXPLAIN ANALYZE to analyze and add indexes to tables in both services, especially on foreign keys and columns used for sorting. 26/11/2025 26/11/2025 https://www.postgresql.org/docs/current/using-explain.html 5 - Documentation: Updated api-docs.md with complete and accurate details for all APIs of both services. - Reporting: Finalized the internship report, describing the microservices architecture. 27/11/2025 27/11/2025 https://swagger.io/ 6 - Review: Final code cleanup, checked configurations and environment variables. - Presentation: Prepared a demo and presentation of the overall architecture of both services for the mentor. 28/11/2025 28/11/2025 ‚Äî Week 12 Outcomes System Quality: Both services have good test coverage, ensuring the stability and correctness of business flows. Performance Optimized: Query performance for both services has been improved, ready for production load. Complete Documentation: Delivered unified and clear API documentation for the entire system. Completion: Successfully built and delivered a complete microservices backend system. Overall Internship Reflection: Over the last 4 weeks, I have designed and implemented a microservices system from scratch, including a Program Service and a Chat Service. I have applied professional software development principles from design, implementation, testing, and optimization to documentation, and successfully translated complex business requirements into a functional software product.\n"},{"uri":"https://masterltb.github.io/profile/5-workshop/aws_resources_inventory/","title":"","tags":[],"description":"","content":"AWS Resources Inventory - Smoking Cessation Platform C·∫≠p nh·∫≠t: 2025-12-03\nArchitecture Type: HYBRID (EC2 + Lambda + Managed Services) This platform uses a hybrid architecture combining:\nAlways-on EC2 servers for main applications Serverless Lambda for event-driven tasks Managed services for CDN, authentication, load balancing Account Information Account ID: 140570829989 User: AdminUser (IAM) Regions: us-east-1 (Cognito), ap-southeast-1 (main infrastructure)\nS3 Buckets Bucket Name Region Created Purpose leaflungs-frontend-new us-east-1 2025-11-24 Frontend hosting leaflungs-images ap-southeast-1 2025-11-25 Chat/message images leaflungs-images-sg ap-southeast-1 2025-11-30 Image storage Cognito User Pool:\nID: us-east-1_dskUsnKt3 Name: leaflungs-user-pool Region: us-east-1 Created: 2025-11-24 Last Modified: 2025-11-25 EC2 Instances (Hybrid Architecture) ap-southeast-1 (4 instances - t4g.small) Database Tier (leaflungs-db-sg):\nInstance ID Name IP Address Type Status Created i-0d82a626b99a2fecd DB-PG 172.0.8.55 t4g.small running 2025-11-30 i-0374ff6972fd306fe DB-Mongo 172.0.8.124 t4g.small running 2025-12-02 Application Tier (leaflungs-backend-sg):\nInstance ID Name IP Address Type Status Created i-01dd1a4b2b8b4a41f user-cessation 172.0.3.240 t4g.small running 2025-11-30 i-059fae7766eb52ae3 social-media 172.0.3.236 t4g.small running 2025-12-02 Lambda Functions (Event-driven) us-east-1 (1 function) Function Name Runtime Last Modified Role CognitoPostConfirmationTrigger nodejs20.x 2025-11-24 CognitoPostConfirmationLambdaRole ap-southeast-1 (4 functions) Function Name Runtime Last Modified Role Purpose AdminManageCoachesFunction nodejs20.x 2025-12-01 AdminOperationsLambdaRole Admin operations PaymentFunction nodejs24.x 2025-11-30 ? Payment processing leaflungs-websocket-authorizer nodejs20.x 2025-12-02 ? WebSocket auth image-upload-lambda nodejs20.x 2025-11-30 ImageUploadLambdaRole File uploads API Gateways (ap-southeast-1) API Name ID Created Type LeafLungs-UserInfo-API v7agf76rrh 2025-11-24 REST API leaflungs-chat-api vuds39de1b 2025-12-02 REST API + WebSocket Load Balancers (ap-southeast-1) Name Type Status Purpose leaflungs-userinfo-nlb Network active WebSocket chat endpoint VPC \u0026amp; Networking (ap-southeast-1) VPC VPC ID: vpc-046dc916dde2fb93f Name: project-bundau-milo CIDR: 172.0.0.0/18 Security Groups Group ID Name Purpose sg-012293e2687464913 launch-wizard-1 Default sg-0cf34158cb7f5440b leaflungs-backend-sg Backend Lambda sg-0adb5d7ea1fe0f6bb leaflungs-nlb-sg NLB (WebSocket) sg-027ef04aa3c769ecf leaflungs-db-sg EC2 Database Instances sg-0d2dbd7d32700d8c8 default Default EC2 Database Servers Status: DEPLOYED\nInstance ID Name Type IP Database Status i-01dd1a4b2b8b4a41f DB-PG t4g.small 172.0.8.55 PostgreSQL Running i-012ab3c4d5e6f7g8h0 DB-Mongo t4g.small 172.0.8.124 MongoDB Running CloudFront Distribution ID Domain Status E1NREZDKTJH6Y9 d2yo2hr161ib8h.cloudfront.net Deployed IAM Roles Role Name Created AdminOperationsLambdaRole 2025-12-01 AWSServiceRoleForAPIGateway 2025-11-23 CognitoPostConfirmationLambdaRole 2025-11-24 ImageUploadLambdaRole 2025-11-25 Environment Variables Status From .env file:\nCOGNITO_USER_POOL_ID=us-east-1_dskUsnKt3 ‚úì EXISTS COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 ‚úì EXISTS COGNITO_REGION=us-east-1 ‚úì S3_BUCKET_NAME=leaflungs-frontend-new ‚úì EXISTS CLOUDFRONT_DISTRIBUTION_ID=E1NREZDKTJH6Y9 ‚úì EXISTS CLOUDFRONT_DOMAIN=d2yo2hr161ib8h.cloudfront.net ‚úì VITE_API_GATEWAY_URL=https://v7agf76rrh.execute-api.ap-southeast-1.amazonaws.com/prod ‚úì EXISTS VITE_CHAT_API_URL=https://vuds39de1b.execute-api.ap-southeast-1.amazonaws.com/prod ‚úì EXISTS VITE_CHAT_WS_URL=https://leaflungs-userinfo-nlb-3c1d58c7a3d41477.elb.ap-southeast-1.amazonaws.com/ws ‚úì EXISTS Outstanding Items Needed EC2 Database configuration verification - DEPLOYED Verify PaymentFunction Lambda role - UNKNOWN Verify leaflungs-websocket-authorizer Lambda role - UNKNOWN Verify API Gateway resources \u0026amp; methods Verify WebSocket integration Verify Cognito client configuration Database schema \u0026amp; migration scripts - CHECK IF EXISTS Next Steps Module 3: Verify Cognito configuration Module 4: Verify Lambda functions \u0026amp; roles Module 5: Verify API Gateway setup Module 6: Verify EC2 Database Servers (PostgreSQL + MongoDB) Module 7: Verify S3 \u0026amp; CloudFront Module 8: Verify VPC \u0026amp; Security Groups Module 9: Setup Monitoring (CloudWatch, CloudTrail) Module 10: Cost optimization \u0026amp; cleanup Notes Mixed regions: Cognito in us-east-1, most services in ap-southeast-1 WebSocket via NLB (not API Gateway WebSocket) All major resources already created - workshop will focus on verification \u0026amp; documentation "},{"uri":"https://masterltb.github.io/profile/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://masterltb.github.io/profile/tags/","title":"Tags","tags":[],"description":"","content":""}]