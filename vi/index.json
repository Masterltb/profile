[{"uri":"https://masterltb.github.io/profile/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Amazon hoan nghênh Sắc lệnh Hành pháp của Nhà Trắng và khẳng định cam kết đối với việc chăm sóc và nghiên cứu ung thư nhi bởi Dr. Rowland Illing | on 30 SEP 2025 | in Sức khỏe, Công nghiệp\nTheo Tổ chức Ung thư Trẻ em Hoa Kỳ, mỗi ngày tại Hoa Kỳ có 42 gia đình nhận được tin con mình bị chẩn đoán mắc bệnh ung thư. Quá thường xuyên, những chẩn đoán này là giai đoạn cuối—và trẻ em có rất ít lựa chọn điều trị, nếu có. Chính những bác sĩ lâm sàng đang điều trị cho trẻ em bị ung thư cũng là những nhà khoa học đang cố gắng tìm ra phương pháp chữa trị, họ thường bị giới hạn bởi số lượng bệnh nhân có thể khám và dữ liệu có sẵn từ các trường hợp tương tự trên khắp thế giới.\nTháng Nâng cao Nhận thức về Ung thư ở Trẻ em làm nổi bật những căn bệnh này, và mang đến cho toàn thể cộng đồng—bao gồm bệnh nhân, người chăm sóc, bác sĩ lâm sàng, nhà khoa học, ngành công nghiệp, và chính phủ—một cơ hội để tạo ra sự khác biệt. Hôm nay đánh dấu một cột mốc quan trọng khác trong nỗ lực chống lại bệnh ung thư ở trẻ em với một sắc lệnh hành pháp (EO) mới từ Nhà Trắng nhằm mục đích liên kết dữ liệu với các hệ thống trí tuệ nhân tạo (AI) tiên tiến nhất để xác định nhanh chóng hơn các lựa chọn điều trị mới và—cuối cùng là—cứu sống và cải thiện cuộc sống của những đứa trẻ được chẩn đoán mắc bệnh ung thư.\nSắc lệnh EO sẽ thúc đẩy việc sử dụng AI để cải thiện các thử nghiệm lâm sàng nhi khoa, hoạt động chăm sóc bệnh nhân, nghiên cứu ung thư, và phát hiện thuốc mới. Việc hỗ trợ và áp dụng các tiêu chuẩn dữ liệu mạnh mẽ cho khả năng tương tác là cực kỳ quan trọng trong việc đảm bảo rằng các bác sĩ lâm sàng, nhà nghiên cứu, biopharma, và bệnh nhân có thể truy cập đúng dữ liệu vào đúng thời điểm cho đúng đứa trẻ khi mỗi giây đều quý giá.\nSắc lệnh EO ngày hôm nay khởi động các sáng kiến chính sách mới nhằm khai thác những tiến bộ trong khả năng tương tác dữ liệu y tế kết hợp với các công nghệ AI mới để tìm ra các lựa chọn điều trị tốt hơn. Như một bước tiếp theo, các nhà hoạch định chính sách liên bang sẽ phát triển những thay đổi về chính sách để trẻ em, gia đình của chúng, và các bác sĩ lâm sàng điều trị cho chúng có thể sử dụng AI một cách an toàn trên dữ liệu cụ thể của bệnh nhân để tìm ra phương pháp chữa trị.\nAmazon hoan nghênh các hành động chính sách nhằm tận dụng AI và khả năng tương tác dữ liệu để tạo ra những đột phá khoa học sẽ cứu sống nhiều người, đồng thời mang lại hy vọng cho trẻ em và gia đình của chúng. Chúng tôi sẵn sàng đóng góp chuyên môn của mình cho các cơ quan chính phủ đối với những bằng chứng về giá trị này mà sử dụng các dịch vụ AWS cho khả năng tương tác dữ liệu y tế, bảo mật, chia sẻ dữ liệu bảo toàn quyền riêng tư, và các ứng dụng của AI để chống lại bệnh ung thư.\nMỗi giây đều quý giá, và mỗi thành phần dữ liệu đều quan trọng Trong nhiều năm, AWS đã hỗ trợ các nỗ lực chuyên sâu về dữ liệu trong nghiên cứu ung thư nhi khoa, bao gồm việc lưu trữ Kids First Data Resource Center, một cổng thông tin cho khám phá khoa học với dữ liệu di truyền và lâm sàng mạnh mẽ dành cho ung thư nhi khoa và các rối loạn bẩm sinh. Tại AWS Washington DC Summit năm 2024, Amazon đã nhấn mạnh sự hỗ trợ dành cho Children’s Brain Tumor Network (CBTN). Liên minh gồm 35 trung tâm nhi khoa này tập trung vào việc khai thác dữ liệu phân tử, hình ảnh, lâm sàng và bệnh lý để thúc đẩy các real world observational trials bằng cách hợp nhất dữ liệu và AI. Thông qua một nền tảng được xây dựng trên AWS, các nhà khoa học và bác sĩ lâm sàng đang điều trị cho bệnh nhân có thể chia sẻ insights và dữ liệu theo thời gian thực với nhau, để tăng tốc time to insights cho trẻ em và gia đình của họ, những người vừa nhận chẩn đoán ung thư mới. Để tăng tốc hơn nữa các sáng kiến AI cho sức khỏe trẻ em, Amazon đã trao 1 triệu USD hỗ trợ từ thiện cho mỗi đơn vị gồm CBTN, Nationwide Children’s Hospital và Children’s National Hospital thông qua chương trình Children’s Health Innovation Award (CHIA) trị giá 10 triệu USD.\nMô hình hợp tác chia sẻ dữ liệu do CBTN thiết lập đã mở rộng hơn nữa với khoản tài trợ 10 triệu USD từ Advanced Research Projects Agency-Health (ARPA-H) cho cơ sở hạ tầng dữ liệu nhi khoa RADIANT trên AWS. Nền tảng mở rộng này đã cho thấy rằng việc chia sẻ an toàn, theo thời gian thực dữ liệu EHR thông qua Bulk FHIR APIs vào AWS HealthLake là khả thi đối với trẻ em mắc ung thư nhi khoa. AWS tự hào là đối tác công nghiệp chủ chốt cho RADIANT và mô hình mới về interoperability và trao đổi dữ liệu an toàn mà nó đã mở ra để cải thiện việc nghiên cứu và chăm sóc.\nXây dựng lực lượng lao động AI về ung thư nhi cho tương lai Việc xây dựng cơ sở hạ tầng công nghệ đóng vai trò là một nền tảng thiết yếu, nhưng chỉ khi các bác sĩ lâm sàng và nhà khoa học có những kỹ năng họ cần để tận dụng dữ liệu và các công cụ AI nhằm tìm ra phương pháp chữa trị. Để đẩy nhanh hơn nữa những kỹ năng công nghệ này, Amazon đã hợp tác với chương trình NIH Kids First và CBTN để giúp thêm nhiều nhà nghiên cứu, bác sĩ lâm sàng, và học viên có được kinh nghiệm thực hành với dữ liệu trên đám mây và các công cụ AI, bao gồm cả tại Hội nghị thượng đỉnh CBTN, nơi Trung tâm Kỹ năng AWS đã tổ chức các buổi hội thảo để giúp nâng cao kỹ năng cho thế hệ các nhà khoa học tiếp theo về AI và đám mây.\nHy vọng ở phía chân trời Đối với trẻ em và các gia đình đối mặt với chẩn đoán ung thư, việc tìm ra các lựa chọn điều trị hiệu quả là cực kỳ quan trọng. Bằng cách kết hợp các khả năng của AI và khả năng tương tác dữ liệu y tế, các nhà cung cấp dịch vụ chăm sóc sức khỏe có thể xác định được các khả năng điều trị bổ sung mà có thể giúp hỗ trợ việc chăm sóc bệnh nhân. Điều này bao gồm việc thúc đẩy phát hiện dấu ấn sinh học ung thư thông qua Amazon Bedrock Agents hoặc sử dụng AWS Clean Rooms để cho phép nhiều nhà nghiên cứu truy cập vào dữ liệu mà không cho phép chia sẻ hoặc sao chép dữ liệu gốc.\nVới sự kiên cường của những đứa trẻ đang chiến đấu với bệnh ung thư, sự khéo léo được mang lại bởi những bộ óc vĩ đại nhất của khoa học, và Sắc lệnh EO ngày hôm nay có thể thúc đẩy những thay đổi chính sách đầy ý nghĩa, những bệnh nhân và gia đình trong tương lai nhận được chẩn đoán ung thư nhi không thể tưởng tượng được sẽ sớm có thêm hy vọng và sự lạc quan.\nThông báo ngày hôm nay phản ánh bước tiếp theo hướng tới việc kết hợp dữ liệu và AI để cải thiện sức khỏe của trẻ em. Amazon tự hào được hợp tác với bệnh nhân, gia đình của họ, các bác sĩ lâm sàng, và các nhà khoa học để giúp dẫn đường.\nChúng tôi khuyến khích bạn truy cập aws.amazon.com/healthcare để tìm hiểu thêm về cách Amazon có thể trao quyền cho các sáng kiến nghiên cứu ung thư nhi.\nDr. Rowland Illing\nDr. Rowland Illing serves as Chief Medical Officer and Director of Healthcare and Life Sciences for Amazon Web Services (AWS). In this role, he oversees strategy and engagement for healthcare customers worldwide, encompassing providers, payors, and health technology companies. His work centers on leveraging technologies such as artificial intelligence to drive innovation in health equity and sustainability, while also enabling healthcare organizations to optimize their data utilization for improved efficiency and patient outcomes. An Academic Interventional Radiologist by training, Dr. Illing was previously Director of the Interventional Oncology Service at University College Hospitals London. He holds positions as Honorary Associate Professor at University College London and Visiting Professor of Informatics and Imaging at Oxford University. His professional affiliations include membership in the Royal College of Surgeons of England, fellowship in the Royal College of Radiologists, senior fellowship in the UK’s Faculty of Medical Leadership and Management, and membership in the Leadership Consortium of the US National Academy of Medicine. Dr. Illing maintains an active presence in academia through ongoing presentations and publications in the field.\n"},{"uri":"https://masterltb.github.io/profile/vi/4-eventparticipated/4.1-event1/","title":"AWS Cloud Day Vietnam - AI Edition 2025","tags":[],"description":"","content":"AWS Cloud Day Vietnam - AI Edition 2025 - Ngày: 18 tháng 9, 2025 - Địa điểm: Số 2 đường Hải Triều, Phường Bến Nghé, Quận 1, TP. Hồ Chí Minh\nTổng quan sự kiện Một sự kiện quan trọng dành cho cộng đồng công nghệ và doanh nghiệp Việt Nam, tập trung vào việc thúc đẩy chuyển đổi số thông qua sự hội tụ của Điện toán đám mây và Trí tuệ nhân tạo.\nMục tiêu chính:\nPhổ cập AI Tạo sinh: Đưa GenAI từ khái niệm đến ứng dụng thực tế, có nhận thức theo ngữ cảnh cho doanh nghiệp. Gắn kết Kinh doanh \u0026amp; CNTT: Thu hẹp khoảng cách giữa mục tiêu kinh doanh và CNTT, đặc biệt trong lĩnh vực Dịch vụ Tài chính. Thúc đẩy Hiện đại hóa: Cung cấp lộ trình hiện đại hóa theo đặc thù ngành để di chuyển và phát triển ứng dụng cloud-native. Tăng cường Bảo mật: Thúc đẩy tư duy \u0026ldquo;bảo mật ngay từ thiết kế\u0026rdquo; trong toàn bộ vòng đời ứng dụng. Bài học và Erkenntnisse chính Dữ liệu là Yếu tố Tạo nên Sự khác biệt: Một chiến lược dữ liệu toàn diện là điều kiện tiên quyết cho sự thành công của AI Tạo sinh. Hiện đại hóa là một Hành trình Liên tục: Mục tiêu không chỉ là di chuyển mà là \u0026ldquo;Di chuyển để Vận hành\u0026rdquo; và đổi mới không ngừng. Công nghệ phải do Kinh doanh dẫn dắt: Các sáng kiến công nghệ phải được thúc đẩy bởi các kết quả kinh doanh rõ ràng. Bảo mật là Trách nhiệm của Mọi người: Bảo mật phải được tích hợp ngay từ dòng mã đầu tiên. Ứng dụng vào Công việc Kiểm tra Mức độ sẵn sàng của Dữ liệu: Đánh giá chiến lược dữ liệu hiện tại của chúng tôi để đảm bảo nó có thể hỗ trợ các sáng kiến GenAI trong tương lai. Thử nghiệm GenAI trong DevOps: Thử nghiệm với việc tạo mã do AI điều khiển và kiểm thử tự động để cải thiện tốc độ phát triển. Đối chiếu các Nỗ lực Hiện đại hóa: Phân tích các nghiên cứu điển hình từ Honda Việt Nam (di chuyển SAP) và Masterise Group (di chuyển VMware) để hoàn thiện lộ trình hiện đại hóa của chúng tôi. Triển khai \u0026ldquo;Bảo mật ở Quy mô lớn\u0026rdquo;: Tích hợp các công cụ bảo mật và các phương pháp hay nhất trong toàn bộ vòng đời phát triển. Hình ảnh sự kiện "},{"uri":"https://masterltb.github.io/profile/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lâm Thanh Bình\nSố điện thoại: 0352668240\nEmail: binhhltse1845@fpt.edu.vn\nTrường: Đại học FPT Hồ Chí Minh\nNgành: Công nghệ thông tin\nLớp: SE184538\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.1-introduction/","title":"5.1 Introduction","tags":[],"description":"","content":"Module 1: Giới Thiệu Hạ Tầng Smoking Cessation Platform Mục tiêu Module Hiểu kiến trúc AWS toàn bộ hệ thống Nắm các thành phần chính của nền tảng Tìm hiểu flow dữ liệu giữa các service Chuẩn bị cho các module tiếp theo Kiến Trúc Hệ Thống Tổng Quát (Hybrid - EC2 + Lambda) Sơ đồ Kiến Trúc AWS Architecture Type: Hybrid (EC2 + Serverless Lambda) Deployment Pattern: EC2 for stateful services, Lambda for event-driven tasks\n[workshop\\assets\\architecture.png]\nCác Thành Phần Chính 1. Frontend Layer (React + Vite) Hosting: S3 + CloudFront\nFeatures:\nResponsive UI cho Web \u0026amp; Mobile Real-time Chat với WebSocket User Authentication (Cognito) Progress Tracking Dashboard Coach Management Interface 2. API Gateway Layer REST API: /api/v1/* endpoints WebSocket: /ws endpoints cho real-time chat\nResponsibilities:\nRequest routing Authentication validation Rate limiting CORS handling 3. Backend Layer (Hybrid: EC2 + Lambda) EC2 Application Servers (Always-on):\nuser-cessation service (Port 8000)\nUser profiles, progress tracking Coaching session management Statistics \u0026amp; analytics social-media service (Port 8000)\nSocial features Notifications Community management Lambda Functions (Event-driven):\nFile Upload Lambda\nHandle image/file uploads to S3 Payment Processing Lambda\nProcess payments \u0026amp; subscriptions Specific Trigger Functions\nWebhooks Scheduled tasks 4. WebSocket \u0026amp; Real-time Layer NLB (Network Load Balancer):\nHandles persistent WebSocket connections Port 443 (HTTPS) Distributes real-time chat traffic Integration with EC2 backend servers 5. Database Layer (EC2-hosted) PostgreSQL Server (DB-PG):\nUser profiles \u0026amp; authentication Progress tracking data Coaching session records Relational data MongoDB Server (DB-Mongo):\nChat message history Social media content Message metadata Flexible schema data 6. Security Layer AWS Cognito: User authentication \u0026amp; authorization IAM Roles: Service-to-service permissions VPC: Network isolation (private subnets for databases) Security Groups: Firewall rules for EC2 \u0026amp; databases SSL/TLS: Data encryption in transit \u0026amp; at rest NLB Security Group: Restricts access to WebSocket port 7. Monitoring \u0026amp; Logging CloudWatch: Logs \u0026amp; Metrics for all services CloudTrail: API audit trail EC2 Instance Monitoring: CPU, memory, disk usage Database Monitoring: Query performance, connections Alarms: Performance \u0026amp; health alerts User Journeys \u0026amp; Data Flow Journey 1: User Registration \u0026amp; Login 1. User đến trang đăng ký ↓ 2. Frontend gửi credentials → API Gateway → Lambda (Auth Service) ↓ 3. Lambda validate \u0026amp; create user trong PostgreSQL (EC2) ↓ 4. AWS Cognito tạo user account ↓ 5. Lambda return access token \u0026amp; refresh token ↓ 6. Frontend lưu token → có quyền truy cập API Journey 2: Real-time Chat 1. User A gửi message ↓ 2. Message được gửi → API Gateway WebSocket endpoint ↓ 3. Lambda (Chat Service) xử lý message ↓ 4. Lưu message vào MongoDB (EC2) ↓ 5. WebSocket broadcast message đến User B (connected) ↓ 6. User B nhận message real-time Journey 3: Progress Tracking 1. User update progress data (e.g., smoke-free days) ↓ 2. Frontend gửi → API Gateway → Lambda (User Service) ↓ 3. Lambda validate \u0026amp; update PostgreSQL (EC2) ↓ 4. Coach nhận notification (thông qua WebSocket) ↓ 5. Dashboard cập nhật real-time Các Công Nghệ \u0026amp; Services Thành Phần Service Chi Tiết Frontend Hosting S3 + CloudFront Static website hosting + CDN Authentication Cognito User authentication \u0026amp; SSO API Management API Gateway REST API routing Compute (Always-on) EC2 (t4g.small) Main application servers Compute (Event-driven) Lambda Specific functions (upload, payment) Real-time NLB + WebSocket WebSocket connections \u0026amp; messaging Database (SQL) EC2 + PostgreSQL User data, relational data Database (NoSQL) EC2 + MongoDB Chat history, social data Storage S3 File uploads \u0026amp; assets Security VPC, Security Groups, IAM Network isolation \u0026amp; access control Monitoring CloudWatch Logs, metrics, alarms CDN CloudFront Content delivery network Các Module Tiếp Theo Module 2: Prerequisites - Chuẩn bị tài khoản \u0026amp; tools Module 3: Setup Cognito - User authentication Module 4: Setup Lambda - Backend functions Module 5: Setup API Gateway - API endpoints Module 6: Verify EC2 Servers \u0026amp; Databases - PostgreSQL + MongoDB on EC2 Module 7: Setup S3 + CloudFront - Frontend hosting Module 8: Setup VPC \u0026amp; Security - Network security Module 9: Monitoring \u0026amp; Logging - System observability Module 10: Cleanup - Xóa resources \u0026amp; cost optimization Checklist Hiểu kiến trúc AWS tổng quát Nắm 6 thành phần chính Hiểu 3 user journeys chính Sẵn sàng cho Module 2 Notes Hệ thống sử dụng Serverless Architecture - không cần quản lý servers Mọi service đều auto-scaling theo demand Pay-as-you-go pricing model Highly available \u0026amp; disaster recovery ready "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS Console, CLI và các dịch vụ cơ bản (VPC, EC2).\nTuần 2: Người dùng/Vai trò IAM, MFA, Cảnh báo thanh toán, Quản lý chi phí.\nTuần 3: Nguyên tắc đặc quyền tối thiểu, Cấu hình EC2 Instance, Chiến lược ngân sách.\nTuần 4: Subnet, Bảng định tuyến, NAT Gateway, NACL và Security Group.\nTuần 5: Khởi chạy instance, AMI tùy chỉnh, Session Manager, Lightsail.\nTuần 6: Cài đặt RDS, Tính sẵn sàng cao với Multi-AZ, Read Replica, Sao lưu.\nTuần 7: Viết kịch bản với AWS CLI v2, Cài đặt môi trường Cloud9.\nTuần 8: Ôn tập Well-Architected Framework và thi.\nTuần 9: Khởi động song song: Dựng khung cho Service Program \u0026amp; Chat, Schema DB, và Lớp bảo mật chung.\nTuần 10: Đi sâu vào Program Service: Triển khai Logic Nhiệm vụ Hàng ngày \u0026amp; Streak.\nTuần 11: Triển khai Chat Service \u0026amp; Tinh chỉnh Program Service.\nTuần 12: Hoàn thiện toàn hệ thống: Kiểm thử Tích hợp cho cả hai Service, Tối ưu hóa, và Tài liệu.\n"},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.1-week1/","title":"Nhật ký Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1 Làm quen môi trường thực tập, kết nối với nhóm/lớp. Hình thành thói quen tự học, hoàn thành chuỗi thử thách để nhận $100 Free Tier. Các công việc thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Gặp gỡ và nắm thông tin các thành viên trong nhóm.\n- Nắm quy trình/biểu mẫu đăng ký tại văn phòng.\n- Hướng dẫn đường vào công ty, mượn thẻ visitor và chỗ gửi xe. 08/09/2025 08/09/2025 https://cloudjourney.awsstudygroup.com/ 3 - Khảo sát tổng quan chương trình (workshop, project, yêu cầu đầu ra).\n- Tạo trang worklog cá nhân và ghi chép hằng ngày. 09/09/2025 09/09/2025 https://workshop-sample.fcjuni.com/1-worklog/ 4 - Tạo AWS Free Tier account.\n- Phân biệt root user và IAM user.\n- Lab: tạo/tắt VPC, khởi tạo/thu hồi EC2. 10/09/2025 10/09/2025 https://aws.amazon.com/profile 5 - Đọc yêu cầu/điều kiện nhận thêm $100 credits và thử thách đầu tiên.\n- Lab: hoàn thành Challenge 1 \u0026amp; 2; thực hành vẽ sơ đồ kiến trúc trên draw.io. 11/09/2025 11/09/2025 https://us-east-1.console.aws.amazon.com/billing/home#/credits 6 - Tiếp tục các thử thách để đủ $100 credits còn lại.\n- Lab: hoàn tất Challenge 3, 4, 5. 12/09/2025 12/09/2025 https://us-east-1.console.aws.amazon.com/billing/home#/credits Kết quả đạt được Tuần 1 Đăng ký làm việc tại văn phòng cùng nhóm; làm quen AWS qua Console và quy trình chung. Tạo và cấu hình AWS Free Tier thành công; hiểu khác biệt root vs IAM user. Làm quen với AWS Management Console: tra cứu, điều hướng và thao tác cơ bản trên dịch vụ. Cài đặt \u0026amp; cấu hình AWS CLI (Access key, Secret key, default region, profile). CLI practice đã thực hiện:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình. Liệt kê danh sách regions. Truy vấn trạng thái EC2. Tạo/quản lý key pair phục vụ SSH. Theo dõi dịch vụ đang sử dụng để tránh phát sinh chi phí. Kiến thức bổ sung:\nPhân biệt và thao tác VPC (mạng), EC2 (compute) ở mức cơ bản. Vẽ sơ đồ kiến trúc ban đầu bằng draw.io để hình dung tài nguyên liên quan. Kết hợp Console và CLI trong cùng quy trình quản trị để làm việc hiệu quả. "},{"uri":"https://masterltb.github.io/profile/vi/4-eventparticipated/4.2-event2/","title":"Khám Phá Agentic AI – Workshop Amazon QuickSuite","tags":[],"description":"","content":"Khám Phá Agentic AI – Workshop Amazon QuickSuite - Ngày: 7 tháng 11, 2025 - Địa điểm: Văn phòng AWS Việt Nam, Bitexco Financial Tower, TP.HCM\nTổng quan sự kiện Một workshop đặc biệt tập trung vào sự chuyển dịch từ AI Tạo sinh (Generative AI) thụ động sang AI Tác tử (Agentic AI) tự chủ. Sự kiện đã có buổi trình diễn trực tiếp đầu tiên của Amazon QuickSuite tại Việt Nam và giới thiệu Chương trình AWS LIFT để giảm bớt rào cản tài chính cho việc áp dụng.\nMục tiêu chính:\nĐịnh nghĩa Agentic AI: Làm rõ khái niệm về các tác tử AI tự chủ có khả năng suy luận và thực thi nhiệm vụ. Giới thiệu Amazon QuickSuite: Trình diễn nền tảng hợp nhất giữa trực quan hóa dữ liệu (QuickSight) và AI tạo sinh (Quick Suite Q). Hỗ trợ học tập thực hành: Cung cấp một môi trường thực tế để xây dựng các khái niệm AI với sự hướng dẫn của chuyên gia. Thúc đẩy áp dụng: Cung cấp khoản tín dụng 80.000 USD thông qua Chương trình AWS LIFT để thúc đẩy R\u0026amp;D. Bài học và Erkenntnisse chính Tập trung vào tính tự chủ: Mục tiêu thiết kế của Agentic AI là xây dựng các hệ thống hành động thay mặt người dùng, không chỉ cung cấp thông tin. Cách tiếp cận hệ sinh thái là rất quan trọng: Các tác tử hiệu quả đòi hỏi một mạng lưới công cụ được kết nối, giống như mạng lưới được cung cấp bởi QuickSuite, để liên kết các nguồn dữ liệu với logic hành động. Việc áp dụng sớm tạo ra lợi thế: Việc thành thạo các công cụ như QuickSuite trước khi chúng trở nên phổ biến sẽ mang lại một lợi thế cạnh tranh đáng kể. Nguồn vốn thúc đẩy sự đổi mới: Các ưu đãi tài chính như chương trình LIFT cho phép các công ty thử nghiệm và đổi mới nhanh hơn. Ứng dụng vào Công việc Khám phá QuickSuite cho Phân tích: Nghiên cứu việc tích hợp QuickSight và Quick Suite Q để tạo ra các \u0026ldquo;Tác tử Phân tích\u0026rdquo; có thể tự động hóa việc báo cáo và phân tích dữ liệu. Đảm bảo kinh phí cho R\u0026amp;D: Đăng ký Chương trình AWS LIFT để đảm bảo các khoản tín dụng cho các dự án nghiên cứu và phát triển liên quan đến AI sắp tới. Xác định các trường hợp sử dụng tự động hóa: Kiểm tra các hoạt động nội bộ để tìm các tác vụ lặp đi lặp lại, nhiều bước phù hợp để một tác tử AI thực hiện tự chủ. Hợp tác với các đối tác triển khai: Hợp tác với các đối tác như Cloud Kinetics để thiết kế và triển khai kiến trúc phức tạp, giảm thiểu rủi ro phát triển nội bộ. Hình ảnh sự kiện Thêm hình ảnh sự kiện của bạn tại đây\n"},{"uri":"https://masterltb.github.io/profile/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Hiện đại hóa việc phòng chống gian lận: GraphStorm v0.5 cho suy luận thời gian thực Gian lận tiếp tục gây ra thiệt hại tài chính đáng kể trên toàn cầu, chỉ riêng người tiêu dùng Hoa Kỳ đã mất 12,5 tỷ USD vào năm 2024—tăng 25% so với năm trước theo Ủy ban Thương mại Liên bang. Sự gia tăng này không xuất phát từ các cuộc tấn công thường xuyên hơn, mà từ sự tinh vi ngày càng tăng của những kẻ gian lận. Khi các hoạt động gian lận trở nên phức tạp và kết nối với nhau hơn, các phương pháp machine learning thông thường tỏ ra yếu kém do chỉ phân tích các giao dịch một cách riêng lẻ, không thể nắm bắt được mạng lưới các hoạt động phối hợp đặc trưng cho các âm mưu gian lận hiện đại.\nGraph neural networks (GNNs) giải quyết hiệu quả thách thức này bằng cách mô hình hóa các mối quan hệ giữa các thực thể—chẳng hạn như người dùng chia sẻ thiết bị, vị trí hoặc phương thức thanh toán. Bằng cách phân tích cả cấu trúc mạng lưới và thuộc tính của thực thể, GNNs có hiệu quả trong việc xác định các âm mưu gian lận tinh vi nơi thủ phạm che giấu các hoạt động đáng ngờ riêng lẻ nhưng để lại dấu vết trong mạng lưới quan hệ của chúng. Tuy nhiên, việc triển khai phòng chống gian lận trực tuyến dựa trên GNN trong môi trường production đặt ra những thách thức đặc thù: đạt được phản hồi inference dưới một giây, mở rộng quy mô đến hàng tỷ nodes và edges, và duy trì hiệu quả vận hành cho các bản cập nhật mô hình. Trong bài đăng này, chúng tôi chỉ cho bạn cách vượt qua những thách thức này bằng cách sử dụng GraphStorm, đặc biệt là các khả năng real-time inference mới của GraphStorm v0.5.\nCác giải pháp trước đây đòi hỏi sự đánh đổi (tradeoffs) giữa khả năng và sự đơn giản. Cách tiếp cận DGL ban đầu của chúng tôi cung cấp các khả năng real-time toàn diện nhưng đòi hỏi việc điều phối dịch vụ (service orchestration) phức tạp—bao gồm việc cập nhật thủ công các cấu hình endpoint và định dạng payload sau khi huấn luyện lại với các hyperparameters mới. Cách tiếp cận này cũng thiếu sự linh hoạt của mô hình, đòi hỏi phải tùy chỉnh các mô hình và cấu hình GNN khi sử dụng các kiến trúc ngoài relational graph convolutional networks (RGCN). Các triển khai DGL in-memory sau đó đã giảm bớt sự phức tạp nhưng gặp phải những hạn chế về khả năng mở rộng (scalability) với khối lượng dữ liệu cấp doanh nghiệp. Chúng tôi đã xây dựng GraphStorm để thu hẹp khoảng cách này, bằng cách giới thiệu distributed training và các APIs cấp cao giúp đơn giản hóa việc phát triển GNN ở quy mô doanh nghiệp (enterprise scale).\nTrong một bài đăng blog gần đây, chúng tôi đã minh họa khả năng và sự đơn giản trong việc huấn luyện mô hình GNN quy mô doanh nghiệp và offline inference của GraphStorm. Mặc dù phát hiện gian lận bằng GNN ngoại tuyến (offline) có thể xác định các giao dịch gian lận sau khi chúng xảy ra—việc ngăn chặn tổn thất tài chính đòi hỏi phải chặn đứng gian lận trước khi nó xảy ra. GraphStorm v0.5 hiện thực hóa điều này thông qua hỗ trợ real-time inference gốc qua Amazon SageMaker AI. GraphStorm v0.5 mang đến hai cải tiến: triển khai endpoint được tinh giản giúp giảm nhiều tuần kỹ thuật tùy chỉnh—lập trình các tệp entry point của SageMaker, đóng gói các model artifacts, và gọi các APIs triển khai của SageMaker—xuống còn một thao tác lệnh duy nhất, và đặc tả payload được tiêu chuẩn hóa giúp đơn giản hóa việc tích hợp của client với các dịch vụ real-time inference. Những khả năng này cho phép thực hiện các tác vụ node classification dưới một giây như phòng chống gian lận, giúp các tổ chức chủ động chống lại mối đe dọa gian lận bằng các giải pháp GNN có khả năng mở rộng và vận hành đơn giản.\nĐể giới thiệu những khả năng này, bài đăng này trình bày một giải pháp phòng chống gian lận. Thông qua giải pháp này, chúng tôi chỉ ra cách một data scientist có thể chuyển đổi một mô hình GNN đã được huấn luyện sang các inference endpoints sẵn sàng cho production với chi phí vận hành tối thiểu. Nếu bạn quan tâm đến việc triển khai các mô hình dựa trên GNN để phòng chống gian lận thời gian thực hoặc các trường hợp kinh doanh (business cases) tương tự, bạn có thể điều chỉnh các phương pháp được trình bày ở đây để tạo ra giải pháp của riêng mình.\nTổng quan về giải pháp Giải pháp được đề xuất của chúng tôi là một quy trình (pipeline) 4 bước như được hiển thị trong hình sau. Quy trình bắt đầu ở bước 1 với việc xuất biểu đồ giao dịch từ cơ sở dữ liệu đồ thị xử lý giao dịch trực tuyến (OLTP) sang bộ nhớ có khả năng mở rộng (Amazon Simple Storage Service (Amazon S3) hoặc Amazon EFS), tiếp theo là huấn luyện mô hình phân tán ở bước 2. Bước 3 là quy trình triển khai đơn giản hóa của GraphStorm v0.5, tạo ra các real-time inference endpoints của SageMaker bằng một lệnh duy nhất. Sau khi SageMaker AI đã triển khai endpoint thành công, một ứng dụng client tích hợp với cơ sở dữ liệu đồ thị OLTP để xử lý các luồng giao dịch trực tiếp ở bước 4. Bằng cách truy vấn cơ sở dữ liệu đồ thị, client chuẩn bị các đồ thị con (subgraphs) xung quanh các giao dịch cần dự đoán, chuyển đổi đồ thị con thành định dạng payload được tiêu chuẩn hóa, và gọi endpoint đã được triển khai để dự đoán thời gian thực.\nĐể cung cấp chi tiết triển khai cụ thể cho từng bước trong giải pháp real-time inference, chúng tôi minh họa luồng công việc hoàn chỉnh bằng cách sử dụng nhiệm vụ phát hiện gian lận IEEE-CIS có sẵn công khai.\nLưu ý: Ví dụ này sử dụng một Jupyter notebook làm bộ điều khiển cho toàn bộ quy trình bốn bước để cho đơn giản. Để có thiết kế sẵn sàng cho production hơn, hãy xem kiến trúc được mô tả trong Build a GNN-based real-time fraud detection solution.\nCác điều kiện tiên quyết Để chạy ví dụ này, bạn cần có một tài khoản AWS mà mã AWS Cloud Development Kit (AWS CDK) của ví dụ sử dụng để tạo các tài nguyên cần thiết, bao gồm Amazon Virtual Private Cloud (Amazon VPC), cơ sở dữ liệu Amazon Neptune, Amazon SageMaker AI, Amazon Elastic Container Registry (Amazon ECR), Amazon S3, cùng các roles và permission liên quan.\nLưu ý: Các tài nguyên này sẽ phát sinh chi phí trong quá trình thực thi (khoảng 6 USD mỗi giờ với cài đặt mặc định). Hãy theo dõi việc sử dụng một cách cẩn thận và xem lại các trang giá cho những dịch vụ này trước khi tiếp tục. Làm theo hướng dẫn dọn dẹp ở cuối để tránh các khoản phí phát sinh liên tục.\nVí dụ thực hành: Phòng chống gian lận thời gian thực với bộ dữ liệu IEEE-CIS Toàn bộ mã triển khai cho ví dụ này, bao gồm các Jupyter notebook và các tệp kịch bản Python hỗ trợ, hiện có sẵn trong kho lưu trữ (repository) công khai của chúng tôi. Kho lưu trữ này cung cấp một bản triển khai end-to-end hoàn chỉnh mà bạn có thể trực tiếp thực thi và điều chỉnh cho các trường hợp sử dụng (use cases) phòng chống gian lận của riêng bạn.\nTổng quan về bộ dữ liệu và nhiệm vụ Ví dụ này sử dụng bộ dữ liệu phát hiện gian lận IEEE-CIS, chứa 500.000 giao dịch đã được ẩn danh với khoảng 3,5% là các trường hợp gian lận. Bộ dữ liệu bao gồm 392 thuộc tính dạng phân loại (categorical) và dạng số (numerical), với các thuộc tính chính như loại thẻ, loại sản phẩm, địa chỉ, và tên miền email tạo thành cấu trúc đồ thị (graph structure) được hiển thị trong hình sau. Mỗi giao dịch (với một nhãn isFraud) kết nối đến các thực thể Loại thẻ, Vị trí, Loại sản phẩm, và tên miền email của Người mua và Người nhận, tạo ra một đồ thị không đồng nhất (heterogeneous graph) cho phép các mô hình GNN phát hiện các mẫu gian lận thông qua các mối quan hệ giữa các thực thể.\nKhác với bài đăng trước của chúng tôi đã minh họa về GraphStorm cùng với Amazon Neptune Analytics cho các luồng công việc phân tích ngoại tuyến (offline), ví dụ này sử dụng cơ sở dữ liệu Neptune làm kho lưu trữ đồ thị OLTP, được tối ưu hóa cho việc trích xuất đồ thị con (subgraph) nhanh chóng cần thiết trong quá trình real-time inference. Dựa trên thiết kế đồ thị, dữ liệu IEEE-CIS dạng bảng được chuyển đổi thành một bộ tệp CSV tương thích với định dạng của cơ sở dữ liệu Neptune, cho phép tải trực tiếp vào cả cơ sở dữ liệu Neptune và quy trình huấn luyện mô hình GNN của GraphStorm chỉ với một bộ tệp duy nhất.\nBước 0: Thiết lập môi trường Bước 0 thiết lập môi trường chạy cần thiết cho quy trình (pipeline) phòng chống gian lận bốn bước. Hướng dẫn thiết lập hoàn chỉnh có sẵn trong kho lưu trữ (repository) triển khai.\nĐể chạy giải pháp ví dụ, bạn cần triển khai một AWS CloudFormation stack thông qua AWS CDK. Stack này tạo ra Neptune DB instance, VPC để đặt nó vào, và các roles và security groups phù hợp. Nó còn tạo thêm một SageMaker AI notebook instance, từ đó bạn chạy các notebook ví dụ đi kèm với repository.\ngit clone [https://github.com/aws-samples/amazon-neptune-samples.git](https://github.com/aws-samples/amazon-neptune-samples.git) cd neptune-database-graphstorm-online-inference/neptune-db-cdk # Ensure you have CDK installed and have appropriate credentials set up cdk deploy Khi việc triển khai (deployment) hoàn tất (mất khoảng 10 phút để các tài nguyên cần thiết sẵn sàng), AWS CDK sẽ in ra một vài kết quả đầu ra (outputs), một trong số đó là tên của SageMaker notebook instance mà bạn sử dụng để chạy qua các notebooks: Bash # Example output NeptuneInfraStack.NotebookInstanceName = arn:aws:sagemaker:us-east-1:012345678912:notebook-instance/NeptuneNotebook-9KgSB9XXXXXX Bạn có thể điều hướng đến giao diện người dùng (UI) của SageMaker AI notebook, tìm notebook instance tương ứng, và chọn liên kết Open Jupyterlab của nó để truy cập notebook. Một cách khác là, bạn có thể sử dụng AWS Command Line Interface (AWS CLI) để nhận một URL đã được ký trước (pre-signed URL) để truy cập notebook. Bạn sẽ cần thay thế \u0026lt;notebook-instance-name\u0026gt; bằng tên notebook instance thực tế. Bash aws sagemaker create-presigned-notebook-instance-url --notebook-instance-name \u0026lt;notebook-instance-name\u0026gt; Khi bạn đang ở trong giao diện web console của notebook instance, hãy mở notebook đầu tiên, 0-Data-Preparation.ipynb, để bắt đầu đi qua ví dụ. Bước 1: Xây dựng đồ thị Trong Notebook 0-Data-Preparation, bạn chuyển đổi bộ dữ liệu IEEE-CIS dạng bảng thành cấu trúc đồ thị không đồng nhất (heterogeneous graph structure) được hiển thị trong hình ở đầu phần này. Jupyter Notebook được cung cấp sẽ trích xuất các thực thể từ các thuộc tính (features) của giao dịch, tạo ra các node Loại thẻ từ các thuộc tính card1–card6, các node Người mua và Người nhận từ các tên miền email, các node Loại sản phẩm từ mã sản phẩm, và các node Vị trí từ thông tin địa lý. Quá trình chuyển đổi này thiết lập các mối quan hệ giữa các giao dịch và những thực thể này, tạo ra dữ liệu đồ thị ở định dạng nhập của Neptune (Neptune import format) để nhập trực tiếp vào kho lưu trữ đồ thị OLTP. Hàm create_neptune_db_data() điều phối quá trình trích xuất thực thể và tạo mối quan hệ này trên tất cả các loại node (mất khoảng 30 giây). Python GRAPH_NAME = \u0026#34;ieee-cis-fraud-detection\u0026#34; PROCESSED_PREFIX = f\u0026#34;./{GRAPH_NAME}\u0026#34; ID_COLS = \u0026#34;card1,card2,card3,card4,card5,card6,ProductCD,addr1,addr2,P_emaildomain,R_emaildomain\u0026#34; CAT_COLS = \u0026#34;M1,M2,M3,M4,M5,M6,M7,M8,M9\u0026#34; # Lists of columns to keep from each file COLS_TO_KEEP = { \u0026#34;transaction.csv\u0026#34;: ( ID_COLS.split(\u0026#34;,\u0026#34;) + CAT_COLS.split(\u0026#34;,\u0026#34;) + # Numerical features without missing values [f\u0026#34;C{idx}\u0026#34; for idx in range(1, 15)] + [\u0026#34;TransactionID\u0026#34;, \u0026#34;TransactionAmt\u0026#34;, \u0026#34;TransactionDT\u0026#34;, \u0026#34;isFraud\u0026#34;] ), \u0026#34;identity.csv\u0026#34;: [\u0026#34;TransactionID\u0026#34;, \u0026#34;DeviceType\u0026#34;], } create_neptune_db_data( data_prefix=\u0026#34;./input-data/\u0026#34;, output_prefix=PROCESSED_PREFIX, id_cols=ID_COLS, cat_cols=CAT_COLS, cols_to_keep=COLS_TO_KEEP, num_chunks=1, ) Notebook này cũng tạo ra tệp cấu hình JSON cần thiết cho lệnh GConstruct của GraphStorm và thực thi quy trình xây dựng đồ thị. Lệnh GConstruct này chuyển đổi dữ liệu có định dạng Neptune thành một định dạng đồ thị nhị phân phân tán (distributed binary graph format) được tối ưu hóa cho quy trình (pipeline) huấn luyện của GraphStorm, có chức năng phân chia cấu trúc đồ thị không đồng nhất (heterogeneous graph structure) trên các nút tính toán (compute nodes) để cho phép huấn luyện mô hình có khả năng mở rộng trên các đồ thị quy mô công nghiệp (được đo bằng hàng tỷ nodes và edges). Đối với dữ liệu IEEE-CIS, lệnh GConstruct mất 90 giây để hoàn thành. Trong Notebook 1-Load-Data-Into-Neptune-DB, bạn tải dữ liệu CSV vào Neptune database instance (mất khoảng 9 phút), việc này giúp chúng có sẵn cho online inference. Trong quá trình online inference, sau khi chọn một node giao dịch, bạn truy vấn cơ sở dữ liệu Neptune để lấy vùng lân cận đồ thị (graph neighborhood) của node mục tiêu, truy xuất các thuộc tính (features) của mọi node trong vùng lân cận và cấu trúc đồ thị con (subgraph structure) xung quanh mục tiêu. Bước 2: Huấn luyện mô hình Sau khi bạn đã chuyển đổi dữ liệu sang định dạng đồ thị nhị phân phân tán (distributed binary graph format), đã đến lúc huấn luyện một mô hình GNN. GraphStorm cung cấp các kịch bản dòng lệnh (command-line scripts) để huấn luyện một mô hình mà không cần viết mã. Trong Notebook 2-Model-Training, bạn huấn luyện một mô hình GNN sử dụng lệnh phân loại node (node classification) của GraphStorm với cấu hình được quản lý thông qua các tệp YAML. Cấu hình cơ bản xác định một mô hình RGCN hai lớp với các lớp ẩn 128 chiều, huấn luyện trong 4 epochs với learning rate là 0.001 và batch size là 1024, mất khoảng 100 giây cho 1 epoch huấn luyện và đánh giá mô hình trên một instance ml.m5.4xlarge. Để cải thiện độ chính xác của việc phát hiện gian lận, notebook cung cấp các cấu hình mô hình nâng cao hơn như lệnh dưới đây. Bash !python -m graphstorm.run.gs_node_classification \\ --workspace ./ \\ --part-config ieee_gs/ieee-cis.json \\ --num-trainers 1 \\ --cf ieee_nc.yaml \\ --eval-metric roc_auc \\ --save-model-path ./model-simple/ \\ --topk-model-to-save 1 \\ --imbalance-class-weights 0.1,1.0 Các đối số trong lệnh này giải quyết thách thức về sự mất cân bằng nhãn (label imbalance) của bộ dữ liệu, nơi chỉ có 3,5% giao dịch là gian lận, bằng cách sử dụng AUC-ROC làm thước đo đánh giá (evaluation metric) và sử dụng trọng số lớp (class weights). Lệnh này cũng lưu mô hình hoạt động tốt nhất cùng với các tệp cấu hình thiết yếu cần thiết cho việc triển khai endpoint. Các cấu hình nâng cao có thể nâng cao hơn nữa hiệu suất của mô hình thông qua các kỹ thuật như HGT encoders, multi-head attention, và hàm mất mát class-weighted cross entropy, mặc dù những tối ưu hóa này làm tăng yêu cầu tính toán. GraphStorm cho phép thực hiện những thay đổi này thông qua các đối số lúc chạy (run time arguments) và các cấu hình YAML, làm giảm nhu cầu sửa đổi mã. Bước 3: Triển khai endpoint thời gian thực Trong Notebook 3-GraphStorm-Endpoint-Deployment, bạn triển khai endpoint thời gian thực thông qua kịch bản khởi chạy (launch script) đơn giản của GraphStorm v0.5. Việc triển khai đòi hỏi ba model artifacts được tạo ra trong quá trình huấn luyện: tệp mô hình đã lưu chứa các trọng số, tệp JSON xây dựng đồ thị đã được cập nhật với metadata biến đổi thuộc tính, và tệp YAML cấu hình huấn luyện được cập nhật lúc chạy. Những artifacts này cho phép GraphStorm tái tạo lại chính xác các cấu hình huấn luyện và mô hình để có hành vi inference nhất quán. Đáng chú ý, tệp JSON xây dựng đồ thị và tệp YAML cấu hình huấn luyện đã được cập nhật chứa các cấu hình quan trọng, thiết yếu để khôi phục mô hình đã được huấn luyện trên endpoint và xử lý các payload yêu cầu đến. Việc sử dụng các tệp JSON và YAML đã được cập nhật cho việc triển khai endpoint là rất quan trọng. GraphStorm sử dụng tính năng bring your own container (BYOC) của SageMaker AI để triển khai một môi trường inference nhất quán. Bạn cần xây dựng và đẩy (push) Docker image thời gian thực của GraphStorm lên Amazon ECR bằng cách sử dụng các kịch bản shell (shell scripts) được cung cấp. Cách tiếp cận container hóa này cung cấp các môi trường chạy (runtime environments) nhất quán tương thích với cơ sở hạ tầng được quản lý của SageMaker AI. Docker image chứa các phụ thuộc cần thiết cho các khả năng real-time inference của GraphStorm trên môi trường triển khai. Để triển khai endpoint, bạn có thể sử dụng kịch bản (script) launch_realtime_endpoint.py do GraphStorm cung cấp, giúp bạn thu thập các artifacts cần thiết và tạo ra các tài nguyên SageMaker AI cần thiết để triển khai một endpoint. Script này chấp nhận URI của image trên Amazon ECR, IAM role, đường dẫn đến các model artifact, và cấu hình S3 bucket, tự động xử lý việc cấp phát (provisioning) và cấu hình endpoint. Theo mặc định, script sẽ đợi cho việc triển khai endpoint hoàn tất trước khi thoát. Khi hoàn tất, nó sẽ in ra tên và Khu vực AWS (AWS Region) của endpoint đã được triển khai cho các yêu cầu inference sau đó. Bạn sẽ cần phải thay thế các trường được đặt trong \u0026lt;\u0026gt; bằng các giá trị thực tế của môi trường của bạn. Bash !python ~/graphstorm/sagemaker/launch/launch_realtime_endpoint.py \\ --image-uri \u0026lt;account_id\u0026gt;.dkr.ecr.\u0026lt;aws_region\u0026gt;[.amazonaws.com/graphstorm:sagemaker-endpoint-cpu](https://.amazonaws.com/graphstorm:sagemaker-endpoint-cpu) \\ --role arn:aws:iam::\u0026lt;account_id\u0026gt;:role/\u0026lt;your_role\u0026gt; \\ --region \u0026lt;aws_region\u0026gt; \\ --restore-model-path \u0026lt;restore-model-path\u0026gt;/models/epoch-1/ \\ --model-yaml-config-file \u0026lt;restore-model-path\u0026gt;/models/GRAPHSTORM_RUNTIME_UPDATED_TRAINING_CONFIG.yaml \\ --graph-json-config-file \u0026lt;restore-model-path\u0026gt;/models/data_transform_new.json \\ --infer-task-type node_classification \\ --upload-tarfile-s3 s3://\u0026lt;cdk-created-bucket\u0026gt; \\ --model-name ieee-fraud-detect Bước 4: Real-time inference Trong Notebook 4-Sample-Graph-and-Invoke-Endpoint, bạn xây dựng một ứng dụng client cơ bản tích hợp với endpoint GraphStorm đã được triển khai để thực hiện phòng chống gian lận thời gian thực trên các giao dịch đến. Quy trình inference chấp nhận dữ liệu giao dịch thông qua các payload JSON được tiêu chuẩn hóa, thực hiện các dự đoán phân loại node (node classification) trong vài trăm mili giây, và trả về điểm xác suất gian lận cho phép đưa ra quyết định ngay lập tức. Một lời gọi inference end-to-end cho một node đã tồn tại trong đồ thị có ba giai đoạn riêng biệt: Lấy mẫu đồ thị (Graph sampling) từ cơ sở dữ liệu Neptune. Đối với một node mục tiêu đã cho đã tồn tại trong đồ thị, truy xuất vùng lân cận k-hop của nó với một giới hạn fanout, tức là giới hạn số lượng hàng xóm được truy xuất ở mỗi hop bằng một ngưỡng. Chuẩn bị payload cho inference. Neptune trả về các đồ thị bằng GraphSON, một định dạng dữ liệu giống JSON chuyên dụng được sử dụng để mô tả dữ liệu đồ thị. Ở bước này, bạn cần chuyển đổi GraphSON được trả về sang đặc tả JSON của riêng GraphStorm. Bước này được thực hiện trên client thực hiện inference, trong trường hợp này là một SageMaker notebook instance. Thực hiện Model inference bằng một SageMaker endpoint. Sau khi payload được chuẩn bị, bạn gửi một yêu cầu inference đến một SageMaker endpoint đã tải một model snapshot đã được huấn luyện trước đó. Endpoint nhận yêu cầu, thực hiện bất kỳ phép biến đổi thuộc tính nào cần thiết (chẳng hạn như chuyển đổi các thuộc tính dạng phân loại (categorical) sang mã hóa one-hot (one-hot encoding)), tạo biểu diễn đồ thị nhị phân trong bộ nhớ, và đưa ra dự đoán cho node mục tiêu bằng cách sử dụng vùng lân cận đồ thị và các trọng số mô hình đã được huấn luyện. Phản hồi được mã hóa thành JSON và gửi lại cho client. Một phản hồi ví dụ từ endpoint sẽ trông như sau: JSON { \u0026#34;status_code\u0026#34;: 200, \u0026#34;request_uid\u0026#34;: \u0026#34;877042dbc361fc33\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Request processed successfully.\u0026#34;, \u0026#34;error\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;results\u0026#34;: [ { \u0026#34;node_type\u0026#34;: \u0026#34;Transaction\u0026#34;, \u0026#34;node_id\u0026#34;: \u0026#34;2991260\u0026#34;, \u0026#34;prediction\u0026#34;: [0.995966911315918, 0.004033133387565613] } ] } } Dữ liệu quan tâm cho giao dịch đơn lẻ mà bạn đã dự đoán nằm trong khóa (key) prediction và node_id. tương ứng. Kết quả dự đoán cung cấp cho bạn điểm số thô (raw scores) mà mô hình tạo ra cho lớp 0 (hợp lệ) và lớp 1 (gian lận) tại các chỉ số (indexes) 0 và 1 tương ứng của danh sách predictions. Trong ví dụ này, mô hình đánh dấu giao dịch này là có khả năng cao là hợp lệ. Bạn có thể tìm thấy đặc tả phản hồi đầy đủ của GraphStorm trong tài liệu của GraphStorm. Các ví dụ triển khai hoàn chỉnh, bao gồm mã client và các đặc tả payload, được cung cấp trong kho lưu trữ (repository) để hướng dẫn việc tích hợp với các hệ thống production. Dọn dẹp Để ngừng phát sinh chi phí trên tài khoản của bạn, bạn cần xóa các tài nguyên AWS mà bạn đã tạo bằng AWS CDK tại bước Thiết lập Môi trường (Environment Setup). Trước tiên, bạn phải xóa SageMaker endpoint được tạo trong Bước 3 để lệnh cdk destroy có thể hoàn thành. Hãy xem mục Delete Endpoints and Resources để biết thêm các tùy chọn xóa một endpoint. Khi xong, bạn có thể chạy lệnh sau từ thư mục gốc của repository: Bash cd neptune-database-graphstorm-online-inference/neptune-db-cdk cdk destroy Xem tài liệu của AWS CDK để biết thêm thông tin về cách sử dụng cdk destroy, hoặc xem tài liệu của CloudFormation để biết cách xóa một stack từ giao diện người dùng console (console UI). Theo mặc định, lệnh cdk destroy không xóa các model artifacts và dữ liệu đồ thị đã xử lý được lưu trữ trong S3 bucket trong quá trình huấn luyện và triển khai. Bạn phải xóa chúng theo cách thủ công. Hãy xem mục Deleting a general purpose bucket để biết thông tin về cách làm trống và xóa một S3 bucket mà AWS CDK đã tạo. Kết luận Graph neural networks giải quyết các thách thức phòng chống gian lận phức tạp bằng cách mô hình hóa các mối quan hệ giữa các thực thể mà các phương pháp machine learning truyền thống bỏ lỡ khi phân tích các giao dịch một cách riêng lẻ. GraphStorm v0.5 giúp đơn giản hóa việc triển khai real-time inference của GNN với một lệnh duy nhất để tạo endpoint, việc mà trước đây đòi hỏi sự phối hợp của nhiều dịch vụ, và một đặc tả payload được tiêu chuẩn hóa giúp đơn giản hóa việc tích hợp của client với các dịch vụ real-time inference. Các tổ chức giờ đây có thể triển khai các endpoint phòng chống gian lận quy mô doanh nghiệp thông qua các lệnh được tinh giản, giúp giảm công sức kỹ thuật tùy chỉnh từ hàng tuần xuống còn các thao tác một lệnh duy nhất. Để triển khai phòng chống gian lận dựa trên GNN với dữ liệu của riêng bạn: Xem lại tài liệu của GraphStorm để biết các tùy chọn cấu hình mô hình và các đặc tả triển khai. Điều chỉnh ví dụ IEEE-CIS này cho bộ dữ liệu phòng chống gian lận của bạn bằng cách sửa đổi các bước xây dựng đồ thị và kỹ thuật thuộc tính (feature engineering), sử dụng mã nguồn và các bài hướng dẫn hoàn chỉnh có sẵn trong kho lưu trữ GitHub của chúng tôi. Truy cập hướng dẫn triển khai từng bước để xây dựng các giải pháp phòng chống gian lận sẵn sàng cho production với các khả năng nâng cao của GraphStorm v0.5 bằng cách sử dụng dữ liệu doanh nghiệp của bạn. Author Jian Zhang — Nhà khoa học ứng dụng cấp cao, người đã sử dụng các kỹ thuật machine learning để giúp khách hàng giải quyết nhiều vấn đề khác nhau, chẳng hạn như phát hiện gian lận, tạo ảnh trang trí, và nhiều hơn nữa. Ông đã phát triển thành công các giải pháp machine learning dựa trên đồ thị, đặc biệt là graph neural network, cho các khách hàng ở Trung Quốc, Hoa Kỳ, và Singapore. Với vai trò là người truyền bá kiến thức về các khả năng đồ thị của AWS, Zhang đã có nhiều bài thuyết trình trước công chúng về GraphStorm, GNN, Deep Graph Library (DGL), Amazon Neptune, và các dịch vụ AWS khác. Author Theodore Vasiloudis — Nhà khoa học ứng dụng cấp cao tại AWS, nơi ông làm việc về các hệ thống và thuật toán machine learning phân tán. Ông đã lãnh đạo việc phát triển GraphStorm Processing, thư viện xử lý đồ thị phân tán cho GraphStorm và là một nhà phát triển cốt lõi cho GraphStorm. Ông nhận bằng Tiến sĩ Khoa học Máy tính từ Viện Công nghệ Hoàng gia KTH, Stockholm, vào năm 2019. Author Xiang Song — Nhà khoa học ứng dụng cấp cao tại AWS AI Research and Education (AIRE), nơi ông phát triển các framework deep learning bao gồm GraphStorm, DGL, và DGL-KE. Ông đã lãnh đạo việc phát triển Amazon Neptune ML, một khả năng mới của Neptune sử dụng graph neural networks cho các đồ thị được lưu trữ trong cơ sở dữ liệu đồ thị. Hiện ông đang lãnh đạo việc phát triển GraphStorm, một framework machine learning đồ thị nguồn mở cho các trường hợp sử dụng doanh nghiệp. Ông nhận bằng Tiến sĩ về hệ thống và kiến trúc máy tính tại Đại học Fudan, Thượng Hải, vào năm 2014. Author Florian Saupe — Giám đốc Sản phẩm Kỹ thuật Cấp cao tại bộ phận nghiên cứu AI/ML của AWS, hỗ trợ các nhóm khoa học như nhóm machine learning đồ thị, và các nhóm Hệ thống ML làm việc về huấn luyện phân tán quy mô lớn, inference, và khả năng chịu lỗi. Trước khi gia nhập AWS, Florian đã lãnh đạo mảng quản lý sản phẩm kỹ thuật cho lĩnh vực lái xe tự động tại Bosch, là một nhà tư vấn chiến lược tại McKinsey \u0026amp; Company, và đã làm việc như một nhà khoa học về hệ thống điều khiển và robot—một lĩnh vực mà ông có bằng Tiến sĩ. Author Ozan Eken — Giám đốc Sản phẩm tại AWS, đam mê xây dựng các sản phẩm Generative AI và Graph Analytics tiên tiến. Với việc tập trung vào đơn giản hóa các thách thức dữ liệu phức tạp, Ozan giúp khách hàng khai phá những hiểu biết sâu sắc hơn và thúc đẩy sự đổi mới. Ngoài công việc, anh ấy thích thử các món ăn mới, khám phá các quốc gia khác nhau, và xem bóng đá. "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.2-perequisites/","title":"5.2 Prerequisites","tags":[],"description":"","content":"Module 2: Prerequisites - Chuẩn Bị Tài Khoản \u0026amp; Tools Mục tiêu Module Tạo \u0026amp; cấu hình AWS account Thiết lập IAM roles \u0026amp; policies Verify quyền truy cập cần thiết Setup cost monitoring \u0026amp; alerts Phần 1: AWS Account Setup Bước 1: Tạo AWS Account Nếu chưa có AWS account:\nTruy cập https://aws.amazon.com/ Click \u0026ldquo;Create an AWS Account\u0026rdquo; Điền email, password, account name Chọn Support Plan (Free tier available) Verify email \u0026amp; setup billing information Bước 2: Login vào AWS Console Truy cập https://console.aws.amazon.com/ Nhập root account email \u0026amp; password Verify MFA (Multi-Factor Authentication) nếu được yêu cầu Note: Nên bật MFA cho root account để bảo mật\nPhần 2: IAM Setup - Tạo Admin User Bước 1: Truy cập IAM Dashboard Từ AWS Console, tìm kiếm \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; từ services list Click \u0026ldquo;Users\u0026rdquo; trong navigation menu Bước 2: Tạo IAM User cho Workshop Click \u0026ldquo;Create user\u0026rdquo; Nhập User name: \u0026ldquo;workshop-admin\u0026rdquo; Check \u0026ldquo;Provide user access to the AWS Management Console - optional\u0026rdquo; Check \u0026ldquo;Users must create a new password at next sign-in - Recommended\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Bước 3: Gán Permissions Chọn \u0026ldquo;Attach policies directly\u0026rdquo;\nTìm và check policies sau:\nAdministratorAccess (cho phép toàn bộ services) Click \u0026ldquo;Next\u0026rdquo;\nBước 4: Review \u0026amp; Create Review thông tin user Click \u0026ldquo;Create user\u0026rdquo; Download \u0026ldquo;.csv\u0026rdquo; file chứa credentials Bước 5: Login bằng IAM User Copy User sign-in link từ confirmation screen Mở link trong browser mới Login bằng user name \u0026amp; password Phần 3: Verify Permissions Kiểm tra quyền truy cập AWS Services Login vào AWS Console bằng IAM user Truy cập từng service để verify quyền: Cognito: https://console.aws.amazon.com/cognito/ Lambda: https://console.aws.amazon.com/lambda/ EC2: https://console.aws.amazon.com/ec2/ API Gateway: https://console.aws.amazon.com/apigateway/ S3: https://console.aws.amazon.com/s3/ VPC: https://console.aws.amazon.com/vpc/ Kiểm tra: Bạn nên thấy \u0026ldquo;Create application\u0026rdquo; (không phải error message)\nPhần 4: Resources Naming Convention Để quản lý resources dễ dàng, sử dụng naming convention:\n{project-name}-{service}-{environment} Examples:\nsmoking-cessation-cognito-dev smoking-cessation-lambda-auth-dev smoking-cessation-db-pg-dev (PostgreSQL on EC2) smoking-cessation-db-mongo-dev (MongoDB on EC2) smoking-cessation-api-dev smoking-cessation-frontend-dev smoking-cessation-vpc-dev Benefit: Dễ tìm kiếm \u0026amp; quản lý resources trong console\nTroubleshooting Không thể tạo IAM User Kiểm tra: Bạn đã login bằng root account hay IAM user khác? Solution: Login lại bằng root account để tạo IAM user Permission Denied errors Verify: IAM policies attached to user Kiểm tra: Policies có include service bạn đang sử dụng không? Contact AWS support nếu cần elevated permissions Notes Từ bây giờ, tất cả actions đều sử dụng IAM user, không phải root Mỗi service sẽ có specific IAM role (created ở modules tiếp theo) Free Tier cung cấp sufficient resources cho learning Kết Quả Đạt Được Sau Module 2, bạn sẽ có:\nAWS account đã activate IAM user \u0026ldquo;workshop-admin\u0026rdquo; có quyền admin Quyền truy cập tất cả AWS services cần thiết Sẵn sàng cho Module 3 (Setup Cognito) "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.2-week2/","title":"Nhật ký Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2 Thiết lập tài khoản AWS và IAM fundamentals. Bật MFA và tạo IAM users. Hiểu access control và credential management. Các nhiệm vụ trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tạo tài khoản AWS Free Tier với root user.\n- Thiết lập billing alerts và free tier monitoring. 16/09/2025 16/09/2025 https://aws.amazon.com/ 3 - Bật MFA (Multi-Factor Authentication) trên root account.\n- Tải và lưu backup codes an toàn. 17/09/2025 17/09/2025 https://console.aws.amazon.com/iam/ 4 - Tạo IAM user đầu tiên để sử dụng hàng ngày.\n- Gán AdministratorAccess policy cho test user.\n- Tạo access keys và test AWS CLI connection. 18/09/2025 18/09/2025 https://console.aws.amazon.com/iam/ 5 - Khám phá AWS Management Console navigation.\n- Tìm hiểu về service regions và availability zones.\n- Xem xét billing dashboard và free tier usage. 19/09/2025 19/09/2025 https://console.aws.amazon.com/billing/ 6 - Học IAM core components: Users, Groups, Roles, Policies.\n- Tạo IAM group và thêm users vào group. 20/09/2025 20/09/2025 https://console.aws.amazon.com/iam/ Kết quả Tuần 2 Tạo thành công AWS Free Tier account với MFA enabled. Hiểu root user vs IAM user best practices. Tạo IAM user đầu tiên với programmatic access (AWS CLI). Kiến thức nền tảng về IAM access control model. Thực hành AWS Management Console và CLI cho basic operations. Thiết lập billing alerts để monitor free tier usage. Những điều quan trọng học được:\nRoot user chỉ dùng cho account recovery (MFA + backup codes rất quan trọng). IAM users cung cấp granular access control và audit trail. Access keys nên rotate thường xuyên cho security. Luôn dùng least privilege principle khi assign permissions. "},{"uri":"https://masterltb.github.io/profile/vi/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Đề Xuất Hệ Thống Hỗ Trợ Cai Thuốc Lá 📄 Download Proposal (.docx)\n1. Tóm tắt Điều hành Bản đề xuất này mô tả thiết kế và triển khai một Nền tảng Hỗ trợ Cai Thuốc Lá dựa trên đám mây, nhằm giúp người dùng bỏ thuốc thông qua việc theo dõi dữ liệu, phân tích hành vi, huấn luyện bằng AI và tương tác cộng đồng.\nHệ thống tích hợp một hạ tầng backend hiện đại, có khả năng mở rộng, được triển khai trên AWS Cloud, đảm bảo tính sẵn sàng cao, bảo mật và trải nghiệm người dùng liền mạch.\nMục tiêu là cung cấp một hành trình thông minh và cá nhân hóa để người dùng theo dõi, lập kế hoạch và đạt được mục tiêu cai thuốc—đồng thời mang đến cho quản trị viên và huấn luyện viên các công cụ để hỗ trợ và hướng dẫn họ.\n2. Mục tiêu Hệ thống Giúp người dùng xây dựng và theo dõi các kế hoạch cai thuốc được cá nhân hóa. Theo dõi hành vi hút thuốc và tiến trình sức khỏe theo thời gian thực. Cung cấp huấn luyện bằng AI, nhắc nhở và thông điệp động viên. Cho phép tương tác và khích lệ giữa các thành viên trong cộng đồng. Cung cấp hạ tầng điện toán đám mây an toàn và có khả năng mở rộng. 3. Các Tính năng Chính Tính năng cho Người dùng Đăng ký \u0026amp; Gói thành viên: Người dùng có thể đăng ký, chọn các gói dịch vụ và thanh toán cho các tính năng cao cấp. Theo dõi tình trạng hút thuốc: Ghi lại số lượng thuốc lá sử dụng mỗi ngày, chi phí và tần suất. Kế hoạch cai thuốc cá nhân: Tạo và điều chỉnh kế hoạch cai dựa trên thói quen và mục tiêu của người dùng. Theo dõi tiến trình: Hiển thị các thống kê như số ngày không hút thuốc, tiền tiết kiệm và cải thiện sức khỏe. Thông báo động viên: Gửi tự động nhắc nhở và thông điệp khích lệ theo định kỳ. Thành tựu \u0026amp; Huy hiệu: Mở khóa các cột mốc như “7 ngày không hút thuốc” hoặc “Tiết kiệm 100K”. Tương tác cộng đồng: Chia sẻ thành tích, lời khuyên và động viên trong mạng lưới hỗ trợ. Tác tử AI Coaching: Hướng dẫn cá nhân hóa dựa trên công nghệ máy học. Tích hợp thiết bị sức khỏe: Thu thập dữ liệu từ các thiết bị đeo thông minh hoặc IoT để theo dõi tiến trình. Tính năng cho Quản trị viên \u0026amp; Nhà vận hành Dashboard \u0026amp; Báo cáo: Giám sát chỉ số người dùng, mức độ tương tác và phân tích tác động sức khỏe. Cổng huấn luyện viên: Huấn luyện viên có thể tương tác với người dùng qua chat hoặc video. Quản lý phản hồi \u0026amp; đánh giá: Theo dõi và phản hồi mức độ hài lòng của người dùng. Quản lý thanh toán \u0026amp; gói dịch vụ: Quản lý các gói phí và đăng ký của người dùng. 4. Kiến trúc Hệ thống (AWS Cloud) Hệ thống tận dụng các dịch vụ do AWS quản lý để đảm bảo khả năng mở rộng và bảo mật, như được minh họa trong sơ đồ kiến trúc.\nLớp Frontend Amazon S3 lưu trữ website tĩnh (frontend React hoặc Angular). Amazon CloudFront phân phối nội dung toàn cầu và xử lý mã hóa SSL/TLS. Xác thực \u0026amp; Phân quyền Amazon Cognito quản lý đăng ký, đăng nhập và liên kết danh tính, đảm bảo truy cập an toàn cho cả người dùng và huấn luyện viên. Lớp Ứng dụng AWS Lambda xử lý các tác vụ serverless như thanh toán hoặc các hoạt động API nhẹ. Network Load Balancer (NLB) phân phối các yêu cầu đến các instance EC2 backend. EC2 (Private Subnet) chạy các microservice cốt lõi: User Service Cessation Service Social Media Service Lớp Dữ liệu PostgreSQL Databases cho dữ liệu người dùng và cai thuốc (trên EC2 hoặc RDS). MongoDB cho tính năng xã hội và dữ liệu phi cấu trúc. S3 Bucket (Backup) lưu trữ bản sao lưu cơ sở dữ liệu được mã hóa định kỳ. DevOps Pipeline GitLab CI/CD Pipeline tự động triển khai lên Amazon ECR và EC2. VPC Endpoint đảm bảo kết nối an toàn với các dịch vụ AWS mà không cần ra Internet. EC2 Instance Connect Endpoint cho phép truy cập quản trị có kiểm soát. Hình 1 – Kiến trúc điện toán đám mây AWS cho Nền tảng Hỗ trợ Cai Thuốc Lá 5. Bảo mật và Tuân thủ Mã hóa dữ liệu: Tất cả dữ liệu nhạy cảm được mã hóa khi truyền (TLS) và khi lưu trữ (AES-256). IAM Policies: Kiểm soát truy cập chi tiết cho từng vai trò hệ thống. Private Subnets: Backend và cơ sở dữ liệu biệt lập khỏi Internet công cộng. VPC Link \u0026amp; Endpoints: Đảm bảo giao tiếp nội bộ an toàn giữa các dịch vụ. Chiến lược sao lưu: Sao lưu tự động hàng ngày lên S3 với versioning và lifecycle policy. 6. Khả năng mở rộng và Hiệu năng Auto Scaling: EC2 và Lambda tự động mở rộng khi nhu cầu tăng. CDN Caching: CloudFront lưu cache nội dung giúp tăng tốc phân phối toàn cầu. Load Balancing: NLB phân phối lưu lượng và đảm bảo chịu lỗi. Microservices tách biệt: Cho phép mở rộng độc lập từng dịch vụ. 7. Phát triển trong tương lai Tích hợp với ứng dụng di động Android và iOS. Dự đoán nguy cơ tái hút sử dụng AI nâng cao dựa trên hành vi người dùng. Chat và tư vấn video thời gian thực. Tích hợp cổng thanh toán bên thứ ba. Các thử thách gamification và hệ thống phần thưởng. 8. Kết quả kỳ vọng Tăng tỷ lệ bỏ thuốc thành công. Tăng động lực và mức độ tương tác của người dùng. Hệ thống có khả năng mở rộng để hỗ trợ lượng người dùng lớn. Nền tảng an toàn, tuân thủ và dễ bảo trì. "},{"uri":"https://masterltb.github.io/profile/vi/4-eventparticipated/4.3-event3/","title":"AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật","tags":[],"description":"","content":"AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật - Ngày: 1 tháng 12, 2025 - Địa điểm: Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nTổng quan sự kiện Một buổi workshop chuyên sâu tập trung vào Trụ cột Bảo mật (Security Pillar) trong Khuôn khổ AWS Well-Architected. Sự kiện cung cấp kiến thức và các phương pháp thực hành tốt nhất để bảo vệ khối lượng công việc trên đám mây.\nMục tiêu chính:\nHiểu sâu về Trụ cột Bảo mật: Phân tích các nguyên tắc thiết kế và các lĩnh vực chính của bảo mật trên AWS. Quản lý Danh tính và Truy cập: Tìm hiểu sâu về AWS IAM, MFA và các phương pháp hay nhất để kiểm soát truy cập. Bảo vệ Dữ liệu: Khám phá các kỹ thuật mã hóa dữ liệu khi lưu trữ (at-rest) và khi truyền (in-transit). Tự động hóa và Giám sát: Học cách sử dụng AWS Config, CloudTrail và Security Hub để giám sát và tự động hóa các biện pháp kiểm soát bảo mật. Bài học và Erkenntnisse chính Bảo mật là Trách nhiệm chung: Hiểu rõ mô hình trách nhiệm chung và vai trò của khách hàng trong việc bảo mật ứng dụng trên đám mây. Bảo mật theo lớp (Defense in Depth): Áp dụng nhiều lớp bảo mật để bảo vệ tài nguyên một cách toàn diện. Tự động hóa là Chìa khóa: Tự động hóa các quy trình kiểm tra và khắc phục bảo mật giúp giảm thiểu sai sót của con người và phản ứng nhanh hơn với các mối đe dọa. Ứng dụng vào Công việc Đánh giá lại Chính sách IAM: Rà soát và củng cố các chính sách IAM hiện tại theo nguyên tắc đặc quyền tối thiểu (least privilege). Triển khai Giám sát Bảo mật: Thiết lập AWS Security Hub để có một cái nhìn tổng quan, tập trung về tình hình bảo mật. Tăng cường Mã hóa Dữ liệu: Đảm bảo tất cả dữ liệu nhạy cảm được mã hóa bằng AWS KMS. "},{"uri":"https://masterltb.github.io/profile/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Thông báo ra mắt Amazon ECS Managed Instances cho các ứng dụng được container hóa Hôm nay, chúng tôi công bố Amazon ECS Managed Instances, một tùy chọn tính toán (compute option) mới cho Amazon Elastic Container Service (Amazon ECS) cho phép các nhà phát triển sử dụng toàn bộ các khả năng của Amazon Elastic Compute Cloud (Amazon EC2) đồng thời chuyển giao trách nhiệm quản lý cơ sở hạ tầng cho Amazon Web Service (AWS). Sản phẩm mới này kết hợp sự đơn giản trong vận hành của việc chuyển giao cơ sở hạ tầng với sự linh hoạt và khả năng kiểm soát của Amazon EC2, điều này có nghĩa là khách hàng có thể tập trung vào việc xây dựng các ứng dụng thúc đẩy sự đổi mới, đồng thời giảm tổng chi phí sở hữu (TCO) và duy trì các thông lệ tốt nhất của AWS (AWS best practices).\nAmazon ECS Managed Instances cung cấp một môi trường tính toán container (container compute environment) được quản lý hoàn toàn, hỗ trợ nhiều loại instance EC2 và tích hợp sâu với các dịch vụ AWS. Theo mặc định, nó tự động chọn các instance EC2 được tối ưu hóa chi phí nhất cho các workloads của bạn, nhưng bạn có thể chỉ định các thuộc tính hoặc loại instance cụ thể khi cần. AWS xử lý mọi khía cạnh của việc quản lý cơ sở hạ tầng, bao gồm việc cấp phát (provisioning), mở rộng quy mô (scaling), vá lỗi bảo mật (security patching), và tối ưu hóa chi phí, giúp bạn có thể tập trung vào việc xây dựng và vận hành các ứng dụng của mình.\nHãy dùng thử nào Nhìn vào trải nghiệm trên AWS Management Console để tạo một cluster Amazon ECS mới, tôi có thể thấy tùy chọn mới để sử dụng ECS Managed Instances. Hãy cùng xem qua một lượt tất cả các tùy chọn mới.\nSau khi tôi đã chọn Fargate và Managed Instances, tôi được cung cấp hai tùy chọn. Nếu tôi chọn Use ECS default, Amazon ECS sẽ chọn các loại instance đa dụng (general purpose) dựa trên việc nhóm các Task đang chờ xử lý lại với nhau, và chọn loại instance tối ưu dựa trên các chỉ số về chi phí và khả năng phục hồi (resilience). Đây là cách đơn giản nhất và được khuyến nghị để bắt đầu. Việc chọn Use custom – advanced sẽ mở ra các tham số cấu hình bổ sung, nơi tôi có thể tinh chỉnh các thuộc tính của các instance mà Amazon ECS sẽ sử dụng.\nTheo mặc định, tôi thấy CPU và Bộ nhớ (Memory) là các thuộc tính, nhưng tôi có thể chọn từ 20 thuộc tính bổ sung để tiếp tục lọc danh sách các loại instance có sẵn mà Amazon ECS có thể truy cập.\nSau khi tôi đã thực hiện các lựa chọn thuộc tính của mình, tôi thấy danh sách tất cả các loại instance phù hợp với các lựa chọn đó.\nTừ đây, tôi có thể tạo cluster ECS của mình như bình thường và Amazon ECS sẽ thay mặt tôi cấp phát (provision) các instance dựa trên các thuộc tính và tiêu chí mà tôi đã xác định trong các bước trước đó.\nCác tính năng chính của Amazon ECS Managed Instances Với Amazon ECS Managed Instances, AWS chịu hoàn toàn trách nhiệm về việc quản lý cơ sở hạ tầng, xử lý mọi khía cạnh của việc cấp phát (provisioning), mở rộng quy mô (scaling), và bảo trì (maintenance) instance. Điều này bao gồm việc triển khai các bản vá bảo mật (security patches) định kỳ được bắt đầu mỗi 14 ngày (do việc rút cạn kết nối của instance (instance connection draining), vòng đời thực tế của instance có thể dài hơn), với khả năng lên lịch cho các cửa sổ bảo trì (maintenance windows) sử dụng các cửa sổ sự kiện của Amazon EC2 (Amazon EC2 event windows) để giảm thiểu sự gián đoạn cho các ứng dụng của bạn.\nDịch vụ này cung cấp sự linh hoạt vượt trội trong việc lựa chọn loại instance. Mặc dù theo mặc định, nó tự động chọn các loại instance được tối ưu hóa chi phí, bạn vẫn duy trì quyền chỉ định các thuộc tính instance mong muốn khi các workloads của bạn yêu cầu các khả năng cụ thể. Điều này bao gồm các tùy chọn cho việc tăng tốc GPU, kiến trúc CPU, và các yêu cầu về hiệu năng mạng, mang lại cho bạn sự kiểm soát chính xác đối với môi trường tính toán (compute environment) của mình.\nĐể giúp tối ưu hóa chi phí, Amazon ECS Managed Instances quản lý việc sử dụng tài nguyên một cách thông minh bằng cách tự động đặt nhiều task trên các instance lớn hơn khi thích hợp. Dịch vụ này liên tục theo dõi và tối ưu hóa việc sắp xếp task, dồn các workloads vào ít instance hơn để rút cạn, sử dụng và chấm dứt các instance không hoạt động (rỗng), cung cấp cả tính sẵn sàng cao (high availability) và hiệu quả về chi phí cho các ứng dụng được container hóa của bạn.\nViệc tích hợp với các dịch vụ AWS hiện có là liền mạch, đặc biệt là với các tính năng của Amazon EC2 như các tùy chọn định giá EC2 (EC2 pricing options). Sự tích hợp sâu này có nghĩa là bạn có thể tối đa hóa các khoản đầu tư vào dung lượng hiện có trong khi vẫn duy trì sự đơn giản trong vận hành của một dịch vụ được quản lý hoàn toàn.\nBảo mật vẫn là ưu tiên hàng đầu với Amazon ECS Managed Instances. Dịch vụ này chạy trên Bottlerocket, một hệ điều hành container được xây dựng chuyên dụng, và duy trì tình trạng bảo mật của bạn thông qua các bản vá bảo mật và cập nhật tự động. Bạn có thể xem tất cả các bản cập nhật và vá lỗi được áp dụng cho image hệ điều hành Bottlerocket trên trang web của Bottlerocket. Cách tiếp cận toàn diện về bảo mật này giữ cho các ứng dụng được container hóa của bạn luôn hoạt động trong một môi trường an toàn, được bảo trì.\nHiện đã có mặt Amazon ECS Managed Instances hiện đã có mặt tại các Khu vực AWS (AWS Regions) sau: US East (North Virginia), US West (Oregon), Europe (Ireland), Africa (Cape Town), Asia Pacific (Singapore), và Asia Pacific (Tokyo). Bạn có thể bắt đầu sử dụng Managed Instances thông qua AWS Management Console, AWS Command Line Interface (AWS CLI), hoặc các công cụ cơ sở hạ tầng dưới dạng mã (infrastructure as code - IaC) như AWS Cloud Development Kit (AWS CDK) và AWS CloudFormation. Bạn trả tiền cho các instance EC2 mà bạn sử dụng cộng với một khoản phí quản lý cho dịch vụ.\nĐể tìm hiểu thêm về Amazon ECS Managed Instances, hãy truy cập tài liệu và bắt đầu đơn giản hóa cơ sở hạ tầng container của bạn ngay hôm nay.\nAuthor Micah Walter — Micah Walter là một Kiến trúc sư giải pháp cấp cao (Sr. Solutions Architect) hỗ trợ các khách hàng doanh nghiệp tại khu vực Thành phố New York và xa hơn nữa. Anh ấy tư vấn cho các giám đốc điều hành, kỹ sư, và kiến trúc sư trong mỗi bước trên hành trình lên đám mây (cloud) của họ, với sự tập trung sâu sắc vào tính bền vững và thiết kế thực tiễn. Trong thời gian rảnh, Micah thích các hoạt động ngoài trời, nhiếp ảnh, và đuổi bắt cùng các con quanh nhà.\n"},{"uri":"https://masterltb.github.io/profile/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Amazon hoan nghênh Sắc lệnh Hành pháp và cam kết chăm sóc ung thư nhi Tóm tắt Sắc lệnh thúc đẩy AI cho ung thư nhi và cách AWS hỗ trợ chia sẻ dữ liệu an toàn, hợp tác lâm sàng.\nBlog 2 - Hiện đại hóa phòng chống gian lận: GraphStorm v0.5 cho suy luận thời gian thực GraphStorm v0.5 cho phép phát hiện gian lận real-time với GNN, đơn giản hóa triển khai endpoint SageMaker.\nBlog 3 - Thông báo ra mắt Amazon ECS Managed Instances cho ứng dụng container hóa ECS Managed Instances: compute EC2 được quản lý cho ECS, kết hợp vận hành đơn giản với linh hoạt/chi phí EC2.\n"},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.3-setup-cognito/","title":"5.3 Setup Cognito","tags":[],"description":"","content":"Module 3: Create Cognito User Pool \u0026amp; Authentication Mục tiêu Module Tạo Cognito User Pool mới Cấu hình Sign-up \u0026amp; Sign-in options Tạo App Client cho frontend Thiết lập User Groups (admin, coach, user) Tạo test users Test authentication flow Duration: 3-4 giờ\nPhần 1: Tạo Cognito User Pool Bước 1: Truy cập Cognito Console Login vào AWS Console (https://console.aws.amazon.com/) Tìm kiếm \u0026ldquo;Cognito\u0026rdquo; Click vào \u0026ldquo;Cognito\u0026rdquo; từ services list Click \u0026ldquo;User pools\u0026rdquo; (left menu) Click \u0026ldquo;Create user pool\u0026rdquo; Bước 2: Điền \u0026ldquo;Set up resources for your application\u0026rdquo; Sau khi click \u0026ldquo;Create user pool\u0026rdquo;, bạn sẽ thấy form \u0026ldquo;Set up resources for your application\u0026rdquo;:\n2.1 Define your application Application type: Chọn \u0026ldquo;Single-page application (SPA)\u0026rdquo; Đây là loại ứng dụng React của bạn Name your application: Nhập smoking-cessation-app Giới hạn: 128 ký tự, chỉ chứa chữ, số, spaces, +, =, ,, ., @, - 2.2 Options for sign-in identifiers Chọn các tùy chọn này:\n☑️ Email (Check) ☐ Phone number (Uncheck) ☐ Username (Uncheck) Lý do: Email là cách đơn giản nhất để users đăng nhập\n2.3 Self-registration ☑️ Enable self-registration (Check) Điều này cho phép users tự đăng ký trên platform Sẽ hiển thị link \u0026ldquo;Sign up\u0026rdquo; trên login page 2.4 Required attributes for sign-up Chọn các attributes bắt buộc:\n☑️ email (Already checked vì bạn selected Email for sign-in) ☑️ name (Check - lưu tên người dùng) 2.5 Add a return URL (optional) Click vào field \u0026ldquo;Return URL\u0026rdquo;\nNhập: https://localhost:3000/callback\nĐây là nơi Cognito sẽ redirect sau khi login thành công Note: For development, localhost hỗ trợ HTTP; for production, phải là HTTPS Sau khi điền xong, click \u0026ldquo;Create user directory\u0026rdquo; button ở dưới\nBước 3: Configure Security Requirements Sau khi click \u0026ldquo;Authentication methods\u0026rdquo;, bạn sẽ đến trang \u0026ldquo;Authentication methods\u0026rdquo;:\nPassword policy:\nChon Cognito defaults trong Password policy mode Edit email configuration:\nChọn Send email with Cognito trong Email provider Bấm Save changes Account recovery:\nSelf-service account recovery: ☑️ Enable Recovery method: ☑️ Email ☑️ SMS Bước 4: Configure Sign-up Experience Trang \u0026ldquo;Configure sign-up experience\u0026rdquo;:\nSelf-registration (đã bật ở bước 2):\nEnable self-registration: ✅ Yes Allow users to sign themselves up: ✅ Yes Standard attributes to collect:\n☑️ email (Required) ☑️ name (Required) ☐ phone_number (Optional - không cần) ☐ family_name (Optional - không cần) Verification settings:\nHow will a user be confirmed?: Email Cognito sẽ gửi confirmation link qua email Click \u0026ldquo;Next\u0026rdquo;\nBước 5: Configure Message Delivery Trang \u0026ldquo;Configure message delivery\u0026rdquo;:\nEmail provider:\nSelect: Cognito (default) Note: Free tier cho phép 50 emails/ngày. Cho production, sử dụng Amazon SES. From email address:\nUse Cognito default email Emails sẽ gửi từ no-reply@cognito.amazonaws.com Click \u0026ldquo;Next\u0026rdquo;\nBước 6: Review \u0026amp; Create Trang cuối \u0026ldquo;Review and create\u0026rdquo;:\nReview tất cả settings bạn đã cấu hình:\nApplication type: Single-page application (SPA) Application name: smoking-cessation-app Sign-in experience Security requirements Sign-up experience Message delivery Scroll xuống, nhập User pool name:\nName: smoking-cessation-users Đây là tên của User Pool (khác với Application name) Click \u0026ldquo;Create user pool\u0026rdquo;\n⏳ Chờ khoảng 2-3 phút để user pool được tạo. Bạn sẽ thấy success message khi xong.\nBước 7: Success Page - Quick Setup Guide Sau khi user pool được tạo, bạn sẽ thấy trang \u0026ldquo;Set up resources for your application\u0026rdquo; với các tùy chọn:\nTrang này hiển thị:\n\u0026ldquo;Your application \u0026hellip; have been created successfully!\u0026rdquo; - Thông báo thành công \u0026ldquo;Check out your sign-in page\u0026rdquo; - Liên kết để test login page \u0026ldquo;What\u0026rsquo;s the development platform for your single page application?\u0026rdquo; - Các tùy chọn (React, Angular, JavaScript) Code examples - Hướng dẫn tích hợp với frontend Lưu ý: Bạn sẽ cấu hình code tích hợp ở Module tiếp theo. Bây giờ, hãy click \u0026ldquo;Go to overview\u0026rdquo; ở phía dưới để đi tới user pool overview page.\nPhần 2: Lấy User Pool ID Sau khi user pool được tạo:\nBạn sẽ nhìn thấy success message Note lại User Pool ID: Format là ap-southeast-1_xxxxxxxxxxxxx Ví dụ: ap-southeast-1_GAXOSoku5 Lưu vào file .env: COGNITO_USER_POOL_ID=ap-southeast-1_dskxxxxt3 COGNITO_REGION=ap-southeast-1 Phần 3: Tạo App Client Bước 1: Truy cập App Integration Từ User Pool dashboard (smoking-cessation-users) Left menu: Click \u0026ldquo;App integration\u0026rdquo; Click \u0026ldquo;App clients and analytics\u0026rdquo; Click \u0026ldquo;Create app client\u0026rdquo; Bước 2: Configure App Client App client name: smoking-cessation-frontend Refresh token expiration: 30 days Access token expiration: 1 hour (3600 seconds) ID token expiration: 1 hour (3600 seconds) Token validity units: hours Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Authentication Flows Authentication flows and security Select: ✅ ALLOW_USER_PASSWORD_AUTH (for username/password login) ✅ ALLOW_REFRESH_TOKEN_AUTH (for refresh token rotation) ✅ ALLOW_USER_SRP_AUTH (secure password authentication) Click \u0026ldquo;Next\u0026rdquo; Bước 4: Configure Hosted UI (Optional but Recommended) Hosted UI settings Hosted UI domain name: smoking-cessation-dev Click \u0026ldquo;Check availability\u0026rdquo; If taken, append -{number} (e.g., smoking-cessation-dev-2) Allowed callback URLs (add for your frontend): For development: http://localhost:3000/callback For production: https://yourdomain.com/callback Allowed sign-out URLs: For development: http://localhost:3000/logout For production: https://yourdomain.com/logout Allowed OAuth 2.0 scopes: ✅ openid ✅ email ✅ profile Click \u0026ldquo;Next\u0026rdquo; Bước 5: Advanced Security Settings Advanced security settings Prevent user existence errors: ✅ Enable This prevents attackers from discovering valid usernames Click \u0026ldquo;Create app client\u0026rdquo; ⏳ Chờ app client được tạo\nBước 6: Lấy App Client ID Sau khi App Client được tạo:\nTìm Client ID ở phần app client details Ví dụ: 4175kqc33olfjinhkll4jme379 Lưu vào .env: COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 Phần 4: Tạo User Groups Bước 1: Truy cập User Groups Từ User Pool (smoking-cessation-users) Left menu: Click \u0026ldquo;User groups\u0026rdquo; Click \u0026ldquo;Create group\u0026rdquo; Bước 2: Tạo Admin Group Group name: admins Description: Platform administrators with full access Assign IAM role to this group: (Optional, skip for now) Click \u0026ldquo;Create group\u0026rdquo; Bước 3: Tạo Coach Group Click \u0026ldquo;Create group\u0026rdquo; Group name: coaches Description: Coaches who help users quit smoking Click \u0026ldquo;Create group\u0026rdquo; Bước 4: Tạo User Group Click \u0026ldquo;Create group\u0026rdquo; Group name: users Description: Regular users of the platform Click \u0026ldquo;Create group\u0026rdquo; Phần 5: Tạo Test Users Bước 1: Truy cập Users Từ User Pool (smoking-cessation-users) Left menu: Click \u0026ldquo;Users\u0026rdquo; Click \u0026ldquo;Create user\u0026rdquo; Bước 2: Tạo Admin User Username: admin-test Email address: admin@test.com Temporary password: TempAdminPass123! Mark email as verified: ✅ Check Mark phone number as verified: ☐ Click \u0026ldquo;Create user\u0026rdquo; Bước 3: Gán Admin User vào Admin Group Click vào user admin-test vừa tạo Scroll xuống \u0026ldquo;Group membership\u0026rdquo; Click \u0026ldquo;Add user to groups\u0026rdquo; Chọn admins group Click \u0026ldquo;Add user to groups\u0026rdquo; Bước 4: Tạo Coach User Trở về Users list Click \u0026ldquo;Create user\u0026rdquo; Username: coach-test Email address: coach@test.com Temporary password: TempCoachPass123! Mark email as verified: ✅ Check Click \u0026ldquo;Create user\u0026rdquo; Bước 5: Gán Coach User vào Coach Group Click vào user coach-test Scroll xuống \u0026ldquo;Group membership\u0026rdquo; Click \u0026ldquo;Add user to groups\u0026rdquo; Chọn coaches group Click \u0026ldquo;Add user to groups\u0026rdquo; Bước 6: Tạo Regular User Trở về Users list Click \u0026ldquo;Create user\u0026rdquo; Username: user-test Email address: user@test.com Temporary password: TempUserPass123! Mark email as verified: ✅ Check Click \u0026ldquo;Create user\u0026rdquo; Gán vào users group (tương tự bước 5) Phần 6: Set Permanent Passwords (Optional) Nếu bạn muốn users có thể đăng nhập ngay mà không cần đổi temporary password:\nTừ Users list Click vào user (e.g., admin-test) Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Set password\u0026rdquo; Permanent password: AdminPass123! Make this permanent password: ✅ Check Click \u0026ldquo;Set password\u0026rdquo; Phần 7: Cấu hình App Client Thêm (Authentication Methods) Bước 1: Cấu hình App Client Details Từ User Pool → App integration → App clients Click vào smoking-cessation-frontend Scroll down → \u0026ldquo;Client secret\u0026rdquo; ⚠️ Lưu ý: Nếu bạn tạo Client Secret, frontend JavaScript không thể sử dụng được (vì không thể lưu secret an toàn trên client) Khuyến cáo: Không tạo Client Secret cho public frontend Leave \u0026ldquo;Client secret\u0026rdquo; as-is (không tạo) Phần 8: Enable Cognito Hosted UI (Optional) Bước 1: Cấu hình Hosted UI Domain Từ User Pool → App integration → Domain name If already configured → Skip If not → Click \u0026ldquo;Create domain\u0026rdquo; Domain prefix: smoking-cessation-dev Click \u0026ldquo;Create domain\u0026rdquo; ⏳ Chờ 1-2 phút để domain được tạo\nBước 2: Test Hosted UI Từ App integration → App clients Click vào smoking-cessation-frontend Scroll xuống \u0026ldquo;Hosted UI settings\u0026rdquo; Tìm Hosted UI domain URL: Format: https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com Click link để open Hosted UI Login test: Username: admin-test Password: AdminPass123! Should redirect to http://localhost:3000/callback (or configured callback URL) Phần 9: Thông Tin Tóm Tắt Lưu lại những thông tin này vào .env file:\n# Cognito Configuration COGNITO_REGION=us-east-1 COGNITO_USER_POOL_ID=us-east-1_dskUsnKt3 COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 COGNITO_DOMAIN=smoking-cessation-dev COGNITO_HOSTED_UI_DOMAIN=https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com # Test User Credentials (để remove trước production) TEST_ADMIN_USER=admin-test TEST_ADMIN_PASSWORD=AdminPass123! TEST_COACH_USER=coach-test TEST_COACH_PASSWORD=TempCoachPass123! TEST_USER=user-test TEST_USER_PASSWORD=TempUserPass123! Phần 10: Troubleshooting \u0026ldquo;Email already exists\u0026rdquo; Vấn đề: Tạo user nhưng email đã tồn tại\nGiải pháp:\nTừ Users list Tìm user với email đó Delete nó (nếu test user) Tạo user mới với email khác \u0026ldquo;Temporary password doesn\u0026rsquo;t meet requirements\u0026rdquo; Vấn đề: Password không đủ requirements\nGiải pháp:\nPassword phải: Minimum 12 characters Có uppercase (A-Z) Có lowercase (a-z) Có number (0-9) Có special character (!@#$%^\u0026amp;*) Ví dụ hợp lệ: TempPass123!, AdminTest456! \u0026ldquo;Hosted UI domain not available\u0026rdquo; Vấn đề: Domain đã bị dùng\nGiải pháp:\nThêm số vào suffix: smoking-cessation-dev-2 Hoặc dùng tên khác Checklist User Pool \u0026ldquo;smoking-cessation-users\u0026rdquo; tạo thành công App Client \u0026ldquo;smoking-cessation-frontend\u0026rdquo; tạo thành công 3 User Groups created (admins, coaches, users) 3 test users created \u0026amp; assigned to groups Permanent passwords set for test users Hosted UI domain configured Login test successful with admin-test user .env file updated với Cognito credentials Sẵn sàng cho Module 4 (Setup Lambda) Kết Quả Đạt Được Sau Module 3, bạn sẽ có:\n✅ Cognito User Pool hoạt động đầy đủ ✅ App Client để frontend connect ✅ User Groups (admins, coaches, users) cho role-based access control ✅ Test users để verify authentication flow ✅ Hosted UI domain có thể dùng cho login/signup ✅ Credentials được lưu để dùng trong modules tiếp theo "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.3-week3/","title":"Nhật ký Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3 Hiểu IAM security best practices và credential handling. Tìm hiểu AWS Budgets để kiểm soát chi phí. Thực hành least privilege access patterns. Các nhiệm vụ trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học IAM access keys vs temporary credentials.\n- Tìm hiểu EC2 instance roles và metadata service. 23/09/2025 23/09/2025 https://docs.aws.amazon.com/iam/ 3 - Tạo IAM roles cho EC2 instances.\n- Gán policies với least privilege principle.\n- Test role-based access via metadata endpoint. 24/09/2025 24/09/2025 https://console.aws.amazon.com/iam/ 4 - Thiết lập AWS Budgets để monitor chi phí hàng tháng.\n- Tạo alert thresholds ở 80% và 100% của $50 limit.\n- Xem xét free tier usage patterns và cost drivers. 25/09/2025 25/09/2025 https://console.aws.amazon.com/billing/budgets/ 5 - Cấu hình budget alerts via email notifications.\n- Tìm hiểu cost optimization strategies và Reserved Instances. 26/09/2025 26/09/2025 https://console.aws.amazon.com/ce/ 6 - Thực hành apply permissions policies cho users và roles.\n- Verify least privilege enforcement với test scenarios. 27/09/2025 27/09/2025 https://console.aws.amazon.com/iam/ Kết quả Tuần 3 Chuyển từ hardcoded access keys sang IAM role-based approach. Cấu hình EC2 instance roles để secure access. Thiết lập AWS Budgets và cost monitoring infrastructure. Triển khai least privilege access patterns. Hiểu cost control mechanisms và free tier limits. Các thực hành bảo mật IAM:\nIAM Roles ưu tiên hơn access keys cho applications và EC2 instances. Metadata service cung cấp temporary credentials tự động. Role-based access control đảm bảo security tốt hơn và auditability. Temporary credentials auto-rotate cho enhanced security. Cost monitoring và budget setup:\nAWS Budgets được cấu hình với alerts ở 80% và 100% thresholds. Email notifications theo dõi spending patterns real-time. Budget reviews thường xuyên prevent unexpected charges. Cost monitoring cho early detection của resource waste. "},{"uri":"https://masterltb.github.io/profile/vi/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"Sự kiện 1 Tên sự kiện: AWS Cloud Day Vietnam - AI Edition 2025\nNgày: 18 tháng 9, 2025\nĐịa điểm: Số 2 đường Hải Triều, Phường Bến Nghé, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện và Hoạt động chính Sự kiện AWS Cloud Day Vietnam - AI Edition 2025 đóng vai trò là một diễn đàn then chốt nhằm thúc đẩy quá trình chuyển đổi số của Việt Nam, khai thác sức mạnh của Điện toán đám mây và Trí tuệ nhân tạo. Sự kiện đã khám phá bốn chủ đề cốt lõi:\nPhổ cập AI Tạo sinh cho Doanh nghiệp. Thu hẹp khoảng cách giữa Kinh doanh và CNTT trong lĩnh vực Tài chính. Thúc đẩy Hiện đại hóa theo ngành. Tăng cường các Khuôn khổ Bảo mật. Các hoạt động trong ngày bao gồm các phiên họp toàn thể cấp cao với sự tham gia của các quan chức chính phủ và lãnh đạo ngành, sau đó là các chuyên đề kỹ thuật chuyên sâu tập trung vào Chiến lược Dữ liệu, DevOps, và Lộ trình Di chuyển lên Đám mây.\nBài học Chính và Kết quả Hiểu biết Chiến lược: Có được sự hiểu biết sâu sắc hơn về sự tương tác quan trọng giữa AI Tạo sinh và một chiến lược dữ liệu vững chắc, được xác định là động lực chính cho sự thành công trong các doanh nghiệp hiện đại. Tư duy \u0026ldquo;Di chuyển để Vận hành\u0026rdquo;: Phát triển sự đánh giá cao đối với khuôn khổ \u0026ldquo;Migrate to Operate\u0026rdquo;, nhấn mạnh việc sử dụng AI để tinh giản hoạt động và tối ưu hóa chi phí sau khi di chuyển lên đám mây. Kiến thức Kỹ thuật: Thu được những hiểu biết sâu sắc về việc tích hợp AI Tạo sinh trong vòng đời DevOps, đặc biệt là trong việc tự động hóa tạo mã và kiểm thử. Đổi mới về Bảo mật: Tìm hiểu về phương pháp \u0026ldquo;Bảo mật ngay từ thiết kế\u0026rdquo; (Security by Design), tập trung vào việc nhúng các biện pháp bảo mật trong suốt vòng đời ứng dụng thay vì chỉ dựa vào các biện pháp phòng thủ ở vành đai. Sự kiện này đã cung cấp kiến thức vô giá và những bài học thực tế, nâng cao hơn nữa sự hiểu biết của tôi về sự giao thoa giữa AI, điện toán đám mây và bảo mật trong bối cảnh các giải pháp doanh nghiệp hiện đại.\nSự kiện 2 Tên sự kiện: Khám Phá Agentic AI – Workshop Amazon QuickSuite\nNgày: 7 tháng 11, 2025\nĐịa điểm: Văn phòng AWS Việt Nam, Tháp Tài chính Bitexco, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện và Hoạt động chính Workshop \u0026ldquo;Khám Phá Agentic AI – Amazon QuickSuite\u0026rdquo;, được tổ chức với sự hợp tác của Cloud Kinetics, là một phiên kỹ thuật chiến lược đánh dấu sự phát triển từ AI Tạo sinh thụ động sang AI Tác tử tự chủ. Sự kiện nổi bật với buổi trình diễn trực tiếp đầu tiên của Amazon QuickSuite tại Việt Nam. Workshop tập trung vào bốn trụ cột chính:\nĐịnh nghĩa mô hình \u0026ldquo;Agentic\u0026rdquo;: Tự chủ, Suy luận và Thực thi. Tích hợp Dữ liệu và AI thông qua hệ sinh thái Amazon QuickSuite. Thực hành xây dựng các khái niệm AI với các chuyên gia kỹ thuật của AWS. Hỗ trợ tài chính cho đổi mới thông qua Chương trình AWS LIFT. Chương trình nghị sự kết hợp các phiên kiến trúc lý thuyết với các workshop thực hành sử dụng Amazon QuickSight và Quick Suite Q, cho phép người tham dự xây dựng các khái niệm AI chức năng trong thời gian thực.\nBài học Chính và Kết quả Thay đổi Mô hình: Hiểu rõ sự chuyển đổi từ AI Tạo sinh (tạo nội dung) sang AI Tác tử (thực thi tác vụ tự chủ), nơi các hệ thống có thể nhận thức môi trường và hành động độc lập để giải quyết các vấn đề kinh doanh. Hệ sinh thái Hợp nhất: Có được những hiểu biết thực tế về Amazon QuickSuite, học cách tích hợp trí tuệ doanh nghiệp (QuickSight) với các khả năng tạo sinh để tạo ra các \u0026ldquo;Tác tử Phân tích\u0026rdquo; giúp tinh giản hoạt động. Linh hoạt trong Vận hành: Nhận ra giá trị chiến lược của khuôn khổ \u0026ldquo;Quick\u0026rdquo;, nhấn mạnh vào việc triển khai nhanh chóng và \u0026ldquo;Thời gian tạo ra Giá trị\u0026rdquo;, cho phép các doanh nghiệp triển khai các giải pháp AI phức tạp với tốc độ cao. Hỗ trợ Chiến lược: Tìm hiểu về Chương trình AWS LIFT (cung cấp tín dụng lên tới 80.000 USD), xác định đây là một cơ chế quan trọng để giảm thiểu rủi ro cho R\u0026amp;D và thúc đẩy việc áp dụng tính toán hiệu năng cao. Workshop này đã cung cấp một lộ trình cụ thể để xây dựng các hệ thống doanh nghiệp tự chủ, kết hợp kiến thức lý thuyết với kỹ năng kỹ thuật thực hành và các hiểu biết tài chính chiến lược để thúc đẩy chuyển đổi số.\nSự kiện 3 Tên sự kiện: AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật\nNgày: 1 tháng 12, 2025\nĐịa điểm: Trực tuyến\nTổng quan Sự kiện và Hoạt động chính Workshop chuyên sâu này tập trung vào Trụ cột Bảo mật của Khuôn khổ AWS Well-Architected. Buổi học cung cấp một phương pháp có cấu trúc để đánh giá và bảo mật các khối lượng công việc trên đám mây, bao gồm các lĩnh vực chính như:\nCác phương pháp hay nhất về Quản lý Danh tính và Truy cập (IAM). Các kỹ thuật bảo vệ dữ liệu để mã hóa dữ liệu khi lưu trữ và khi truyền. Các biện pháp kiểm soát phát hiện sử dụng AWS Config, CloudTrail và Security Hub. Bảo vệ cơ sở hạ tầng và phản ứng sự cố tự động. Bài học Chính và Kết quả Mô hình Trách nhiệm Chung: Hiểu rõ về sự phân chia trách nhiệm bảo mật giữa AWS và khách hàng. Bảo mật theo lớp: Học cách áp dụng phương pháp bảo mật đa lớp để bảo vệ tài nguyên đám mây một cách toàn diện, từ rìa mạng đến dữ liệu cá nhân. Bảo mật Tự động: Hiểu được tầm quan trọng của việc tự động hóa các kiểm tra và khắc phục bảo mật để giảm thiểu lỗi của con người và cho phép phản ứng nhanh hơn với các mối đe dọa. Tình trạng Bảo mật Chủ động: Có được các kỹ năng sử dụng các công cụ của AWS để chủ động giám sát và cải thiện tình trạng bảo mật của môi trường đám mây. Sự kiện 4 Tên sự kiện: AWS Cloud Mastery Series #2 - DevOps trên AWS\nNgày: 17 tháng 11, 2025\nĐịa điểm: Tháp Tài chính Bitexco, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện và Hoạt động chính Buổi học chuyên sâu cả ngày này tập trung vào việc triển khai văn hóa và các phương pháp DevOps trên AWS. Workshop bao gồm toàn bộ vòng đời CI/CD, từ kiểm soát nguồn đến triển khai tự động, và khám phá các công nghệ hiện đại bao gồm:\nInfrastructure as Code (IaC) với AWS CloudFormation và CDK. Container hóa với Docker, ECR và ECS/EKS. Xây dựng các đường ống CI/CD tự động bằng bộ dịch vụ AWS Code. Triển khai khả năng quan sát với CloudWatch và AWS X-Ray để truy vết phân tán. Bài học Chính và Kết quả Tự động hóa Toàn diện: Nắm vững khái niệm xây dựng các đường ống phát hành phần mềm hoàn toàn tự động, giảm thiểu sự can thiệp thủ công và tăng tần suất triển khai. IaC là Tiêu chuẩn: Hiểu rằng việc quản lý cơ sở hạ tầng dưới dạng mã là điều cần thiết để có thể lặp lại, nhất quán và ngăn ngừa sự thay đổi cấu hình. Khả năng quan sát trong các Hệ thống Phân tán: Học cách sử dụng AWS X-Ray để truy vết các yêu cầu thông qua các microservice, cung cấp những hiểu biết quan trọng để gỡ lỗi và tối ưu hóa hiệu suất. Đo lường Thành công của DevOps: Có được kiến thức về các chỉ số DORA chính (Tần suất triển khai, MTTR, v.v.) để đo lường và cải thiện hiệu suất của nhóm. "},{"uri":"https://masterltb.github.io/profile/vi/4-eventparticipated/4.4-event4/","title":"AWS Cloud Mastery Series #2 - DevOps trên AWS","tags":[],"description":"","content":"AWS Cloud Mastery Series #2 - DevOps trên AWS - Ngày: 17 tháng 11, 2025 (Cả ngày) - Địa điểm: Bitexco Financial Tower, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện Sự kiện chuyên sâu kéo dài cả ngày này tập trung vào việc áp dụng Văn hóa DevOps, các công cụ CI/CD (Tích hợp liên tục/Triển khai liên tục) của AWS, và các công nghệ hiện đại hóa như Infrastructure as Code (IaC) và Containerization.\nMục tiêu chính:\nPhát triển Tư duy DevOps: Hiểu rõ văn hóa, nguyên tắc và các chỉ số hiệu suất chính (DORA, MTTR, deployment frequency). Xây dựng CI/CD: Nắm vững cách sử dụng bộ dịch vụ AWS Code (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) để tự động hóa quy trình phát hành. Triển khai IaC: Thực hành triển khai và quản lý cơ sở hạ tầng bằng AWS CloudFormation và AWS CDK. Hiện đại hóa Ứng dụng: Tìm hiểu về containerization, lưu trữ (ECR), và quản lý orchestration (ECS/EKS). Cải thiện Observability: Thiết lập hệ thống giám sát toàn diện bằng CloudWatch và AWS X-Ray để truy vết phân tán. Bài học và Kiến thức cốt lõi (Key Takeaways) Văn hóa là Nền tảng: DevOps là sự kết hợp giữa văn hóa, nguyên tắc và công cụ; các chỉ số DORA là thước đo quan trọng cho sự thành công của đội ngũ. Tự động hóa Triệt để: Toàn bộ quá trình từ mã nguồn (CodeCommit) đến triển khai (CodePipeline/CodeDeploy) phải được tự động hóa, ưu tiên các chiến lược triển khai an toàn như Blue/Green và Canary. IaC là Bắt buộc: Quản lý cơ sở hạ tầng dưới dạng mã (IaC) giúp tăng khả năng lặp lại, giảm thiểu lỗi thủ công, và dễ dàng phát hiện độ lệch (drift detection) trong CloudFormation. Container cho Microservices: Sử dụng Docker cùng với các dịch vụ quản lý container của AWS (ECS, EKS, App Runner) là mô hình chuẩn để triển khai kiến trúc microservices. Tracing Phân tán: AWS X-Ray rất cần thiết để hiểu rõ hiệu suất và điểm nghẽn trong các hệ thống phân tán, bổ sung cho các metrics và logs truyền thống của CloudWatch. Ứng dụng vào Công việc (Application to Work) Đo lường DORA: Bắt đầu đo lường các chỉ số DORA (Tần suất triển khai, Thời gian quay vòng thay đổi, Thời gian phục hồi sự cố, Tỷ lệ lỗi thay đổi) cho các dự án hiện tại. Chuyển đổi Pipeline: Lựa chọn một quy trình triển khai thủ công hoặc bán tự động và chuyển đổi hoàn toàn sang AWS CodePipeline với các bước Build (CodeBuild) và Deployment (CodeDeploy) tự động. Thí điểm CDK: Bắt đầu thí điểm sử dụng AWS CDK để định nghĩa và triển khai một dịch vụ nhỏ, tận dụng các ngôn ngữ lập trình quen thuộc (ví dụ: Python/TypeScript). Tích hợp X-Ray: Áp dụng AWS X-Ray cho các microservices mới được phát triển để thu thập dữ liệu truy vết (tracing data) và phân tích hiệu suất giữa các thành phần. Hình ảnh sự kiện "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.4-setup-lambda/","title":"Module 4: Setup Lambda","tags":[],"description":"","content":"Module 4: Create Lambda Functions Mục tiêu Module Tạo 5 Lambda functions từ đầu Cấu hình IAM roles \u0026amp; permissions Thiết lập environment variables Cấu hình Cognito post-confirmation trigger Test Lambda functions Setup monitoring \u0026amp; alarms Duration: 4-5 giờ\nLambda Functions Overview Lambda functions sẽ xử lý các specific events:\nFunction Region Runtime Purpose Memory Timeout CognitoPostConfirmationTrigger us-east-1 nodejs20.x Create user profile khi user signup 256 MB 30s AdminManageCoachesFunction ap-southeast-1 nodejs20.x Manage coaches (CRUD operations) 512 MB 30s image-upload-lambda ap-southeast-1 nodejs20.x Handle image uploads to S3 256 MB 60s leaflungs-websocket-authorizer ap-southeast-1 nodejs20.x Authorize WebSocket connections 256 MB 30s PaymentFunction ap-southeast-1 nodejs24.x Process payments 512 MB 60s Phần 1: Create IAM Role for Lambda Functions Bước 1: Truy cập IAM Console Login vào AWS Console bằng IAM user Tìm kiếm \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; từ services list Left menu: Click \u0026ldquo;Roles\u0026rdquo; Click \u0026ldquo;Create role\u0026rdquo; Bước 2: Configure Trust Relationship Trusted entity type: Select \u0026ldquo;AWS service\u0026rdquo; Service or use case: Search và click \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Bước 3: Add Permissions Search và check policies: ✅ AWSLambdaVPCAccessExecutionRole (for EC2 database access) ✅ AWSLambdaBasicExecutionRole (for CloudWatch logs) ✅ AmazonS3FullAccess (for image upload function) ✅ SecretsManagerReadSecret (for database credentials) Click \u0026ldquo;Next\u0026rdquo; Bước 4: Review \u0026amp; Create Role name: smoking-cessation-lambda-role Description: Lambda execution role for smoking cessation platform Click \u0026ldquo;Create role\u0026rdquo; ⏳ Chờ role được tạo\nBước 5: Note Role ARN Click vào role vừa tạo: smoking-cessation-lambda-role Copy Role ARN: Format là arn:aws:iam::014097726842:role/smoking-cessation-lambda-role Lưu lại để dùng trong modules tiếp theo Phần 2: Create Cognito Post-Confirmation Trigger (us-east-1) Bước 1: Truy cập Lambda Console Login vào AWS Console Tìm kiếm \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Lambda\u0026rdquo; service Chọn region: us-east-1 (phải giống với Cognito) Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Function Basics Function name: smoking-cessation-cognito-post-confirmation Runtime: nodejs20.x Execution role: Select \u0026ldquo;Use an existing role\u0026rdquo; Existing role: smoking-cessation-lambda-role (từ Phần 1) Click \u0026ldquo;Create function\u0026rdquo; ⏳ Chờ function được tạo (khoảng 1-2 phút)\nBước 3: Configure General Settings Scroll xuống \u0026ldquo;General configuration\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Memory: 256 MB (default) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Environment Variables Scroll xuống \u0026ldquo;Environment variables\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Add the following variables: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager later) PG_DATABASE = smoking_cessation PG_PORT = 5432 COGNITO_USER_POOL_ID = (get from Module 3) Click \u0026ldquo;Save\u0026rdquo; Bước 5: Add Placeholder Code Click \u0026ldquo;Code\u0026rdquo; tab In the code editor, replace everything with: exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Cognito post-confirmation event:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.request.userAttributes.sub; const email = event.request.userAttributes.email; const name = event.request.userAttributes.name; console.log(`Creating user profile for ${email}`); // TODO: Implement database connection to PostgreSQL // Create user record in users table // Initialize coaching session if needed return event; } catch (error) { console.error(\u0026#39;Error in post-confirmation:\u0026#39;, error); throw error; } }; Click \u0026ldquo;Deploy\u0026rdquo; Bước 6: Add Cognito Trigger (Later) Note: Sau khi deploy code, bạn sẽ cấu hình Cognito trigger ở Phần 8\nPhần 3: Create Admin Manage Coaches Function (ap-southeast-1) Bước 1: Switch to ap-southeast-1 Region Top left: Click region dropdown Select ap-southeast-1 Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Function Function name: smoking-cessation-admin-manage-coaches Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; ⏳ Chờ function được tạo\nBước 3: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (for database operations) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager) PG_DATABASE = smoking_cessation API_REGION = ap-southeast-1 Click \u0026ldquo;Save\u0026rdquo; Bước 5: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Admin coaches request:\u0026#39;, JSON.stringify(event, null, 2)); try { const httpMethod = event.httpMethod; const path = event.path; const body = event.body ? JSON.parse(event.body) : {}; console.log(`${httpMethod} ${path}`); // TODO: Implement database operations // GET /admin/coaches - List all coaches // POST /admin/coaches - Create new coach // PUT /admin/coaches/{id} - Update coach // DELETE /admin/coaches/{id} - Delete coach // Include RBAC check (admin only) return { statusCode: 200, body: JSON.stringify({ message: \u0026#39;Coaches function placeholder\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 4: Create Image Upload Lambda (ap-southeast-1) Bước 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-image-upload Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 256 MB Timeout: 60 seconds (vì file upload có thể mất thời gian) Click \u0026ldquo;Save\u0026rdquo; Bước 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: S3_BUCKET = smoking-cessation-images S3_REGION = ap-southeast-1 MAX_FILE_SIZE = 10485760 Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Image upload request:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.requestContext.authorizer.claims.sub; const fileBuffer = Buffer.from(event.body, \u0026#39;base64\u0026#39;); const fileName = event.headers[\u0026#39;x-filename\u0026#39;] || `image-${Date.now()}.jpg`; console.log(`Uploading ${fileName} for user ${userId}`); // TODO: Implement S3 upload // Validate file size (max 10MB) // Upload to S3 with user prefix // Generate pre-signed URL // Store reference in database const s3Url = `https://${process.env.S3_BUCKET}.s3.${process.env.S3_REGION}.amazonaws.com/${userId}/${fileName}`; return { statusCode: 200, body: JSON.stringify({ url: s3Url }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 5: Create WebSocket Authorizer Lambda (ap-southeast-1) Bước 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-websocket-authorizer Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 256 MB Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: COGNITO_USER_POOL_ID = (from Module 3) COGNITO_CLIENT_ID = (from Module 3) JWT_SECRET = (will be set via Secrets Manager) Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;WebSocket authorization event:\u0026#39;, JSON.stringify(event, null, 2)); try { const token = event.authorizationToken; if (!token) { throw new Error(\u0026#39;No authorization token\u0026#39;); } console.log(\u0026#39;Validating WebSocket token\u0026#39;); // TODO: Implement JWT token validation // Validate token signature // Check token expiration // Extract user ID from token // Placeholder authorization response return { principalId: \u0026#39;user-id-placeholder\u0026#39;, policyDocument: { Version: \u0026#39;2012-10-17\u0026#39;, Statement: [ { Action: \u0026#39;execute-api:Invoke\u0026#39;, Effect: \u0026#39;Allow\u0026#39;, Resource: event.methodArn } ] } }; } catch (error) { console.error(\u0026#39;Authorization failed:\u0026#39;, error); throw new Error(\u0026#39;Unauthorized\u0026#39;); } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 6: Create Payment Function (ap-southeast-1) Bước 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-payment Runtime: nodejs24.x (latest version) Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (payment processing needs resources) Timeout: 60 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager) PG_DATABASE = smoking_cessation STRIPE_API_KEY = (will be set via Secrets Manager) STRIPE_WEBHOOK_SECRET = (will be set via Secrets Manager) PAYMENT_TABLE = payments Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Payment event:\u0026#39;, JSON.stringify(event, null, 2)); try { const { userId, amount, paymentMethod, description } = JSON.parse(event.body); console.log(`Processing payment for user ${userId}: $${amount}`); // TODO: Implement payment processing // Validate amount // Process payment via Stripe/Payment gateway // Store payment record in database // Send confirmation email // Handle webhooks return { statusCode: 200, body: JSON.stringify({ success: true, transactionId: `txn-${Date.now()}`, message: \u0026#39;Payment processed successfully\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Payment error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 7: Create Secrets Manager for Database Credentials Bước 1: Truy cập Secrets Manager Tìm kiếm \u0026ldquo;Secrets Manager\u0026rdquo; Click service Click \u0026ldquo;Store a new secret\u0026rdquo; Bước 2: Store Database Password Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: db-password Value: \u0026lt;your-postgres-password\u0026gt; Click \u0026ldquo;Next\u0026rdquo; Secret name: smoking-cessation/db-password Click \u0026ldquo;Store secret\u0026rdquo; Bước 3: Store Payment Credentials (Optional) Click \u0026ldquo;Store a new secret\u0026rdquo; Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: stripe-api-key Value: \u0026lt;your-stripe-key\u0026gt; Secret name: smoking-cessation/stripe-api-key Click \u0026ldquo;Store secret\u0026rdquo; Bước 4: Update Lambda IAM Role Lambda needs permission to read secrets:\nGo to IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Select \u0026ldquo;JSON\u0026rdquo; tab Paste: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:secretsmanager:*:*:secret:smoking-cessation/*\u0026#34; ] } ] } Click \u0026ldquo;Review policy\u0026rdquo; Policy name: lambda-secrets-access Click \u0026ldquo;Create policy\u0026rdquo; Phần 8: Configure Cognito Post-Confirmation Trigger Bước 1: Go to Cognito User Pool Switch region to us-east-1 Tìm kiếm \u0026ldquo;Cognito\u0026rdquo; Click Cognito service Click \u0026ldquo;User pools\u0026rdquo; Click vào user pool: smoking-cessation-users (tạo ở Module 3) Bước 2: Add Lambda Trigger Left menu: Click \u0026ldquo;User lifecycle\u0026rdquo; Click \u0026ldquo;Post confirmation\u0026rdquo; Click \u0026ldquo;Add Lambda trigger\u0026rdquo; Lambda function: smoking-cessation-cognito-post-confirmation Click \u0026ldquo;Save\u0026rdquo; Bước 3: Verify Trigger Refresh page Verify trigger shows: Trigger: Post confirmation Function: smoking-cessation-cognito-post-confirmation (us-east-1) Status: Active Phần 9: Grant Cognito Permission to Invoke Lambda Cognito cần permission để gọi Lambda function:\nBước 1: Add Resource-Based Policy Switch to us-east-1 region Go to Lambda console Click function: smoking-cessation-cognito-post-confirmation Scroll xuống \u0026ldquo;Resource-based policy statements\u0026rdquo; Click \u0026ldquo;Add permissions\u0026rdquo; Statement ID: AllowCognitoInvoke Principal: cognito-idp.amazonaws.com Action: lambda:InvokeFunction Source account: Source ARN: arn:aws:cognito-idp:us-east-1:\u0026lt;account-id\u0026gt;:userpool/\u0026lt;user-pool-id\u0026gt; Click \u0026ldquo;Save\u0026rdquo; Phần 10: Test Lambda Functions Bước 1: Test Cognito Post-Confirmation Trigger Go to Lambda console (us-east-1) Click function: smoking-cessation-cognito-post-confirmation Click \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;userAttributes\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;12345678-1234-1234-1234-123456789012\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Test User\u0026#34; } }, \u0026#34;response\u0026#34;: {} } Click \u0026ldquo;Test\u0026rdquo; Verify: ✅ Execution result: Succeeded ✅ CloudWatch logs show console.log output Bước 2: Test Admin Coaches Function Switch to ap-southeast-1 Click function: smoking-cessation-admin-manage-coaches Click \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/admin/coaches\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer test-token\u0026#34; }, \u0026#34;body\u0026#34;: null } Click \u0026ldquo;Test\u0026rdquo; Verify status code 200 in response Bước 3: Test Image Upload Function Click function: smoking-cessation-image-upload Click \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/upload\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;x-filename\u0026#34;: \u0026#34;test-image.jpg\u0026#34; }, \u0026#34;body\u0026#34;: \u0026#34;base64-encoded-image-data\u0026#34;, \u0026#34;requestContext\u0026#34;: { \u0026#34;authorizer\u0026#34;: { \u0026#34;claims\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;user-123\u0026#34; } } } } Click \u0026ldquo;Test\u0026rdquo; Verify response contains S3 URL Bước 4: View CloudWatch Logs Click \u0026ldquo;Monitor\u0026rdquo; tab của bất kỳ function nào Click \u0026ldquo;View logs in CloudWatch\u0026rdquo; Select most recent log stream Verify logs show: Input event Console.log statements Execution time Phần 11: Create CloudWatch Alarms Bước 1: Create Error Alarm Tìm kiếm \u0026ldquo;CloudWatch\u0026rdquo; Click \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;All alarms\u0026rdquo; Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda Dimension: Function name Statistic: Sum Function: smoking-cessation-admin-manage-coaches Metric: Errors Threshold: \u0026gt; 5 in 1 minute Click \u0026ldquo;Next\u0026rdquo; Action: Create SNS topic Topic name: smoking-cessation-lambda-errors Email endpoint: your-email@example.com Click \u0026ldquo;Create alarm\u0026rdquo; Check email để verify SNS subscription Bước 2: Create Duration Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda → Durations Function: smoking-cessation-admin-manage-coaches Statistic: Average Threshold: \u0026gt; 20 seconds (warning if approaching 30s timeout) Click \u0026ldquo;Next\u0026rdquo; Action: Use existing SNS topic smoking-cessation-lambda-errors Click \u0026ldquo;Create alarm\u0026rdquo; Bước 3: Create Throttle Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Lambda → Throttles Function: All functions Threshold: \u0026gt; 0 Click \u0026ldquo;Next\u0026rdquo; Action: Notify via SNS Click \u0026ldquo;Create alarm\u0026rdquo; Phần 12: Enable X-Ray Tracing (Optional) Bước 1: Update IAM Role Go to IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Attach policies directly\u0026rdquo; Search: AWSXRayWriteAccess Check ✅ Click \u0026ldquo;Attach policies\u0026rdquo; Bước 2: Enable X-Ray on Functions For each Lambda function:\nClick function Click \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;Monitoring and operations tools\u0026rdquo; Under \u0026ldquo;X-Ray\u0026rdquo;: Check ✅ \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Environment Variables Summary Cognito Post-Confirmation Function (us-east-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation PG_PORT=5432 COGNITO_USER_POOL_ID=(from Module 3) Admin Coaches \u0026amp; Payment Functions (ap-southeast-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation API_REGION=ap-southeast-1 STRIPE_API_KEY=(from Secrets Manager) STRIPE_WEBHOOK_SECRET=(from Secrets Manager) Image Upload Function (ap-southeast-1) S3_BUCKET=smoking-cessation-images S3_REGION=ap-southeast-1 MAX_FILE_SIZE=10485760 WebSocket Authorizer (ap-southeast-1) COGNITO_USER_POOL_ID=(from Module 3) COGNITO_CLIENT_ID=(from Module 3) JWT_SECRET=(from Secrets Manager) Checklist IAM role smoking-cessation-lambda-role created Cognito Post-Confirmation function created (us-east-1) Admin Coaches function created (ap-southeast-1) Image Upload function created (ap-southeast-1) WebSocket Authorizer function created (ap-southeast-1) Payment function created (ap-southeast-1) All functions have correct runtime \u0026amp; memory Environment variables configured for all functions Secrets Manager setup (db-password, stripe-api-key) Cognito trigger configured (post-confirmation) Lambda resource-based policy added for Cognito All functions tested successfully CloudWatch alarms created (errors, duration, throttles) X-Ray tracing enabled (optional) CloudWatch logs reviewed Sẵn sàng cho Module 5 (Setup API Gateway) Troubleshooting Function Execution Failed Issue: \u0026ldquo;An error occurred while getting the logs from CloudWatch\u0026rdquo;\nSolution:\nCheck IAM role has AWSLambdaBasicExecutionRole Wait 1-2 minutes for logs to appear Check function code for syntax errors Cognito Trigger Not Working Issue: \u0026ldquo;User created but Lambda function didn\u0026rsquo;t execute\u0026rdquo;\nSolution:\nVerify trigger is enabled in Cognito console Check Lambda resource-based policy exists Review CloudWatch logs for errors Check IAM role permissions Timeout Errors Issue: \u0026ldquo;Task timed out after 30 seconds\u0026rdquo;\nSolution:\nIncrease timeout to 60 seconds Check database connectivity (VPC configuration in Module 8) Add console logs to identify slow operations Consider increasing memory (also increases CPU) Permission Denied Issue: \u0026ldquo;User is not authorized to perform: secretsmanager:GetSecretValue\u0026rdquo;\nSolution:\nAdd secrets manager policy to Lambda role Verify policy resource ARN matches secret name Check secret exists in correct region Cold Start Issues Issue: \u0026ldquo;High duration on first invocation\u0026rdquo;\nSolution:\nIncrease memory allocation (256 → 512 MB) Consider provisioned concurrency for frequently used functions Optimize code dependencies Next Steps Implement actual code for each Lambda function (provided separately) Setup database connections to EC2 instances (Module 6) Create API Gateway routes (Module 5) Test end-to-end flow Optimize based on CloudWatch metrics Kết Quả Đạt Được Sau Module 4, bạn sẽ có:\n✅ 5 Lambda functions created và deployed ✅ IAM role với appropriate permissions ✅ Environment variables configured ✅ Secrets Manager setup cho sensitive data ✅ Cognito post-confirmation trigger configured ✅ Resource-based policies for Cognito invocation ✅ CloudWatch alarms setup ✅ X-Ray tracing enabled (optional) ✅ All functions tested và verified ✅ Sẵn sàng cho Module 5 (Create API Gateway) "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.4-week4/","title":"Nhật ký Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4 Thiết kế và triển khai VPC infrastructure. Cấu hình networking components: subnets, route tables, gateways. Triển khai security groups và network ACLs. Hiểu AWS Support plans. Các nhiệm vụ trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Xem xét AWS Support plans (Basic, Developer, Business, Enterprise).\n- Hiểu SLA, response times, và support channels cho mỗi tier. 30/09/2025 30/09/2025 https://aws.amazon.com/support/plans/ 3 - Thiết kế VPC với CIDR block 10.0.0.0/16.\n- Tạo public và private subnets across multiple AZs. 01/10/2025 01/10/2025 https://console.aws.amazon.com/vpc/ 4 - Cấu hình Internet Gateway (IGW) cho public subnet access.\n- Thiết lập NAT Gateway ở public subnet cho private subnet internet access.\n- Tạo và cấu hình route tables cho traffic routing. 02/10/2025 02/10/2025 https://console.aws.amazon.com/vpc/ 5 - Tạo security groups với inbound/outbound rules.\n- Triển khai Network ACLs cho stateless filtering.\n- Test connectivity giữa public và private subnets. 03/10/2025 03/10/2025 https://console.aws.amazon.com/vpc/ 6 - Bật VPC Flow Logs cho network traffic monitoring.\n- Xem xét security best practices và compliance requirements. 04/10/2025 04/10/2025 https://console.aws.amazon.com/vpc/ Kết quả Tuần 4 Thiết kế và triển khai multi-AZ VPC infrastructure. Cấu hình internet và NAT gateways cho controlled connectivity. Triển khai tiered security với Security Groups và Network ACLs. Bật network visibility với VPC Flow Logs. Hiểu AWS Support ecosystem và select appropriate support plan. Những điều quan trọng học được:\nVPC design nên có multiple AZs cho high availability. Public/Private subnet separation critical cho security. Security Groups stateful; Network ACLs stateless. Regular security group reviews prevent overly permissive rules. "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"XÂY DỰNG HỆ THỐNG SMOKING-CESSATION TRÊN AWS TỪ A → Z Workshop này hướng dẫn triển khai toàn bộ hệ thống thực tế bao gồm: Backend (Lambda + API Gateway), Databases (PostgreSQL + MongoDB), Authentication (Cognito), Infrastructure (VPC, EC2, Security), Frontend hosting (S3 + CloudFront), Monitoring (CloudWatch), và Cleanup.\nMỗi module tương ứng với một phần kiến trúc quan trọng trong hệ thống.\n🎯 Mục tiêu tổng quan Sau toàn bộ workshop, bạn sẽ nắm được:\nXây dựng hệ thống microservices trên AWS Quản lý user authentication bằng Cognito Tạo \u0026amp; vận hành Lambda serverless backend Publish API bằng API Gateway Tạo database server trên EC2 Cấu hình VPC, subnet, NAT Gateway, Security Groups Host frontend bằng S3 + CloudFront Theo dõi \u0026amp; giám sát bằng CloudWatch Tối ưu chi phí \u0026amp; dọn dẹp tài nguyên 🧩 Kiến trúc tổng quan hệ thống Full architecture bao gồm:\n8 Lambda Functions 2 REST APIs (User API + Chat API) 2 Databases trên EC2 (PostgreSQL + MongoDB) S3 + CloudFront cho frontend Cognito User Pool để đăng ký / đăng nhập VPC hoàn chỉnh với NAT, IGW, NLB CloudWatch Monitoring + Alarms Secrets Manager cho sensitive data 📚 Nội dung Workshop (10 Modules) Mỗi module đều có hướng dẫn step-by-step kèm hình minh họa.\n1️⃣ Giới thiệu Workshop Phác thảo mục tiêu dự án, kiến trúc tổng quan và các thành phần AWS sẽ sử dụng.\n2️⃣ Điều kiện tiên quyết Chuẩn bị môi trường AWS, IAM user, VS Code, SSH key, CLI tools, cấu trúc thư mục dự án.\n3️⃣ Cấu hình Cognito Tạo User Pool, App Client, Password Policy, Post-confirmation Trigger, Email Verification.\n4️⃣ Cấu hình Lambda Functions Tạo 5 Lambda functions cho hệ thống, gán IAM Role, thêm environment variables, kết nối Secrets Manager.\n5️⃣ Cấu hình API Gateway Tạo 2 REST APIs, mapping với Lambda, bật CORS, request validation, throttling, test API end-to-end.\n6️⃣ Cấu hình RDS \u0026amp; Database EC2 Tạo 2 EC2 database servers, cài PostgreSQL + MongoDB, tạo user, schema, SSH hardening, backup scripts.\n7️⃣ Cấu hình S3 + CloudFront Tạo S3 hosting cho frontend React, cấu hình OAC, tạo CloudFront distribution, SSL, caching, invalidation.\n8️⃣ Cấu hình VPC \u0026amp; Security Khởi tạo VPC, subnets, route tables, NAT Gateway, IGW, SGs, NLB cho WebSocket, GuardDuty + Flow Logs.\n9️⃣ Monitoring \u0026amp; Logging Tạo CloudWatch dashboards, alarms, SNS notifications, CloudTrail, X-Ray distributed tracing.\n🔟 Cleanup \u0026amp; Cost Optimization Kiểm tra tài nguyên còn dùng, phân tích chi phí, backup databases, xóa API, EC2, Lambda, S3, CloudFront.\n✔ Kết luận Workshop này giúp bạn xây dựng một hệ thống hoàn chỉnh, bảo mật, tối ưu chi phí theo đúng chuẩn AWS Production.\nBạn đã sẵn sàng bắt đầu với Module 5.1 — Introduction.\n"},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.5-setup-api-gateway/","title":"5.5 Setup API Gateway","tags":[],"description":"","content":"Module 5: Create API Gateway REST APIs Mục tiêu Module Tạo 2 REST APIs từ đầu Tạo resources \u0026amp; methods Integrate với Lambda functions Cấu hình authentication \u0026amp; authorization Setup CORS \u0026amp; rate limiting Deploy \u0026amp; test APIs Duration: 3-4 giờ\nAPI Gateway Overview 2 REST APIs sẽ được tạo:\nAPI Name Region Purpose Resources Methods smoking-cessation-user-api ap-southeast-1 User management, Admin operations /admin/coaches, /api/user-info, /upload GET, POST, PUT, DELETE smoking-cessation-chat-api ap-southeast-1 Chat \u0026amp; WebSocket /chat/rooms, /chat/messages, /ws GET, POST, WebSocket Phần 1: Create First REST API (User Management) Bước 1: Truy cập API Gateway Console Login vào AWS Console Tìm kiếm \u0026ldquo;API Gateway\u0026rdquo; Click \u0026ldquo;API Gateway\u0026rdquo; service Chọn region: ap-southeast-1 Click \u0026ldquo;Create API\u0026rdquo; Bước 2: Choose API Type Chọn \u0026ldquo;REST API\u0026rdquo; Click \u0026ldquo;Build\u0026rdquo; Bước 3: Configure API Details API name: smoking-cessation-user-api Description: REST API for user management and admin operations Endpoint type: Regional Click \u0026ldquo;Create API\u0026rdquo; ⏳ Chờ API được tạo (khoảng 1-2 phút)\nBước 4: View API Dashboard Sau khi API tạo xong, bạn sẽ thấy:\nResources tree (currently only \u0026ldquo;/\u0026rdquo; root) Methods available for root Integration settings Phần 2: Create /admin Resource \u0026amp; /admin/coaches Sub-resource Bước 1: Create /admin Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: admin Resource path: /admin ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 2: Create /admin/coaches Sub-resource Click vào /admin resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: coaches Resource path: coaches (automatically becomes /admin/coaches) ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 3: Create GET Method for /admin/coaches Click vào /admin/coaches resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;GET\u0026rdquo; Click checkmark to confirm Bước 4: Configure GET Method Integration Integration type: Lambda Function Lambda Region: ap-southeast-1 Lambda Function: smoking-cessation-admin-manage-coaches ✅ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Confirm the permission popup Bước 5: Create POST Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;POST\u0026rdquo; Same integration as GET: Integration type: Lambda Function Lambda Function: smoking-cessation-admin-manage-coaches ✅ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Bước 6: Create PUT Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;PUT\u0026rdquo; Same Lambda integration Click \u0026ldquo;Save\u0026rdquo; Bước 7: Create DELETE Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;DELETE\u0026rdquo; Same Lambda integration Click \u0026ldquo;Save\u0026rdquo; Result: /admin/coaches now has GET, POST, PUT, DELETE methods\nPhần 3: Create /api/user-info Resource \u0026amp; Sub-resources Bước 1: Create /api Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: api Resource path: /api ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 2: Create /api/user-info Resource Click vào /api resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: user-info Resource path: user-info ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 3: Create Methods for /api/user-info Create GET, POST, PUT, DELETE methods (same as /admin/coaches):\nFor each method: Click \u0026ldquo;Create Method\u0026rdquo; Select method type Integration: smoking-cessation-admin-manage-coaches Lambda ✅ Lambda Proxy integration Save Bước 4: Create /{id} Resource (Path Parameter) Click vào /api/user-info Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: {id} Resource path: {id} Click \u0026ldquo;Create Resource\u0026rdquo; Bước 5: Create GET Method for /api/user-info/{id} Click vào /{id} resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;GET\u0026rdquo; Integration: smoking-cessation-admin-manage-coaches Lambda Save Bước 6: Create /by-user-id Resource Click vào /api/user-info (parent) Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: by-user-id Resource path: by-user-id Click \u0026ldquo;Create Resource\u0026rdquo; Add GET method with Lambda integration Bước 7: Create /empty Resource Click vào /api/user-info (parent) Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: empty Resource path: empty Click \u0026ldquo;Create Resource\u0026rdquo; Add GET method with Lambda integration Result: /api/user-info resource tree created with all sub-resources\nPhần 4: Create /upload Resource Bước 1: Create /upload Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: upload Resource path: /upload ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 2: Create POST Method Click vào /upload resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;POST\u0026rdquo; Integration type: Lambda Function Lambda Function: smoking-cessation-image-upload ✅ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Phần 5: Configure Authentication \u0026amp; Authorization Bước 1: Create Cognito Authorizer Left menu: Click \u0026ldquo;Authorizers\u0026rdquo; Click \u0026ldquo;Create Authorizer\u0026rdquo; Authorizer name: cognito-user-pool-authorizer Type: Cognito Cognito User Pool: smoking-cessation-users (tạo ở Module 3) Token source: Authorization Click \u0026ldquo;Create authorizer\u0026rdquo; Bước 2: Test Authorizer (Optional) Token: (enter a valid JWT token from your Cognito user pool) Click \u0026ldquo;Test authorizer\u0026rdquo; Verify response shows user claims Bước 3: Add Authorization to Methods For critical endpoints (e.g., /admin/coaches):\nClick vào /admin/coaches resource Click \u0026ldquo;GET\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Authorization: Select cognito-user-pool-authorizer Click checkmark to save Repeat for POST, PUT, DELETE methods Phần 6: Setup Request Validators Bước 1: Create Request Validator Left menu: Click \u0026ldquo;Request Validators\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: validate-body-and-params ✅ \u0026ldquo;Validate request body\u0026rdquo; ✅ \u0026ldquo;Validate query string parameters and headers\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Bước 2: Apply Validator to POST Methods Click vào /admin/coaches → \u0026ldquo;POST\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Request Validator: Select validate-body-and-params Save Phần 7: Setup CORS Bước 1: Enable CORS for All Resources Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Enable CORS\u0026rdquo; Review default settings Click \u0026ldquo;Enable CORS and replace existing CORS headers\u0026rdquo; Bước 2: Configure CORS Headers CORS headers automatically configured:\nAccess-Control-Allow-Headers: Content-Type, X-Amz-Date, Authorization, X-Api-Key, X-Amz-Security-Token Access-Control-Allow-Methods: GET, POST, PUT, DELETE, OPTIONS Access-Control-Allow-Origin: * (for dev, restrict in production) Phần 8: Create Second API - Chat API (WebSocket) Bước 1: Create WebSocket API Click \u0026ldquo;Create API\u0026rdquo; Select \u0026ldquo;WebSocket API\u0026rdquo; Click \u0026ldquo;Build\u0026rdquo; Bước 2: Configure WebSocket API API name: smoking-cessation-chat-api Description: WebSocket API for chat functionality Route Selection Expression: $request.body.action Click \u0026ldquo;Create API\u0026rdquo; ⏳ Chờ API được tạo\nBước 3: Create Routes Create default routes:\n$default route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $connect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $disconnect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer Phần 9: Deploy APIs Bước 1: Create Deployment Stage For User API:\nClick \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Stage description: Production environment Click \u0026ldquo;Deploy\u0026rdquo; Bước 2: Note API Endpoint After deployment, you\u0026rsquo;ll see:\nInvoke URL: https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod Save this URL Bước 3: Deploy Chat API Go to Chat API Click \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Click \u0026ldquo;Deploy\u0026rdquo; Note the WebSocket Invoke URL Phần 10: Test REST API Endpoints Bước 1: Test GET /admin/coaches In API Gateway console:\nSelect User API Click /admin/coaches → \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: GET\nPath: /admin/coaches\nHeaders:\nAuthorization: Bearer {your-cognito-token} Click \u0026ldquo;Test\u0026rdquo;\nExpected result:\nStatus: 200 Body: JSON response from Lambda Bước 2: Test POST /admin/coaches Click /admin/coaches → \u0026ldquo;POST\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: POST Headers: Authorization: Bearer {your-cognito-token} Content-Type: application/json Body: { \u0026#34;name\u0026#34;: \u0026#34;Coach Name\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;coach@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; } Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with created coach data Bước 3: Test /upload Endpoint Click /upload → \u0026ldquo;POST\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: POST Headers: Authorization: Bearer {your-cognito-token} Content-Type: multipart/form-data Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with S3 URL Bước 4: Test with cURL (Optional) # Get list of coaches curl -X GET \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; # Create new coach curl -X POST \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Coach John\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; }\u0026#39; Phần 11: Setup CloudWatch Logging Bước 1: Enable Full Request/Response Logging Click \u0026ldquo;Settings\u0026rdquo; (left menu) CloudWatch log role ARN: Click \u0026ldquo;Edit\u0026rdquo; Select or create IAM role for API Gateway logging Role should have logs:CreateLogGroup, logs:CreateLogStream, logs:PutLogEvents permissions Click \u0026ldquo;Save changes\u0026rdquo; Bước 2: Set Log Level Go to \u0026ldquo;Stages\u0026rdquo; → \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Logs\u0026rdquo; ✅ \u0026ldquo;Enable CloudWatch Logs\u0026rdquo; Log level: INFO (or DEBUG for troubleshooting) Data trace enabled: ✅ Full request/response data: ✅ Click \u0026ldquo;Save changes\u0026rdquo; Bước 3: View Logs Tìm kiếm \u0026ldquo;CloudWatch\u0026rdquo; Click \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Logs\u0026rdquo; → \u0026ldquo;Log groups\u0026rdquo; Search for API-Gateway-Execution-Logs_{api-id} View recent requests Phần 12: Setup Rate Limiting (Usage Plans) Bước 1: Create API Key Left menu: Click \u0026ldquo;API Keys\u0026rdquo; Click \u0026ldquo;Create API Key\u0026rdquo; Name: mobile-app-key Description: API key for mobile app Click \u0026ldquo;Create API Key\u0026rdquo; Copy and save the key Bước 2: Create Usage Plan Left menu: Click \u0026ldquo;Usage Plans\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: free-tier-plan Description: Free tier plan with rate limiting Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Throttling \u0026amp; Quota Rate: 100 requests per second Burst: 200 requests Quota: 1,000,000 requests per month Click \u0026ldquo;Next\u0026rdquo; Bước 4: Associate API to Plan Associated API Stages: Select User API Select stage: prod Click \u0026ldquo;Next\u0026rdquo; Bước 5: Associate API Key to Plan API Keys: Search and select mobile-app-key Click \u0026ldquo;Finish\u0026rdquo; Phần 13: Setup Resource-Based Policy (Optional) To restrict API access to specific IAM users/roles:\nBước 1: Add Resource Policy Left menu: Click \u0026ldquo;Resource Policy\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;execute-api:Invoke\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;execute-api:/*\u0026#34; } ] } Click \u0026ldquo;Save\u0026rdquo; Phần 14: Enable API Caching (Optional) Bước 1: Enable Cache for GET Endpoints Go to stage: \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Settings\u0026rdquo; Cache cluster enabled: ✅ Cache cluster size: 0.5 (smallest) Click \u0026ldquo;Save changes\u0026rdquo; Bước 2: Configure Cache per Method Click vào /admin/coaches → \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Integration Response\u0026rdquo; Expand \u0026ldquo;200\u0026rdquo; response Cache settings: ✅ \u0026ldquo;Enable method caching\u0026rdquo; Cache time to live (TTL): 300 seconds (5 minutes) Click checkmark Environment Variables Summary Save these URLs after API deployment:\n# User Management API USER_API_ENDPOINT=https://{api-id-1}.execute-api.ap-southeast-1.amazonaws.com/prod USER_API_ID={api-id-1} # Chat API (WebSocket) CHAT_API_ENDPOINT=wss://{api-id-2}.execute-api.ap-southeast-1.amazonaws.com/prod CHAT_API_ID={api-id-2} # Authorizer COGNITO_AUTHORIZER_ID=cognito-user-pool-authorizer # Rate Limiting API_KEY={your-api-key} Checklist User API (smoking-cessation-user-api) created /admin/coaches resource with GET, POST, PUT, DELETE methods created /api/user-info resource with sub-resources created /upload resource with POST method created Chat API (smoking-cessation-chat-api) created Cognito authorizer configured CORS enabled for all resources Request validators configured Both APIs deployed to prod stage CloudWatch logging enabled Rate limiting with Usage Plans configured All endpoints tested successfully API endpoints saved to environment variables Sẵn sàng cho Module 6 (Create EC2 Instances \u0026amp; Databases) Troubleshooting CORS Errors in Browser Issue: \u0026ldquo;Access to XMLHttpRequest blocked by CORS policy\u0026rdquo;\nSolution:\nVerify CORS is enabled for resource Check Access-Control-Allow-Origin header For development, use * wildcard For production, restrict to specific domain 403 Unauthorized Errors Issue: \u0026ldquo;User is not authorized to perform: execute-api:Invoke\u0026rdquo;\nSolution:\nVerify JWT token is valid Check authorizer is configured on method Verify user has required role in Cognito Review API resource policy Lambda Function Not Found Issue: \u0026ldquo;Invalid Lambda function ARN specified\u0026rdquo;\nSolution:\nVerify Lambda function exists in same region Check Lambda function name spelling Verify IAM role has Lambda invoke permissions Check CloudWatch logs for integration errors Rate Limiting Not Working Issue: \u0026ldquo;Requests not throttled according to plan\u0026rdquo;\nSolution:\nVerify API key is passed in request Check Usage Plan is associated with stage Verify API key is associated with Usage Plan Wait for throttling to take effect (may take a few minutes) High Latency Issue: \u0026ldquo;API requests taking too long\u0026rdquo;\nSolution:\nEnable caching for GET requests Increase Lambda memory (Module 4) Check database connection from Lambda (Module 6) Monitor CloudWatch metrics Next Steps Implement API Gateway request/response transformations (optional) Setup WAF (Web Application Firewall) for security (optional) Configure CloudFront for API caching (Module 7) Setup API documentation (optional) Test end-to-end with frontend application Kết Quả Đạt Được Sau Module 5, bạn sẽ có:\n✅ 2 REST APIs created (User API \u0026amp; Chat API) ✅ All resources \u0026amp; methods configured ✅ Lambda integrations setup ✅ Cognito authorization configured ✅ CORS enabled for all endpoints ✅ Request validators configured ✅ Both APIs deployed to prod stage ✅ CloudWatch logging enabled ✅ Rate limiting configured ✅ All endpoints tested \u0026amp; verified ✅ API endpoints documented ✅ Sẵn sàng cho Module 6 (Create EC2 Instances \u0026amp; Databases) "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.5-week5/","title":"Nhật ký Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5 Launch và manage EC2 instances. Tạo custom AMI cho reusable deployments. Deploy applications trên EC2. Hiểu EC2 access recovery và management. Các nhiệm vụ trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Launch EC2 instance (t2.micro) ở public subnet.\n- Tạo và tải key pair cho SSH access.\n- Cấu hình security group với SSH, HTTP, HTTPS ports. 07/10/2025 07/10/2025 https://console.aws.amazon.com/ec2/ 3 - Install packages trên EC2.\n- Tạo EBS snapshot của root volume.\n- Build custom AMI từ snapshot cho faster future deployments. 08/10/2025 08/10/2025 https://console.aws.amazon.com/ec2/ 4 - Deploy Node.js application trên EC2.\n- Thiết lập systemd service cho application auto-start.\n- Cấu hình logging và monitor application health. 09/10/2025 09/10/2025 https://console.aws.amazon.com/ec2/ 5 - Học Session Manager như SSH alternative.\n- Tạo IAM role với SSM permissions.\n- Thực hành access recovery không key pair. 10/10/2025 10/10/2025 https://console.aws.amazon.com/systems-manager/ 6 - Tạo Lightsail instance như alternative EC2.\n- Deploy WordPress dùng Lightsail blueprint.\n- So sánh Lightsail vs EC2 pricing và use cases. 11/10/2025 11/10/2025 https://lightsail.aws.amazon.com/ Kết quả Tuần 5 Launch và cấu hình EC2 instances thành công. Tạo reusable custom AMI cho consistent deployments. Deploy Node.js application với auto-restart capability. Học Session Manager cho enhanced security và auditability. Hiểu Lightsail như viable alternative cho simpler workloads. Áp dụng least privilege IAM policies cho EC2 access control. Những điều quan trọng học được:\nCustom AMI tiết kiệm thời gian deploy và ensure consistency. Session Manager cung cấp better security audit trail hơn SSH key pairs. Lightsail cung cấp simpler, fixed-price alternative cho appropriate workloads. Proper IAM roles eliminate cần credential management trên instances. "},{"uri":"https://masterltb.github.io/profile/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Amazon Web Services từ ngày 08/09/2025 đến 28/11/2025, tôi đã có cơ hội quý báu để áp dụng kiến thức lý thuyết vào việc xây dựng và triển khai một dự án thực tế trên nền tảng đám mây.\nTôi đã tham gia vào dự án \u0026ldquo;Nền tảng Hỗ trợ Cai thuốc lá\u0026rdquo;, qua đó cải thiện và phát triển một loạt kỹ năng quan trọng, bao gồm:\nLập trình Backend: Phát triển các microservices bằng Java (phiên bản 25), xử lý logic nghiệp vụ phức tạp như theo dõi tiến trình, quản lý người dùng và hệ thống đánh giá. Kiến trúc Đám mây (Cloud Architecture): Thiết kế và triển khai hạ tầng trên AWS, sử dụng các dịch vụ cốt lõi như EC2, S3, VPC, IAM, và RDS (PostgreSQL). DevOps: Xây dựng quy trình CI/CD tự động bằng AWS CodePipeline, giúp tự động hóa việc build, test và deploy ứng dụng, giảm thiểu sai sót thủ công. Cơ sở dữ liệu: Thiết kế và quản lý cơ sở dữ liệu quan hệ (PostgreSQL) để lưu trữ dữ liệu người dùng và phi quan hệ (MongoDB) cho các tính năng xã hội. Phân tích và Giải quyết vấn đề: Phân tích các yêu cầu từ bản đề xuất, đối mặt với các thách thức kỹ thuật (ví dụ: tối ưu hóa truy vấn, xử lý logic nghiệp vụ phức tạp) và tìm ra giải pháp phù hợp. Về tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ được giao, tuân thủ các quy trình làm việc của nhóm, và tích cực trao đổi với các thành viên để đảm bảo dự án tiến triển đúng hướng.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Áp dụng kiến thức về Java, AWS, và DevOps vào dự án. Chất lượng mã nguồn và thiết kế hạ tầng. ✅ ☐ ☐ 2 Khả năng học hỏi Nhanh chóng tiếp thu các công nghệ mới (CDK, Cognito) và các khái niệm phức tạp. ✅ ☐ ☐ 3 Chủ động Tự nghiên cứu giải pháp cho các vấn đề kỹ thuật, đề xuất cải tiến cho quy trình CI/CD. ✅ ☐ ☐ 4 Tinh thần trách nhiệm Đảm bảo các tính năng được giao hoàn thành đúng hạn và hoạt động ổn định. ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, quy trình báo cáo và các quy định chung của nhóm. ☐ ✅ ☐ 6 Tính cầu tiến Luôn lắng nghe góp ý từ người hướng dẫn và đồng nghiệp để cải thiện mã nguồn và kỹ năng. ✅ ☐ ☐ 7 Giao tiếp Trình bày tiến độ công việc và các vấn đề kỹ thuật rõ ràng trong các buổi họp nhóm. ☐ ✅ ☐ 8 Hợp tác nhóm Phối hợp hiệu quả với các thành viên khác để tích hợp các microservices. ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, môi trường làm việc chuyên nghiệp. ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Phân tích các lỗi (bugs), tối ưu hóa hiệu suất và tìm ra nguyên nhân gốc rễ của vấn đề. ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hoàn thành các module được giao, góp phần xây dựng thành công backend cho dự án. ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập và sự phát triển của bản thân. ✅ ☐ ☐ Cần cải thiện Quản lý thời gian: Cần cải thiện kỹ năng ước tính thời gian cho các tác vụ phức tạp để đảm bảo tiến độ chính xác hơn. Kiến thức chuyên sâu về Mạng: Mặc dù đã làm việc với VPC, cần tìm hiểu sâu hơn về các khía cạnh nâng cao như peering, VPN, và Direct Connect để thiết kế các hệ thống phức tạp hơn. Kỹ năng kiểm thử (Testing): Cần viết các bài kiểm thử (unit test, integration test) một cách toàn diện và tự động hóa chúng trong quy trình CI/CD một cách hiệu quả hơn. Giao tiếp phi kỹ thuật: Cải thiện khả năng trình bày các giải pháp kỹ thuật cho những người không chuyên về công nghệ một cách dễ hiểu. "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.6-setup-rds-database/","title":"5.6 Setup RDS Database","tags":[],"description":"","content":"Module 6: Create EC2 Instances \u0026amp; Setup Databases Mục tiêu Module Tạo 4 EC2 instances từ đầu Setup PostgreSQL trên DB-PG instance Setup MongoDB trên DB-Mongo instance Cấu hình security groups Tạo databases \u0026amp; users Test connectivity giữa instances Setup monitoring \u0026amp; backups Duration: 5-6 giờ\nEC2 Instances Overview 4 instances sẽ được tạo ở ap-southeast-1 (t4g.small, ARM-based, cost-effective):\nInstance Name Type Purpose Database Port smoking-db-pg t4g.small PostgreSQL Server smoking_cessation 5432 smoking-db-mongo t4g.small MongoDB Server smoking_cessation 27017 smoking-app-user t4g.small User Cessation App (PostgreSQL) 8000 smoking-app-social t4g.small Social Media App (MongoDB) 8000 Phần 1: Create Security Groups Bước 1: Create Database Security Group EC2 Console Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for database servers VPC: Default VPC (or your VPC) Click \u0026ldquo;Create security group\u0026rdquo; Bước 2: Add Inbound Rules for DB-SG Click vào security group vừa tạo \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add these rules: Type: PostgreSQL (5432) Source: Custom → 172.0.0.0/16 (internal VPC CIDR) Type: Custom TCP 27017 (MongoDB) Source: 172.0.0.0/16 Click \u0026ldquo;Save rules\u0026rdquo; Bước 3: Create Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for application servers Click \u0026ldquo;Create security group\u0026rdquo; Bước 4: Add Inbound Rules for App-SG Click vào security group vừa tạo \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: SSH (22) Source: My IP (hoặc 0.0.0.0/0 nếu không có fixed IP) Type: Custom TCP 8000 (application) Source: 0.0.0.0/0 (or restrict to NLB later) Click \u0026ldquo;Save rules\u0026rdquo; Bước 5: Add Outbound Rules \u0026ldquo;Outbound rules\u0026rdquo; → \u0026ldquo;Edit outbound rules\u0026rdquo; Verify: All traffic to smoking-db-sg (for database access) All traffic to internet (for package downloads) Default rule should allow this Click \u0026ldquo;Save rules\u0026rdquo; Phần 2: Create EC2 Instances Bước 1: Launch First Instance (PostgreSQL) EC2 Console Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-pg AMI: Amazon Linux 2023 (free tier eligible) Instance type: t4g.small Keypair: Create new or select existing Key pair name: smoking-cessation-key Click \u0026ldquo;Create key pair\u0026rdquo; Download \u0026amp; save securely Click \u0026ldquo;Next\u0026rdquo; Bước 2: Configure Network VPC: Default VPC (or your VPC) Subnet: Any (or specific subnet in us-southeast-1a) Auto-assign public IP: Disable (private subnet) Security group: smoking-db-sg Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Storage Size: 30 GB (enough for databases) Volume type: gp3 (general purpose, cost-effective) Delete on termination: ✅ Click \u0026ldquo;Next\u0026rdquo; Bước 4: Add Tags Tag key: Name Tag value: smoking-db-pg Click \u0026ldquo;Launch instance\u0026rdquo; ⏳ Chờ instance được tạo (2-3 phút)\nBước 5: Note Private IP Address Wait for instance status \u0026ldquo;running\u0026rdquo; Copy Private IPv4 address (e.g., 172.0.8.55) Save for later: PG_HOST=172.0.8.55 Bước 6: Create MongoDB Instance (Same Steps) Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-mongo Same configuration as PostgreSQL Security group: smoking-db-sg Launch instance Note IP address: MONGO_HOST=\u0026lt;ip\u0026gt; Bước 7: Create Application Instances Launch instance: smoking-app-user\nSecurity group: smoking-app-sg Note IP: APP_USER_HOST=\u0026lt;ip\u0026gt; Launch instance: smoking-app-social\nSecurity group: smoking-app-sg Note IP: APP_SOCIAL_HOST=\u0026lt;ip\u0026gt; All 4 instances should now be running.\nPhần 3: Setup PostgreSQL on DB-PG Instance Bước 1: Connect to Instance Using AWS Session Manager (recommended) or SSH:\n# Via SSH (if you have keypair) ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PRIVATE_IP\u0026gt; # Or use Session Manager in EC2 Console # Click instance → Connect → Session Manager → Connect Bước 2: Update System sudo yum update -y sudo yum upgrade -y Bước 3: Install PostgreSQL # Add PostgreSQL repository sudo tee /etc/yum.repos.d/pgdg.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [pgdg15] name=PostgreSQL 15 for RHEL/CentOS 9 - x86_64 baseurl=https://download.postgresql.org/pub/repos/yum/15/rhel/rhel-9-x86_64 enabled=1 gpgcheck=1 gpgkey=https://download.postgresql.org/pub/repos/yum/RPM-GPG-KEY-PGDG EOF # Install PostgreSQL sudo yum install -y postgresql15-server postgresql15-contrib Bước 4: Initialize Database Cluster # Initialize cluster sudo /usr/pgsql-15/bin/initdb -D /var/lib/pgsql/15/data # Create system user if needed sudo useradd postgres || true # Change permissions sudo chown -R postgres:postgres /var/lib/pgsql/15/data Bước 5: Start PostgreSQL Service # Enable service to start on boot sudo systemctl enable postgresql-15 # Start service sudo systemctl start postgresql-15 # Verify status sudo systemctl status postgresql-15 Bước 6: Configure PostgreSQL for Network Access # Edit config file sudo nano /var/lib/pgsql/15/data/postgresql.conf # Find and change these lines: # listen_addresses = \u0026#39;localhost\u0026#39; → listen_addresses = \u0026#39;*\u0026#39; # port = 5432 → keep as is # Save: Ctrl+O, Enter, Ctrl+X Bước 7: Configure Client Authentication # Edit pg_hba.conf sudo nano /var/lib/pgsql/15/data/pg_hba.conf # Add this line at the end (before any reject lines): # host all all 172.0.0.0/16 md5 # This allows connections from VPC CIDR 172.0.0.0/16 Bước 8: Restart PostgreSQL sudo systemctl restart postgresql-15 sudo systemctl status postgresql-15 Bước 9: Create smoking_cessation Database # Switch to postgres user sudo su - postgres # Connect to psql psql # Create database CREATE DATABASE smoking_cessation; # Create application user CREATE USER app_user WITH PASSWORD \u0026#39;YourSecurePassword123!\u0026#39;; # Grant privileges GRANT ALL PRIVILEGES ON DATABASE smoking_cessation TO app_user; # Connect to database \\c smoking_cessation # Grant schema privileges GRANT ALL ON SCHEMA public TO app_user; GRANT ALL ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO app_user; # Verify \\du # List users \\l # List databases # Exit \\q exit Bước 10: Verify PostgreSQL is Listening # Check if listening on port 5432 sudo netstat -tlnp | grep 5432 # Or use ss command sudo ss -tlnp | grep 5432 # Output should show: LISTEN ... 0.0.0.0:5432 or :::5432 Phần 4: Setup MongoDB on DB-Mongo Instance Bước 1: Connect to Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_PRIVATE_IP\u0026gt; # Or use Session Manager Bước 2: Update System sudo yum update -y sudo yum upgrade -y Bước 3: Install MongoDB # Create MongoDB repository sudo tee /etc/yum.repos.d/mongodb-org.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [mongodb-org-7.0] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/amazon/2023/mongodb-org/7.0/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-7.0.asc EOF # Install MongoDB sudo yum install -y mongodb-org Bước 4: Configure MongoDB for Network Access # Edit MongoDB config sudo nano /etc/mongod.conf # Find these sections and modify: # network: # port: 27017 # bindIp: localhost → Change to bindIp: 0.0.0.0 # Save: Ctrl+O, Enter, Ctrl+X Bước 5: Start MongoDB Service # Enable service to start on boot sudo systemctl enable mongod # Start service sudo systemctl start mongod # Verify status sudo systemctl status mongod Bước 6: Create MongoDB Database \u0026amp; User # Connect to MongoDB mongosh # Switch to admin database use admin # Create admin user db.createUser({ user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;YourAdminPassword123!\u0026#34;, roles: [\u0026#34;root\u0026#34;] }) # Exit mongosh exit # Restart with authentication sudo nano /etc/mongod.conf # Find security section and uncomment: # security: # authorization: enabled # Save and restart sudo systemctl restart mongod Bước 7: Create Application Database \u0026amp; User # Connect with authentication mongosh -u admin -p YourAdminPassword123! # Switch to smoking_cessation database use smoking_cessation # Create application user db.createUser({ user: \u0026#34;app_user\u0026#34;, pwd: \u0026#34;AppPassword123!\u0026#34;, roles: [{role: \u0026#34;readWrite\u0026#34;, db: \u0026#34;smoking_cessation\u0026#34;}] }) # Verify user created show users # Exit exit Bước 8: Verify MongoDB is Listening # Check if listening on port 27017 sudo netstat -tlnp | grep 27017 # Or sudo ss -tlnp | grep 27017 # Output should show LISTEN on port 27017 Phần 5: Test Database Connectivity Bước 1: Test PostgreSQL from App Instance Connect to application instance:\nssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; # Install PostgreSQL client sudo yum install -y postgresql15 # Test connection to PostgreSQL psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation -c \u0026#34;SELECT 1\u0026#34; # Expected output: Should show \u0026#34;1\u0026#34; (success) Bước 2: Test MongoDB from App Instance # Install MongoDB tools sudo yum install -y mongodb-mongosh # Test connection to MongoDB mongosh --host \u0026lt;MONGO_HOST_IP\u0026gt;:27017 --username app_user --password AppPassword123! --authenticationDatabase smoking_cessation --eval \u0026#34;db.adminCommand(\u0026#39;ping\u0026#39;)\u0026#34; # Expected output: { ok: 1 } Bước 3: Test Inter-Instance Ping # From any instance, test network connectivity ping -c 3 \u0026lt;TARGET_IP\u0026gt; # Expected: Low latency (\u0026lt; 5ms in same VPC) Phần 6: Create Database Tables (PostgreSQL) Bước 1: Connect to Database From app instance or via psql:\n# Connect to smoking_cessation database psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation Bước 2: Create Tables -- Create users table CREATE TABLE users ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), cognito_id VARCHAR(255) UNIQUE NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, name VARCHAR(255) NOT NULL, role VARCHAR(50) DEFAULT \u0026#39;user\u0026#39;, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create coaches table CREATE TABLE coaches ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, specialization VARCHAR(255), bio TEXT, hourly_rate DECIMAL(10, 2), created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create coaching_sessions table CREATE TABLE coaching_sessions ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, coach_id UUID REFERENCES coaches(id) ON DELETE SET NULL, status VARCHAR(50) DEFAULT \u0026#39;active\u0026#39;, started_at TIMESTAMP, ended_at TIMESTAMP, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create indexes for performance CREATE INDEX idx_users_cognito_id ON users(cognito_id); CREATE INDEX idx_users_email ON users(email); CREATE INDEX idx_coaches_user_id ON coaches(user_id); CREATE INDEX idx_sessions_user_id ON coaching_sessions(user_id); CREATE INDEX idx_sessions_coach_id ON coaching_sessions(coach_id); -- Grant permissions to app_user GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO app_user; -- Verify tables \\dt Bước 3: Exit psql \\q Phần 7: Setup Application Servers (EC2 Instances) Bước 1: Connect to Application Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; Bước 2: Install Node.js \u0026amp; npm # Update system sudo yum update -y # Install Node.js (Amazon Linux version) curl -fsSL https://rpm.nodesource.com/setup_20.x | sudo bash - sudo yum install -y nodejs # Verify installation node --version npm --version Bước 3: Create Application Directory # Create app directory sudo mkdir -p /opt/smoking-cessation sudo chown -R ec2-user:ec2-user /opt/smoking-cessation # Change to directory cd /opt/smoking-cessation # Create basic package.json cat \u0026gt; package.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; { \u0026#34;name\u0026#34;: \u0026#34;smoking-cessation-app\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Smoking cessation user app\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;server.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node server.js\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;nodemon server.js\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;^4.18.2\u0026#34;, \u0026#34;pg\u0026#34;: \u0026#34;^8.10.0\u0026#34; } } EOF # Install dependencies npm install Bước 4: Create Basic Express Server # Create server.js cat \u0026gt; server.js \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; const express = require(\u0026#39;express\u0026#39;); const { Pool } = require(\u0026#39;pg\u0026#39;); const app = express(); const port = 8000; // Database connection pool const pool = new Pool({ user: \u0026#39;app_user\u0026#39;, password: process.env.DB_PASSWORD || \u0026#39;AppPassword123!\u0026#39;, host: process.env.DB_HOST || \u0026#39;localhost\u0026#39;, port: 5432, database: \u0026#39;smoking_cessation\u0026#39; }); app.use(express.json()); // Health check endpoint app.get(\u0026#39;/health\u0026#39;, (req, res) =\u0026gt; { res.json({ status: \u0026#39;ok\u0026#39;, service: \u0026#39;user-app\u0026#39; }); }); // Test database connection app.get(\u0026#39;/db-test\u0026#39;, async (req, res) =\u0026gt; { try { const result = await pool.query(\u0026#39;SELECT NOW()\u0026#39;); res.json({ message: \u0026#39;Database connected\u0026#39;, time: result.rows[0] }); } catch (error) { res.status(500).json({ error: error.message }); } }); app.listen(port, () =\u0026gt; { console.log(`App listening on port ${port}`); }); EOF Bước 5: Test Application # Start server node server.js # In another terminal, test endpoints curl http://localhost:8000/health curl http://localhost:8000/db-test # Ctrl+C to stop Bước 6: Create Systemd Service (Optional) # Create service file sudo tee /etc/systemd/system/smoking-app.service \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [Unit] Description=Smoking Cessation Application After=network.target [Service] Type=simple User=ec2-user WorkingDirectory=/opt/smoking-cessation ExecStart=/usr/bin/node server.js Restart=on-failure RestartSec=10 [Install] WantedBy=multi-user.target EOF # Enable and start service sudo systemctl daemon-reload sudo systemctl enable smoking-app sudo systemctl start smoking-app sudo systemctl status smoking-app Phần 8: Setup Monitoring \u0026amp; CloudWatch Bước 1: Enable Detailed Monitoring EC2 Console Select each instance Right-click → \u0026ldquo;Monitoring and troubleshooting\u0026rdquo; Click \u0026ldquo;Enable detailed monitoring\u0026rdquo; This provides 1-minute metrics instead of default 5-minute.\nBước 2: Create CloudWatch Alarms For high CPU on database instances:\nCloudWatch Console \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: AWS/EC2 Metric: CPUUtilization Dimension: Instance ID (select DB-PG) Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 80% Notification: Create SNS topic for alerts Click \u0026ldquo;Create alarm\u0026rdquo; Repeat for all instances.\nBước 3: Create Dashboard CloudWatch → Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-infrastructure Add widgets: EC2 CPU Utilization (all instances) Network In/Out Disk usage (if CloudWatch agent installed) Click \u0026ldquo;Create dashboard\u0026rdquo; Phần 9: Setup Database Backups Bước 1: Create Backup Directory On each database instance:\n# Create backup directory sudo mkdir -p /backups sudo chown -R postgres:postgres /backups # For PostgreSQL Bước 2: PostgreSQL Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PG_HOST\u0026gt; # Create backup script cat \u0026gt; ~/backup-pg.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_FILE=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP.sql\u0026#34; sudo -u postgres pg_dump -d smoking_cessation -h localhost \u0026gt; \u0026#34;$BACKUP_FILE\u0026#34; # Keep only last 7 days of backups find $BACKUP_DIR -name \u0026#34;smoking_cessation_*.sql\u0026#34; -mtime +7 -delete echo \u0026#34;Backup completed: $BACKUP_FILE\u0026#34; EOF # Make executable chmod +x ~/backup-pg.sh # Test backup ./backup-pg.sh # Add to crontab for daily backups at 3 AM crontab -e # Add: 0 3 * * * /home/ec2-user/backup-pg.sh \u0026gt;\u0026gt; /var/log/postgres-backup.log 2\u0026gt;\u0026amp;1 Bước 3: MongoDB Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_HOST\u0026gt; # Create backup script cat \u0026gt; ~/backup-mongo.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_PATH=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP\u0026#34; mongodump --username=admin --password=\u0026#34;YourAdminPassword123!\u0026#34; --db smoking_cessation --out \u0026#34;$BACKUP_PATH\u0026#34; # Keep only last 7 days find $BACKUP_DIR -maxdepth 1 -type d -mtime +7 -exec rm -rf {} \\; echo \u0026#34;MongoDB backup completed: $BACKUP_PATH\u0026#34; EOF # Make executable chmod +x ~/backup-mongo.sh # Test backup ./backup-mongo.sh # Add to crontab for daily backups at 4 AM crontab -e # Add: 0 4 * * * /home/ec2-user/backup-mongo.sh \u0026gt;\u0026gt; /var/log/mongo-backup.log 2\u0026gt;\u0026amp;1 Bước 4: Upload Backups to S3 (Optional) To backup off-instance (safer):\n# Configure AWS CLI on instance (requires IAM role) aws configure # Modify backup scripts to upload to S3: # aws s3 cp $BACKUP_FILE s3://smoking-cessation-backups/ Environment Variables Summary Save these for Lambda functions \u0026amp; applications:\n# PostgreSQL PG_HOST=\u0026lt;DB-PG_PRIVATE_IP\u0026gt; PG_USER=app_user PG_PASSWORD=AppPassword123! PG_DATABASE=smoking_cessation PG_PORT=5432 # MongoDB MONGO_HOST=\u0026lt;DB-Mongo_PRIVATE_IP\u0026gt; MONGO_USERNAME=app_user MONGO_PASSWORD=AppPassword123! MONGO_DATABASE=smoking_cessation MONGO_PORT=27017 MONGO_URI=mongodb://app_user:AppPassword123!@\u0026lt;MONGO_HOST\u0026gt;:27017/smoking_cessation # Application Instances APP_USER_HOST=\u0026lt;APP_USER_PRIVATE_IP\u0026gt; APP_SOCIAL_HOST=\u0026lt;APP_SOCIAL_PRIVATE_IP\u0026gt; Checklist 4 EC2 instances launched (DB-PG, DB-Mongo, App-User, App-Social) Security groups created with proper inbound/outbound rules PostgreSQL installed, configured, and accessible MongoDB installed, configured, and accessible smoking_cessation database created in both databases Application users created with proper permissions Database tables created (users, coaches, sessions) Application instances can connect to databases Inter-instance connectivity tested (ping, port access) Node.js \u0026amp; npm installed on app instances Express server created and tested CloudWatch detailed monitoring enabled CloudWatch alarms configured for high CPU CloudWatch dashboard created Database backup scripts created and tested Backup scripts added to crontab All database credentials saved securely Sẵn sàng cho Module 7 (Create S3 \u0026amp; CloudFront) Troubleshooting Cannot Connect to PostgreSQL Issue: Connection refused on port 5432\nSolution:\n# Check PostgreSQL is running sudo systemctl status postgresql-15 # Check listening on port 5432 sudo netstat -tlnp | grep 5432 # Check security group rules allow 5432 # From app instance, verify: telnet \u0026lt;PG_HOST\u0026gt; 5432 # Check pg_hba.conf allows VPC CIDR sudo nano /var/lib/pgsql/15/data/pg_hba.conf Cannot Connect to MongoDB Issue: Connection refused on port 27017\nSolution:\n# Check MongoDB is running sudo systemctl status mongod # Check port listening sudo netstat -tlnp | grep 27017 # Check mongod.conf bindIp is correct sudo nano /etc/mongod.conf # Verify authentication enabled correctly mongosh -u admin -p \u0026lt;password\u0026gt; Network Connectivity Issues Issue: Instances cannot ping each other\nSolution:\nVerify all instances are in same VPC Check security group rules allow traffic between groups Check Network ACLs don\u0026rsquo;t block traffic Verify instances have route table entries High CPU on Database Instance Issue: CPU Utilization \u0026gt; 80%\nSolution:\n# Check top processes top -b -n 1 | head -20 # For PostgreSQL, check long-running queries: psql -h localhost -U postgres -d smoking_cessation SELECT pid, usename, query, query_start FROM pg_stat_activity WHERE query != \u0026#39;autovacuum\u0026#39;; # Consider: Scale up instance type, optimize queries, or add replication Cost Analysis Current costs (4 × t4g.small at $0.0252/hour):\nCompute: ~$30/month (4 instances × 730 hours) Storage: ~$10/month (4 × 30GB EBS volumes) Data transfer: ~$5/month Total: ~$45/month Optimization options:\nUse Reserved Instances for 30% savings (~$31/month) Right-size if low usage (t4g.micro: ~$10/month) Consolidate to 2 instances if possible Next Steps Configure auto-scaling for application instances (optional) Setup read replicas for PostgreSQL (optional) Enable database replication for high availability (optional) Configure point-in-time recovery (PITR) for databases (optional) Setup monitoring alerts (Module 9) Kết Quả Đạt Được Sau Module 6, bạn sẽ có:\n✅ 4 EC2 instances created \u0026amp; running ✅ Security groups configured with proper rules ✅ PostgreSQL server setup \u0026amp; database created ✅ MongoDB server setup \u0026amp; database created ✅ Application users created in both databases ✅ Database tables created \u0026amp; indexed ✅ Application server configuration completed ✅ Inter-instance connectivity tested ✅ CloudWatch monitoring enabled ✅ CloudWatch alarms configured ✅ Database backup scripts setup ✅ All databases operational \u0026amp; accessible ✅ Sẵn sàng cho Module 7 (Create S3 \u0026amp; CloudFront) "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.6-week6/","title":"Nhật ký Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6 Setup RDS cho application data persistence. Hiểu database backup và recovery. Cấu hình high availability với Multi-AZ và Read Replicas. Triển khai database security best practices. Các nhiệm vụ trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Xem xét RDS fundamentals và database engines.\n- Tạo RDS MySQL instance ở private subnet. 14/10/2025 14/10/2025 https://console.aws.amazon.com/rds/ 3 - Bật Multi-AZ cho automatic failover capability.\n- Cấu hình automated backups với 7-day retention. 15/10/2025 15/10/2025 https://console.aws.amazon.com/rds/ 4 - Tạo Read Replica cho load distribution.\n- Test read/write distribution across instances. 16/10/2025 16/10/2025 https://console.aws.amazon.com/rds/ 5 - Cấu hình security group cho database access từ app tier.\n- Test connectivity từ EC2 instances. 17/10/2025 17/10/2025 https://console.aws.amazon.com/rds/ 6 - Thực hành backup và restore testing.\n- Monitor database performance và connection metrics. 18/10/2025 18/10/2025 https://console.aws.amazon.com/rds/ Kết quả Tuần 6 Setup RDS MySQL instance với Multi-AZ enabled thành công. Cấu hình automated backup strategy với appropriate retention. Triển khai Read Replica cho query load distribution. Bảo mật database với proper security group configuration. Test backup/restore procedures cho disaster recovery readiness. Verify connectivity và performance metrics. Những điều quan trọng học được:\nMulti-AZ cung cấp high availability với automatic failover. Read Replicas scale read operations không impact primary writes. Automated backups cho phép point-in-time recovery. Database nên luôn ở private subnet cho security. "},{"uri":"https://masterltb.github.io/profile/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi em gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp em tập trung tốt hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi em chưa hiểu và luôn khuyến khích em đặt câu hỏi. Team mentor hỗ trợ các mà em gặp phải để em làm việc thuận lợi. Em đánh giá cao việc mentor cho phép em thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc em được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, em vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc , mọi người cùng nhau cố gắng, hỗ trợ nhau. 6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nĐiều hài lòng nhất là bốn tuần cuối cùng, khi mình có cơ hội xây dựng một hệ thống microservices hoàn chỉnh (Program Service và Chat Service) từ con số không. Việc chứng kiến các logic nghiệp vụ phức tạp do mình thiết kế—như hệ thống Streak và cơ chế Slip/Relapse—hoạt động một cách chính xác là một cảm giác cực kỳ thỏa mãn. Nó đã biến kiến thức lý thuyết thành một sản phẩm hữu hình, có chức năng.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nEm nghĩ chương trình thực tập sẽ hiệu quả hơn nếu có lộ trình đào tạo bài bản ngay từ đầu, giúp thực tập sinh hiểu rõ hơn về công việc thực tế của công ty và vai trò của mình trong dự án. Việc được hướng dẫn cụ thể từng bước, từ quy trình làm việc cho đến cách triển khai các nhiệm vụ thực tế, sẽ giúp thực tập sinh hòa nhập nhanh hơn với môi trường làm việc chuyên nghiệp.\nNgoài ra, nếu có định hướng rõ ràng hơn về các kỹ năng DevOps cần thiết, cũng như tổng quan về các dịch vụ AWS mà công ty đang sử dụng, thực tập sinh sẽ dễ dàng xây dựng nền tảng vững chắc để phát triển lâu dài. Em cũng mong rằng chương trình có thể cung cấp tài liệu hoặc khung năng lực chi tiết để định hướng cho những bạn muốn theo đuổi vị trí DevOps trong tương lai.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nChắc chắn rồi. Mình rất muốn giới thiệu cho các bạn. Đây không phải là một kỳ thực tập mà bạn chỉ làm những công việc nhỏ nhặt. Bạn được giao một dự án thực sự, đầy thách thức và được tin tưởng để xây dựng nó. Lộ trình học hỏi rất dốc, nhưng lượng kinh nghiệm thực tế bạn có được về kiến trúc đám mây, phát triển backend và các quy trình kỹ thuật phần mềm chuyên nghiệp là vô giá. Sự hỗ trợ tận tình từ mentor tạo nên một môi trường hoàn hảo để phát triển.\nĐề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nĐề xuất mở rộng quy mô văn phòng để nhiều bạn có cơ hội được trao đổi với nhau trực tiếp , được trải nghiệm làm việc trong môi trường văn phòng được nhiều hơn\nBạn có muốn tiếp tục chương trình này trong tương lai?\nCó, em rất quan tâm đến việc tiếp tục với FCJ, dù là thông qua một chương trình thực tập. Em cảm thấy có một sự kết nối mạnh mẽ với dự án đã xây dựng và hạ tầng được triển khai trên AWS và rất hào hứng với khả năng phát triển nó hơn nữa, có thể là triển khai các tính năng , tối ưu hơn về luồng hoặc Video Call đã được nêu trong bản đề xuất ban đầu , phát triển bản thân , học hỏi được những cái hay ho.\nGóp ý khác (tự do chia sẻ):\nEm thực sự biết ơn vì cơ hội này. Kỳ thực tập này là một thời điểm quan trọng trong sự phát triển chuyên môn của mình. Nó không chỉ củng cố các kỹ năng kỹ thuật mà còn cho mình sự tự tin để đối mặt với những thách thức kỹ thuật phần mềm phức tạp trong thế giới thực. Cảm ơn mentor và toàn bộ đội ngũ đã hướng dẫn và hỗ trợ em.\n"},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.7-setup-s3-cloudfront/","title":"5.7 Setup S3 + CloudFront","tags":[],"description":"","content":"Module 7: Create S3 Buckets \u0026amp; CloudFront Distribution Mục tiêu Module Tạo S3 bucket cho frontend Cấu hình bucket properties \u0026amp; policies Tạo CloudFront distribution Setup Origin Access Control (OAC) Configure caching \u0026amp; security Deploy frontend application Test access \u0026amp; cache invalidation Duration: 3-4 giờ\nS3 \u0026amp; CloudFront Overview 2 S3 buckets + 1 CloudFront distribution sẽ được tạo:\nComponent Name Region Purpose S3 Bucket 1 smoking-cessation-frontend us-east-1 Frontend React app hosting S3 Bucket 2 smoking-cessation-backups ap-southeast-1 Database backups \u0026amp; logs CloudFront CF Distribution Global CDN for frontend (edge caching) Phần 1: Create Frontend S3 Bucket Bước 1: Truy cập S3 Console Login vào AWS Console Tìm kiếm \u0026ldquo;S3\u0026rdquo; Click \u0026ldquo;S3\u0026rdquo; service Click \u0026ldquo;Create bucket\u0026rdquo; Bước 2: Configure Bucket Details Bucket name: smoking-cessation-frontend Must be globally unique Use lowercase, hyphens only Region: us-east-1 (required for CloudFront SSL) Object Ownership: ACLs disabled (recommended) Click \u0026ldquo;Create bucket\u0026rdquo; ⏳ Chờ bucket được tạo (vài giây)\nBước 3: Configure Versioning Click vào bucket smoking-cessation-frontend Click \u0026ldquo;Properties\u0026rdquo; tab Scroll down to \u0026ldquo;Versioning\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Check \u0026ldquo;Enable\u0026rdquo; versioning Click \u0026ldquo;Save changes\u0026rdquo; This allows rollback if needed.\nBước 4: Configure Server Access Logging Still in Properties tab Scroll to \u0026ldquo;Server access logging\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Enable logging: ✅ Target bucket: Create new logging bucket Name: smoking-cessation-logs Click \u0026ldquo;Save changes\u0026rdquo; Bước 5: Enable Static Website Hosting Properties tab Scroll to \u0026ldquo;Static website hosting\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Static website hosting: Enable Index document: index.html Error document: index.html (for SPA routing) Click \u0026ldquo;Save changes\u0026rdquo; Bước 6: Block Public Access Click \u0026ldquo;Permissions\u0026rdquo; tab Scroll to \u0026ldquo;Block public access\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; ✅ All 4 options enabled (keep S3 private, CloudFront accesses via OAC) Click \u0026ldquo;Save changes\u0026rdquo; This ensures only CloudFront can access the bucket.\nPhần 2: Create Bucket Policy for CloudFront Access Bước 1: Create Origin Access Control (OAC) CloudFront Console Left menu: \u0026ldquo;Origin access control\u0026rdquo; Click \u0026ldquo;Create origin access control\u0026rdquo; Name: smoking-cessation-oac Origin type: S3 Signing behavior: Sign requests Click \u0026ldquo;Create\u0026rdquo; ⏳ Chờ OAC được tạo\nNote the OAC ID shown (e.g., E7DE5EADPNE96) - you\u0026rsquo;ll need this for the S3 bucket policy.\nBước 2: Create Bucket Policy Go to S3 bucket: smoking-cessation-frontend Click \u0026ldquo;Permissions\u0026rdquo; tab Scroll to \u0026ldquo;Bucket policy\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste this policy (replace OAC_ID with your OAC ID): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Note: You\u0026rsquo;ll update the distribution ID after creating CloudFront distribution.\nPhần 3: Create Backups S3 Bucket Bước 1: Create Second Bucket S3 Console Click \u0026ldquo;Create bucket\u0026rdquo; Bucket name: smoking-cessation-backups Region: ap-southeast-1 (same as databases) Click \u0026ldquo;Create bucket\u0026rdquo; Bước 2: Configure Backup Bucket Click into bucket Properties tab Versioning: Enable (to keep backup history) Encryption: Use server-side encryption Type: AES-256 Click \u0026ldquo;Save changes\u0026rdquo; Bước 3: Create Lifecycle Policy (Optional) To archive old backups after 30 days:\nManagement tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Rule name: archive-old-backups Scope: Apply to all objects Transitions: Transition to Glacier: 30 days Expiration: Delete after 90 days Click \u0026ldquo;Create rule\u0026rdquo; Phần 4: Create CloudFront Distribution Bước 1: Go to CloudFront Console Tìm kiếm \u0026ldquo;CloudFront\u0026rdquo; Click \u0026ldquo;CloudFront\u0026rdquo; service Click \u0026ldquo;Create distribution\u0026rdquo; Bước 2: Configure Origin Origin domain: Select smoking-cessation-frontend.s3.us-east-1.amazonaws.com S3 access: Enable Origin Access Control (OAC) Select: smoking-cessation-oac (created in Phần 2) HTTP version: HTTP/2 and HTTP/1.1 Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Default Cache Behavior Viewer protocol policy: Redirect HTTP to HTTPS Allowed HTTP methods: GET, HEAD, OPTIONS Cache policy: CachingOptimized (recommended) TTL: 86400 seconds (1 day) for HTML TTL: 31536000 seconds (1 year) for assets (js, css) Compress objects automatically: ✅ Click \u0026ldquo;Next\u0026rdquo; Bước 4: Configure Distribution Settings Enabled: ✅ Default root object: index.html Standard logging: Disabled (use CloudWatch instead) IPv6: ✅ Enabled Comment: Smoking Cessation Frontend CDN Click \u0026ldquo;Create distribution\u0026rdquo; ⏳ Chờ distribution được tạo \u0026amp; deployed (5-10 phút)\nDeployment status will show \u0026ldquo;In Progress\u0026rdquo; → \u0026ldquo;Deployed\u0026rdquo;\nBước 5: Note CloudFront Details After deployment, note:\nDistribution ID: (e.g., E1NREZDKTJH6Y9) Domain name: (e.g., d2yo2hr161ib8h.cloudfront.net) CNAME: (if custom domain configured) Phần 5: Update S3 Bucket Policy with Distribution ID Bước 1: Get Distribution ARN CloudFront console Select your distribution Copy Distribution ID Bước 2: Update Bucket Policy Go to S3 bucket: smoking-cessation-frontend Permissions → Bucket policy Update the policy with your Distribution ID: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;YOUR_DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Phần 6: Configure Custom Domain (Optional) Bước 1: Request ACM Certificate Important: ACM certificate must be in us-east-1 region for CloudFront!\nSwitch region to us-east-1 (top right) Tìm kiếm \u0026ldquo;ACM\u0026rdquo; Click \u0026ldquo;Certificate Manager\u0026rdquo; Click \u0026ldquo;Request certificate\u0026rdquo; Certificate type: Public certificate Domain names: yourdomain.com *.yourdomain.com Validation method: DNS Click \u0026ldquo;Request\u0026rdquo; ⏳ Chờ certificate được issued\nYou\u0026rsquo;ll need to validate via DNS CNAME records.\nBước 2: Validate Certificate (DNS Method) Go back to ACM certificates Click on your certificate Click \u0026ldquo;Create records in Route 53\u0026rdquo; (if using Route 53) Or manually add CNAME records to your DNS provider Bước 3: Add Custom Domain to CloudFront Once certificate is validated:\nGo to CloudFront distribution Click \u0026ldquo;Edit\u0026rdquo; Alternate domain names (CNAMEs): yourdomain.com www.yourdomain.com Custom SSL certificate: Select your ACM certificate Click \u0026ldquo;Save changes\u0026rdquo; Bước 4: Update DNS Records Route 53 or external DNS provider Create CNAME records: yourdomain.com → d2yo2hr161ib8h.cloudfront.net www.yourdomain.com → d2yo2hr161ib8h.cloudfront.net Wait for DNS propagation (up to 24 hours) Phần 7: Configure CORS for S3 (If Needed) Bước 1: Enable CORS S3 bucket: smoking-cessation-frontend Permissions tab Scroll to \u0026ldquo;CORS\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste CORS configuration: [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;Authorization\u0026#34;, \u0026#34;Content-Length\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;https://yourdomain.com\u0026#34;, \u0026#34;https://www.yourdomain.com\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] Click \u0026ldquo;Save changes\u0026rdquo; Phần 8: Build \u0026amp; Deploy Frontend Bước 1: Build React Application On your local machine:\n# Navigate to frontend directory cd /path/to/frontend # Install dependencies npm install # Build production npm run build # Output in dist/ or build/ folder Bước 2: Upload to S3 Option A: Using AWS CLI\n# Configure AWS credentials aws configure # Sync build folder to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Set index.html to not cache aws s3 cp s3://smoking-cessation-frontend/index.html s3://smoking-cessation-frontend/index.html \\ --metadata-directive REPLACE \\ --cache-control \u0026#34;max-age=0, no-cache, no-store, must-revalidate\u0026#34; Option B: Using S3 Console\nS3 bucket: smoking-cessation-frontend Click \u0026ldquo;Upload\u0026rdquo; Select all files from dist/ folder Click \u0026ldquo;Upload\u0026rdquo; Bước 3: Verify Files Uploaded S3 bucket content Should see: index.html assets/ *.js, *.css files Other static files Phần 9: Test Frontend Access Bước 1: Test CloudFront URL Open browser Navigate to https://\u0026lt;your-cloudfront-domain\u0026gt;.cloudfront.net Should see your React application loading Bước 2: Test Custom Domain (If Configured) Navigate to https://yourdomain.com Verify page loads properly Check browser console for no errors Bước 3: Test SPA Routing Navigate to an invalid path (e.g., /invalid) Should show 404 from your React app (not AWS 404) This confirms index.html error document is working Bước 4: Check HTTPS Certificate Click lock icon in browser Verify certificate is valid Hostname matches your domain Phần 10: Setup Cache Invalidation Bước 1: Create Invalidation via Console When you deploy new code:\nCloudFront distribution \u0026ldquo;Invalidations\u0026rdquo; tab Click \u0026ldquo;Create invalidation\u0026rdquo; Object paths: /* /index.html Click \u0026ldquo;Create invalidation\u0026rdquo; ⏳ Chờ invalidation hoàn thành (2-3 phút)\nBước 2: Automate Invalidation (Optional) Create a deployment script:\n#!/bin/bash # deploy.sh # Build npm run build # Upload to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Invalidate CloudFront aws cloudfront create-invalidation \\ --distribution-id E1NREZDKTJH6Y9 \\ --paths \u0026#34;/*\u0026#34; echo \u0026#34;Deployment complete!\u0026#34; Make executable:\nchmod +x deploy.sh # Run deployment ./deploy.sh Phần 11: Configure Security Headers Bước 1: Add Response Headers via CloudFront CloudFront distribution \u0026ldquo;Behaviors\u0026rdquo; tab Click default behavior Edit → \u0026ldquo;Response headers policy\u0026rdquo; Select or create custom policy: X-Frame-Options: DENY X-Content-Type-Options: nosniff X-XSS-Protection: 1; mode=block Strict-Transport-Security: max-age=31536000; includeSubDomains Content-Security-Policy: default-src \u0026lsquo;self\u0026rsquo; Click \u0026ldquo;Save changes\u0026rdquo; Bước 2: Add Cache Key Policy For optimal caching:\nBehaviors tab Click default behavior Edit → \u0026ldquo;Cache key and origin requests\u0026rdquo; Cache policy: CachingOptimized Origin request policy: All ViewerExcept CloudFront-Authorization Click \u0026ldquo;Save changes\u0026rdquo; Phần 12: Setup Monitoring \u0026amp; Logging Bước 1: Enable CloudFront Metrics CloudFront distribution \u0026ldquo;Monitoring\u0026rdquo; tab View metrics: Requests (total per time period) Data transferred (GB) Cache hit rate (%) 4xx/5xx error rate Default metrics available (no extra cost) Bước 2: Create CloudWatch Alarms For 4xx errors:\nCloudWatch console \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: CloudFront Metric: 4xxErrorRate Distribution: Your distribution Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 5% Notification: Create SNS topic Topic name: smoking-cessation-alerts Email: your@email.com Click \u0026ldquo;Create alarm\u0026rdquo; Verify SNS subscription via email Bước 3: Create CloudFront Dashboard CloudWatch → Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-cdn Add widgets: CloudFront requests Bytes transferred Cache hit rate Error rates (4xx/5xx) Save dashboard Environment Variables \u0026amp; URLs Save these URLs:\n# Frontend URLs FRONTEND_CLOUDFRONT_URL=https://d2yo2hr161ib8h.cloudfront.net FRONTEND_CUSTOM_DOMAIN=https://yourdomain.com FRONTEND_BUCKET=smoking-cessation-frontend FRONTEND_DISTRIBUTION_ID=E1NREZDKTJH6Y9 # Backup S3 BACKUPS_BUCKET=smoking-cessation-backups Checklist Frontend S3 bucket created (smoking-cessation-frontend) Versioning enabled on frontend bucket Static website hosting enabled Public access blocked Backup S3 bucket created (smoking-cessation-backups) Lifecycle policy configured for backups Origin Access Control (OAC) created CloudFront distribution created S3 bucket policy configured with Distribution ID Frontend built \u0026amp; uploaded to S3 CloudFront URL accessible via HTTPS Custom domain configured (optional) ACM certificate issued \u0026amp; validated CORS configured if needed Security headers configured Cache invalidation tested CloudWatch monitoring enabled CloudWatch alarms created CloudWatch dashboard created Sẵn sàng cho Module 8 (Create VPC \u0026amp; Security) Troubleshooting CloudFront Shows 403 Forbidden Issue: Getting 403 error when accessing via CloudFront\nSolution:\nVerify S3 bucket policy is correct with Distribution ID Verify OAC is properly configured Check CloudFront distribution status (must be \u0026ldquo;Deployed\u0026rdquo;) Wait 5 minutes for changes to propagate Try cache invalidation: /* Files Return 404 from S3 Issue: Some files return 404 when accessed directly\nSolution:\nEnsure all files were uploaded to S3 Check file permissions (should be private) Verify index.html exists For SPA, ensure error document is index.html SPA Routes Don\u0026rsquo;t Work Issue: Navigating to /dashboard returns 404\nSolution:\nVerify error document is set to index.html This allows React Router to handle routing Invalidate CloudFront cache: /* Browser cache: Hard refresh (Ctrl+Shift+R or Cmd+Shift+R) Slow Content Delivery Issue: Pages loading slowly\nSolution:\nEnable compression in CloudFront (gzip, brotli) Check cache policy TTL Verify assets are in /assets folder Monitor CloudFront metrics for cache hit ratio Consider adding more edge locations (available in pricing) DNS Resolution Issues Issue: Custom domain not resolving\nSolution:\nVerify DNS records created in Route 53 Check CNAME points to CloudFront domain Verify ACM certificate is issued \u0026amp; validated Wait for DNS TTL propagation (up to 24 hours) Use nslookup yourdomain.com to test Cost Analysis Monthly costs estimate:\nS3 storage: ~$0.50 (100GB frontend + backups) S3 data transfer: ~$2 (to CloudFront) CloudFront: ~$2-5 (based on traffic) Cache invalidation: ~$0.10 (20 invalidations) Total: ~$5-8/month (very economical!) Cost optimization:\nUse CloudFront TTL effectively (less invalidations) Compress objects in S3 Use S3 lifecycle policies for backups Next Steps Integrate frontend with API Gateway endpoints (Module 5) Setup authentication flow with Cognito (Module 3) Configure error boundaries in React Setup analytics (Google Analytics optional) Monitor CloudFront performance metrics Kết Quả Đạt Được Sau Module 7, bạn sẽ có:\n✅ Frontend S3 bucket created \u0026amp; configured ✅ Backup S3 bucket created with lifecycle policy ✅ Origin Access Control configured ✅ CloudFront distribution deployed globally ✅ HTTPS/SSL certificates configured ✅ Custom domain configured (optional) ✅ Frontend application deployed \u0026amp; accessible ✅ Cache invalidation setup ✅ Security headers configured ✅ CORS configuration applied ✅ CloudWatch monitoring \u0026amp; alarms configured ✅ CDN optimized for performance ✅ Sẵn sàng cho Module 8 (Create VPC \u0026amp; Security) "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.7-week7/","title":"Nhật ký Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7 Master AWS CLI cho infrastructure automation. Setup Cloud9 IDE cho development. Tạo automation scripts cho routine tasks. Chuẩn bị cho advanced AWS services. Các nhiệm vụ trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tạo Cloud9 environment trong VPC.\n- Install AWS CLI v2 ở Cloud9.\n- Test basic AWS CLI commands. 21/10/2025 21/10/2025 https://console.aws.amazon.com/cloud9/ 3 - Install AWS CLI trên local machine.\n- Cấu hình multiple CLI profiles cho different accounts.\n- Test profile switching và commands. 22/10/2025 22/10/2025 https://aws.amazon.com/cli/ 4 - Dùng CLI list và manage EC2 instances.\n- Manage S3 buckets via CLI commands.\n- Tạo và manage IAM users via CLI. 23/10/2025 23/10/2025 https://console.aws.amazon.com/ec2/ 5 - Tạo bash scripts cho automation.\n- Script backup procedures và cost analysis.\n- Setup CloudWatch alarms via CLI. 24/10/2025 24/10/2025 https://console.aws.amazon.com/systems-manager/ 6 - Phân tích cost và usage data via CLI.\n- Tạo reports cho monthly spending by service.\n- Identify cost optimization opportunities. 25/10/2025 25/10/2025 https://console.aws.amazon.com/ce/ Kết quả Tuần 7 Setup Cloud9 IDE cho cloud-based development thành công. Cấu hình AWS CLI với multiple profiles cho different environments. Demonstrate proficiency với EC2, S3, IAM management via CLI. Tạo automation scripts cho routine backup và maintenance tasks. Phân tích cost data và identify optimization opportunities. Prepare foundation cho advanced AWS service exploration. Những điều quan trọng học được:\nCloud9 cung cấp browser-based IDE với built-in terminal và IAM integration. AWS CLI faster và more scriptable hơn console cho repeated tasks. Multiple profiles enable management của different AWS accounts/environments. Automation scripts reduce manual errors và ensure consistent operations. Cost analysis cho phép proactive identification của waste và optimization. "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.8-setup-vpc-security/","title":"5.8 Setup VPC &amp; Security","tags":[],"description":"","content":"Module 8: Create VPC, Subnets, Security Groups \u0026amp; NLB Mục tiêu Module Tạo VPC mới từ đầu Tạo public \u0026amp; private subnets Cấu hình Internet Gateway \u0026amp; NAT Gateway Tạo 3 Security Groups Tạo Network Load Balancer (NLB) cho WebSocket Cấu hình IAM policies Setup VPC Flow Logs \u0026amp; security monitoring Duration: 4-5 giờ\nVPC \u0026amp; Network Overview VPC architecture sẽ được tạo ở ap-southeast-1:\nVPC: smoking-cessation-vpc (172.0.0.0/16) ├── Public Subnets (Internet-facing) │ ├── ap-southeast-1a: 172.0.0.0/24 │ └── ap-southeast-1b: 172.0.1.0/24 ├── Private Subnets (Database \u0026amp; Lambda) │ ├── ap-southeast-1a: 172.0.10.0/24 │ ├── ap-southeast-1b: 172.0.11.0/24 │ └── ap-southeast-1c: 172.0.12.0/24 ├── Internet Gateway: smoking-igw ├── NAT Gateway: smoking-nat (in public subnet) ├── NLB: smoking-nlb (WebSocket endpoint) └── 3 Security Groups: ├── smoking-nlb-sg (NLB) ├── smoking-app-sg (EC2 Applications) └── smoking-db-sg (EC2 Databases) Phần 1: Create VPC Bước 1: Truy cập VPC Console Login vào AWS Console Tìm kiếm \u0026ldquo;VPC\u0026rdquo; Click \u0026ldquo;VPC\u0026rdquo; service Chọn region: ap-southeast-1 Click \u0026ldquo;Create VPC\u0026rdquo; Bước 2: Configure VPC Details Name tag: smoking-cessation-vpc IPv4 CIDR block: 172.0.0.0/16 Đủ lớn cho tất cả subnets (65,536 addresses) IPv6 CIDR block: Leave empty Tenancy: Default Click \u0026ldquo;Create VPC\u0026rdquo; ⏳ Chờ VPC được tạo (vài giây)\nBước 3: Note VPC Details Sau khi tạo, note:\nVPC ID: (e.g., vpc-049ff1c1372e1f3b8) VPC CIDR: 172.0.0.0/16 Phần 2: Create Internet Gateway Bước 1: Create IGW VPC Console Left menu: \u0026ldquo;Internet Gateways\u0026rdquo; Click \u0026ldquo;Create Internet gateway\u0026rdquo; Name: smoking-igw Click \u0026ldquo;Create internet gateway\u0026rdquo; ⏳ Chờ IGW được tạo\nBước 2: Attach IGW to VPC Click vào IGW vừa tạo Click \u0026ldquo;Attach to VPC\u0026rdquo; Select VPC: smoking-cessation-vpc Click \u0026ldquo;Attach internet gateway\u0026rdquo; Phần 3: Create Subnets Bước 1: Create Public Subnet 1a VPC Console Left menu: \u0026ldquo;Subnets\u0026rdquo; Click \u0026ldquo;Create subnet\u0026rdquo; VPC ID: smoking-cessation-vpc Subnet name: smoking-public-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.0.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 2: Create Public Subnet 1b Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-public-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.1.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 3: Create Private Subnet 1a Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.10.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 4: Create Private Subnet 1b Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.11.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 5: Create Private Subnet 1c Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1c Availability Zone: ap-southeast-1c IPv4 CIDR block: 172.0.12.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Result: 5 subnets created (2 public + 3 private)\nPhần 4: Create \u0026amp; Configure Route Tables Bước 1: Create Public Route Table Left menu: \u0026ldquo;Route tables\u0026rdquo; Click \u0026ldquo;Create route table\u0026rdquo; Name: smoking-public-rt VPC: smoking-cessation-vpc Click \u0026ldquo;Create route table\u0026rdquo; Bước 2: Add Internet Gateway Route to Public RT Click vào public route table \u0026ldquo;Routes\u0026rdquo; tab → \u0026ldquo;Edit routes\u0026rdquo; Click \u0026ldquo;Add route\u0026rdquo; Destination: 0.0.0.0/0 Target: Internet Gateway → smoking-igw Click \u0026ldquo;Save routes\u0026rdquo; Bước 3: Associate Public RT with Public Subnets \u0026ldquo;Subnet associations\u0026rdquo; tab → \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-public-1a smoking-public-1b Click \u0026ldquo;Save associations\u0026rdquo; Bước 4: Create Private Route Table Click \u0026ldquo;Create route table\u0026rdquo; Name: smoking-private-rt VPC: smoking-cessation-vpc Click \u0026ldquo;Create route table\u0026rdquo; Bước 5: Associate Private RT with Private Subnets Click vào private route table \u0026ldquo;Subnet associations\u0026rdquo; → \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-private-1a smoking-private-1b smoking-private-1c Click \u0026ldquo;Save associations\u0026rdquo; Note: Private subnets route traffic via NAT Gateway (will configure after NAT is created)\nPhần 5: Create NAT Gateway Bước 1: Create Elastic IP for NAT Left menu: \u0026ldquo;Elastic IPs\u0026rdquo; Click \u0026ldquo;Allocate Elastic IP address\u0026rdquo; Region: ap-southeast-1 Click \u0026ldquo;Allocate\u0026rdquo; Note the Elastic IP address Bước 2: Create NAT Gateway Left menu: \u0026ldquo;NAT Gateways\u0026rdquo; Click \u0026ldquo;Create NAT gateway\u0026rdquo; Name: smoking-nat Subnet: smoking-public-1a (place in public subnet) Elastic IP allocation ID: Select the IP created in Bước 1 Click \u0026ldquo;Create NAT gateway\u0026rdquo; ⏳ Chờ NAT Gateway được tạo (1-2 phút)\nBước 3: Add NAT Gateway Route to Private RT Go to \u0026ldquo;Route tables\u0026rdquo; Click private route table: smoking-private-rt \u0026ldquo;Routes\u0026rdquo; tab → \u0026ldquo;Edit routes\u0026rdquo; Click \u0026ldquo;Add route\u0026rdquo; Destination: 0.0.0.0/0 Target: NAT Gateway → smoking-nat Click \u0026ldquo;Save routes\u0026rdquo; Now private subnets can reach internet via NAT Gateway.\nPhần 6: Create Security Groups Bước 1: Create NLB Security Group Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-nlb-sg Description: Security group for Network Load Balancer VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: Click vào SG vừa tạo \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: HTTPS (443) Source: 0.0.0.0/0 (allow all for WebSocket) Type: HTTP (80) Source: 0.0.0.0/0 (for redirect to HTTPS) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Default allows all traffic ✅ Bước 2: Create Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for application servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: Custom TCP 8000 Source: smoking-nlb-sg (allow from NLB) Type: Custom TCP 22 (SSH) Source: My IP or 0.0.0.0/0 (for admin access) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Allow all traffic to private subnets \u0026amp; databases Bước 3: Create Database Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for database servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: PostgreSQL (5432) Source: smoking-app-sg (allow from app servers) Type: Custom TCP 27017 (MongoDB) Source: smoking-app-sg (allow from app servers) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Default allows all ✅ Result: 3 security groups created with proper rules\nPhần 7: Create Network Load Balancer Bước 1: Go to Load Balancers Left menu: \u0026ldquo;Load Balancers\u0026rdquo; (under EC2) Click \u0026ldquo;Create load balancer\u0026rdquo; Select Network Load Balancer Click \u0026ldquo;Create\u0026rdquo; Bước 2: Configure NLB Basic Settings Name: smoking-nlb Scheme: Internet-facing (accessible from internet) IP address type: IPv4 VPC: smoking-cessation-vpc Subnets: - Select both public subnets: smoking-public-1a, smoking-public-1b Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Security Groups Security groups: Select smoking-nlb-sg Click \u0026ldquo;Next\u0026rdquo; Bước 4: Configure Listeners and Routing Protocol: TCP Port: 443 (HTTPS for WebSocket) Default action: Forward to target group Click \u0026ldquo;Create target group\u0026rdquo; Create Target Group: Name: smoking-ws-targets Protocol: TCP Port: 8000 (where apps listen) VPC: smoking-cessation-vpc Health check: - Protocol: TCP - Port: 8000 - Interval: 30 seconds - Healthy threshold: 2 Click \u0026ldquo;Create\u0026rdquo; Bước 5: Register Targets After target group created, add targets: - Application instances (smoking-app-user, smoking-app-social) - Port: 8000 Click \u0026ldquo;Register targets\u0026rdquo; Bước 6: Review \u0026amp; Create Review all settings Click \u0026ldquo;Create load balancer\u0026rdquo; ⏳ Chờ NLB được tạo \u0026amp; deployed (3-5 phút)\nNote the NLB DNS name: (e.g., smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com)\nPhần 8: Configure NLB with HTTPS/TLS (Optional) Bước 1: Request ACM Certificate Tìm kiếm \u0026ldquo;ACM\u0026rdquo; (Certificate Manager) Click \u0026ldquo;Request certificate\u0026rdquo; Domain names: yourdomain.com (if custom domain) Or use NLB DNS name Validation method: DNS Click \u0026ldquo;Request\u0026rdquo; Bước 2: Create HTTPS Listener Go to NLB \u0026ldquo;Listeners\u0026rdquo; tab → \u0026ldquo;Add listener\u0026rdquo; Protocol: TLS Port: 443 Default action: Forward to target group smoking-ws-targets SSL certificate: Select ACM certificate Click \u0026ldquo;Add\u0026rdquo; Bước 3: Create HTTP → HTTPS Redirect (Optional) Add another listener: Protocol: TCP Port: 80 Default action: Redirect to port 443 (HTTPS) Phần 9: Configure IAM Policies for Lambda VPC Access Bước 1: Update Lambda Execution Role Lambda functions kết nối database cần IAM permissions:\nGo to IAM Console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Select \u0026ldquo;JSON\u0026rdquo; tab Paste policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:DescribeNetworkInterfaces\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:AssignPrivateIpAddresses\u0026#34;, \u0026#34;ec2:UnassignPrivateIpAddresses\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-southeast-1:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:ap-southeast-1:*:secret:smoking-cessation/*\u0026#34; } ] } Click \u0026ldquo;Review policy\u0026rdquo; Policy name: lambda-vpc-policy Click \u0026ldquo;Create policy\u0026rdquo; Bước 2: Configure Lambda Functions for VPC For each Lambda function that accesses databases:\nGo to Lambda Console Click function name Click \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;VPC\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; VPC: smoking-cessation-vpc Subnets: Select private subnets smoking-private-1a smoking-private-1b Security groups: smoking-app-sg Click \u0026ldquo;Save\u0026rdquo; This allows Lambda to access EC2 database instances.\nPhần 10: Setup VPC Flow Logs Bước 1: Enable VPC Flow Logs Go to VPC Console Click \u0026ldquo;VPCs\u0026rdquo; Select smoking-cessation-vpc Click \u0026ldquo;Flow logs\u0026rdquo; tab Click \u0026ldquo;Create flow log\u0026rdquo; Bước 2: Configure Flow Logs Name: smoking-vpc-flow-logs Traffic type: All (capture all traffic) Log destination: CloudWatch Logs Log group name: /aws/vpc/smoking-cessation-vpc IAM role: Create new role Role name: vpc-flow-logs-role Click \u0026ldquo;Create flow log\u0026rdquo; ⏳ Chờ flow logs được enabled\nNow all VPC traffic will be logged to CloudWatch!\nPhần 11: Enable GuardDuty (Threat Detection) Bước 1: Enable GuardDuty Tìm kiếm \u0026ldquo;GuardDuty\u0026rdquo; Click \u0026ldquo;GuardDuty\u0026rdquo; service Click \u0026ldquo;Enable GuardDuty\u0026rdquo; Read and confirm disclaimer Click \u0026ldquo;Enable GuardDuty\u0026rdquo; ⏳ Chờ GuardDuty được enabled (vài phút)\nGuardDuty will analyze VPC Flow Logs for threats.\nPhần 12: Test Network Connectivity Bước 1: Test Public Subnet Connectivity From an EC2 instance in public subnet:\n# Test internet connectivity ping 8.8.8.8 # Check routing table route -n # Should see: # Destination Gateway # 172.0.0.0/16 0.0.0.0 (local) # 0.0.0.0/0 Internet Gateway Bước 2: Test Private Subnet Connectivity From an EC2 instance in private subnet:\n# Test NAT Gateway (internet via NAT) curl https://ip.nslookup.com # Test database connectivity psql -h \u0026lt;DB_IP\u0026gt; -U postgres -d smoking_cessation # Test MongoDB mongosh --host \u0026lt;MONGO_IP\u0026gt;:27017 Bước 3: Test Security Group Rules # From app server, test database access nc -zv \u0026lt;POSTGRES_IP\u0026gt; 5432 # Should be successful nc -zv \u0026lt;MONGO_IP\u0026gt; 27017 # Should be successful # From internet, try SSH to app server ssh -i key.pem ec2-user@\u0026lt;NLB_DNS\u0026gt; # May timeout (not open for SSH) Environment Variables \u0026amp; Networking Info Save these for future use:\n# VPC VPC_ID=vpc-046dc916dde2fb93f VPC_CIDR=172.0.0.0/16 # Subnets PUBLIC_SUBNET_1A=subnet-xxx PUBLIC_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1A=subnet-xxx PRIVATE_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1C=subnet-xxx # Gateways IGW_ID=igw-xxx NAT_EIP=\u0026lt;elastic-ip\u0026gt; NAT_GW_ID=nat-xxx # Security Groups NLB_SG_ID=sg-xxx APP_SG_ID=sg-xxx DB_SG_ID=sg-xxx # Load Balancer NLB_DNS=smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com NLB_ARN=arn:aws:elasticloadbalancing:ap-southeast-1:xxx Checklist VPC created (smoking-cessation-vpc) 5 subnets created (2 public + 3 private) Internet Gateway created \u0026amp; attached Public route table created \u0026amp; configured NAT Gateway created Private route table created \u0026amp; configured with NAT 3 Security Groups created (NLB, App, DB) Security Group rules configured Network Load Balancer created Target group configured with health checks Application targets registered with NLB HTTPS/TLS listener configured (optional) Lambda functions configured for VPC access Lambda IAM policy updated VPC Flow Logs enabled GuardDuty enabled Network connectivity tested Database access from apps verified Sẵn sàng cho Module 9 (CloudWatch Monitoring) Troubleshooting Instances Cannot Access Internet Issue: Private subnet instance cannot reach internet\nSolution:\nVerify NAT Gateway is running (not failed) Check private route table has NAT route: 0.0.0.0/0 → NAT Gateway Verify Elastic IP is allocated Check security group outbound rules Lambda Cannot Connect to Database Issue: Lambda timeout when connecting to database\nSolution:\nVerify Lambda is in VPC with private subnets Check database security group allows inbound from app SG Verify database instances have correct SG Test from EC2 instance first to isolate issue Check database is actually running NLB Health Checks Failing Issue: Target instances marked unhealthy\nSolution:\nVerify target group health check port: 8000 Verify application listening on port 8000 Check security group (NLB-SG → App-SG) allows traffic SSH to instance and test: curl http://localhost:8000/health Check application logs for errors Cost Analysis VPC costs (mostly free, some charges):\nVPC: Free Subnets: Free IGW: Free NAT Gateway: ~$32/month (data processing charge) NLB: ~$16/month (hourly) + $0.006 per LCU VPC Flow Logs: ~$5/month (CloudWatch Logs storage) Total: ~$50-60/month Next Steps Connect EC2 instances to NLB targets Setup auto-scaling groups (optional) Configure CloudFront to front NLB (optional) Setup WAF for NLB (optional) Monitor with CloudWatch (Module 9) Kết Quả Đạt Được Sau Module 8, bạn sẽ có:\n✅ VPC created với CIDR 172.0.0.0/16 ✅ 5 subnets (2 public + 3 private) ✅ Internet Gateway attached ✅ NAT Gateway for private subnet internet access ✅ Public \u0026amp; private route tables configured ✅ 3 Security Groups with proper rules ✅ Network Load Balancer operational ✅ Lambda functions integrated with VPC ✅ VPC Flow Logs capturing all traffic ✅ GuardDuty monitoring for threats ✅ Network security fully configured ✅ Sẵn sàng cho Module 9 (CloudWatch Monitoring \u0026amp; Alarms) "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.8-week8/","title":"Nhật ký Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8 Ôn tập 4 nhóm nội dung chính từ chương trình OJT: Bảo mật, Linh hoạt, Hiệu năng, Tối ưu chi phí. Kết nối các labs thực hành từ Tuần 2-7 với các mẫu kiến trúc và tình huống thi. Chuẩn bị cho kiểm tra AWS ngày 31/10/2025. Các nhiệm vụ trong tuần Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu 2 - Ôn tập Security: IAM, MFA, encryption, KMS, Security Groups.\n27/10/2025 27/10/2025 https://aws.amazon.com/security/ 3 - Ôn tập Resilience: Multi-AZ, Auto Scaling, Load Balancers, Route 53.\n28/10/2025 28/10/2025 https://docs.aws.amazon.com/wellarchitected/ 4 - Ôn tập Performance: EC2, Lambda, S3, caching, CloudFront.\n29/10/2025 29/10/2025 https://aws.amazon.com/architecture/well-architected/ 5 - Ôn tập Cost Optimization: Reserved Instances, Budgets, lifecycle policies.\n30/10/2025 30/10/2025 https://console.aws.amazon.com/ce/ 6 - Luyện tập đề thi: 65 câu hỏi bao gồm 4 nhóm nội dung.\n30/10/2025 30/10/2025 https://skillbuilder.aws/ - - Bài thi AWS. 31/10/2025 31/10/2025 — Kết quả đạt được Nắm vững 4 nhóm nội dung chính cần thiết cho kỳ kiểm tra. Kết nối các labs thực hành OJT (Tuần 2-7) với các mẫu kiến trúc và tình huống thi. Hiểu AWS Well-Architected Framework: Security, Reliability, Performance Excellence, Cost Optimization. Chuẩn bị ôn tập toàn diện cho ngày 31/10/2025. Sẵn sàng áp dụng kiến thức AWS để đưa ra quyết định kiến trúc thực tế. Kiến thức chính:\nBảo mật: IAM roles → least privilege | Encryption (KMS/TLS) → data protection | VPC security → network isolation | MFA → access control Linh hoạt: Multi-AZ → failover | Auto Scaling → elasticity | Load Balancers → traffic distribution | Route 53 → DNS failover Hiệu năng: Auto Scaling → handle spikes | Lambda → serverless compute | S3/EFS/EBS → storage optimization | Caching → reduced latency Chi phí: Reserved Instances → 30-70% savings | Budgets → spending control | Lifecycle policies → storage optimization | Right-sizing → efficient resources "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.9-monitoring-logging/","title":"5.9 Monitoring &amp; Logging","tags":[],"description":"","content":"Module 9: Setup CloudWatch Monitoring, Logging \u0026amp; Alerts Mục tiêu Module Tạo CloudWatch Log Groups cho tất cả services Tạo CloudWatch Dashboard để theo dõi metrics Tạo CloudWatch Alarms với SNS notifications Enable CloudTrail cho audit logging Enable X-Ray distributed tracing Setup Cost Monitoring \u0026amp; Budget Alerts Tạo CloudWatch Synthetics (health checks) Document incident response runbooks Duration: 3-4 giờ\nMonitoring \u0026amp; Observability Architecture Infrastructure monitoring sẽ cover:\nCloudWatch Monitoring: ├── Logs (CloudWatch Logs) │ ├── /aws/lambda/functions │ ├── /aws/apigateway/apis │ ├── /aws/ec2/databases │ ├── /aws/vpc/flow-logs │ └── /aws/s3/access-logs ├── Metrics \u0026amp; Dashboards │ ├── EC2 (CPU, Network, Disk) │ ├── Lambda (Invocations, Errors, Duration) │ ├── API Gateway (Requests, Errors, Latency) │ ├── CloudFront (Requests, Cache Hit Rate) │ └── NLB (Connections, Target Health) ├── Alarms (SNS Notifications) │ ├── High error rates │ ├── High latency │ ├── Resource exhaustion │ └── Cost anomalies └── Audit Trail ├── CloudTrail (API calls) └── X-Ray (Request tracing) Phần 1: Create CloudWatch Log Groups Bước 1: Create Lambda Log Groups CloudWatch Console Left menu: \u0026ldquo;Logs\u0026rdquo; → \u0026ldquo;Log groups\u0026rdquo; Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/lambda/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; ⏳ Chờ log group được tạo\nNote: Lambda functions automatically create their own log streams, but creating parent log group allows custom configuration\nBước 2: Create API Gateway Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/apigateway/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Bước 3: Create EC2 Databases Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/ec2/databases Click \u0026ldquo;Create log group\u0026rdquo; Bước 4: Create VPC Flow Logs Group Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/vpc/flow-logs Click \u0026ldquo;Create log group\u0026rdquo; Bước 5: Create CloudFront Log Groups (Optional) Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/cloudfront/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Result: 5 log groups created for centralized logging\nBước 6: Configure Log Retention Policies For each log group:\nClick on log group name Actions → \u0026ldquo;Edit retention settings\u0026rdquo; Retention: 30 days Balances cost vs. historical data Click \u0026ldquo;Save\u0026rdquo; This prevents logs from consuming unlimited storage.\nPhần 2: Create CloudWatch Dashboard Bước 1: Create Dashboard CloudWatch Console Left menu: \u0026ldquo;Dashboards\u0026rdquo; Click \u0026ldquo;Create dashboard\u0026rdquo; Dashboard name: smoking-cessation-monitoring Click \u0026ldquo;Create dashboard\u0026rdquo; ⏳ Chờ dashboard được tạo\nBước 2: Add Lambda Metrics Widget Click \u0026ldquo;Add widget\u0026rdquo; Choose Line chart Metric selection: Namespace: AWS/Lambda Metric: Invocations Statistics: Sum Add multiple metrics: Invocations Duration (Average) Errors (Sum) Throttles (Sum) Widget name: Lambda Performance Click \u0026ldquo;Create widget\u0026rdquo; Bước 3: Add API Gateway Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/ApiGateway Metrics: Count (total requests) 4XXError 5XXError Latency (p99) Widget name: API Gateway Metrics Click \u0026ldquo;Create widget\u0026rdquo; Bước 4: Add EC2 Database Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/EC2 Filter by instances: DB-PG, DB-Mongo Metrics: CPUUtilization NetworkPacketsIn NetworkPacketsOut DiskReadBytes Widget name: Database Performance Click \u0026ldquo;Create widget\u0026rdquo; Bước 5: Add CloudFront Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Number widget Metric selection: Namespace: AWS/CloudFront Metrics: Requests (Sum) BytesDownloaded CacheHitRate 4xxErrorRate 5xxErrorRate Widget name: CDN Performance Click \u0026ldquo;Create widget\u0026rdquo; Bước 6: Add NLB Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/NetworkELB Metrics: ActiveFlowCount HealthyHostCount UnHealthyHostCount ProcessedBytes Widget name: Load Balancer Health Click \u0026ldquo;Create widget\u0026rdquo; Bước 7: Configure Dashboard Settings Dashboard settings (gear icon) Auto-refresh: 1 minute Save dashboard Now you have a real-time monitoring dashboard!\nPhần 3: Create SNS Topic for Notifications Bước 1: Create SNS Topic Tìm kiếm \u0026ldquo;SNS\u0026rdquo; Click \u0026ldquo;SNS\u0026rdquo; service Left menu: \u0026ldquo;Topics\u0026rdquo; Click \u0026ldquo;Create topic\u0026rdquo; Type: Standard Name: smoking-cessation-alerts Click \u0026ldquo;Create topic\u0026rdquo; ⏳ Chờ topic được tạo\nBước 2: Create Email Subscription Click vào topic vừa tạo \u0026ldquo;Subscriptions\u0026rdquo; tab → \u0026ldquo;Create subscription\u0026rdquo; Protocol: Email Endpoint: your-email@example.com Click \u0026ldquo;Create subscription\u0026rdquo; ⏳ Chờ email confirmation\nCheck your email inbox and click the confirmation link!\nBước 3: Create SMS Subscription (Optional) Click \u0026ldquo;Create subscription\u0026rdquo; Protocol: SMS Endpoint: +1234567890 (your phone number) Click \u0026ldquo;Create subscription\u0026rdquo; Now you\u0026rsquo;ll get SMS alerts for critical issues!\nPhần 4: Create CloudWatch Alarms Bước 1: Create Lambda Error Alarm CloudWatch → Alarms → \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/Lambda Metric: Errors Statistics: Sum Conditions: Threshold: \u0026gt; 5 errors Period: 5 minutes Evaluation periods: 1 Click \u0026ldquo;Next\u0026rdquo; Notification: Select SNS topic smoking-cessation-alerts Alarm name: smoking-lambda-errors Alarm description: Alert when Lambda errors exceed threshold Click \u0026ldquo;Create alarm\u0026rdquo; Bước 3: Create EC2 Database CPU Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/EC2 Metric: CPUUtilization Instance: DB-PG Conditions: Threshold: \u0026gt; 80% Period: 5 minutes Evaluation periods: 2 Click \u0026ldquo;Next\u0026rdquo; Notification: smoking-cessation-alerts Alarm name: smoking-db-pg-high-cpu Click \u0026ldquo;Create alarm\u0026rdquo; Bước 4: Create Similar Alarms for Other Services Repeat for:\nDB-Mongo CPU \u0026gt; 80% Application servers CPU \u0026gt; 75% CloudFront 4xx errors \u0026gt; 5% CloudFront 5xx errors \u0026gt; 1% NLB unhealthy targets \u0026gt; 0 Bước 5: Create Composite Alarm (Optional) Combine multiple alarms into one:\nClick \u0026ldquo;Create alarm\u0026rdquo; Alarm type: Composite alarm Alarm rule: (smoking-lambda-errors OR smoking-apigateway-errors OR smoking-db-pg-high-cpu OR smoking-db-mongo-high-cpu) This triggers if ANY service has issues Click \u0026ldquo;Create alarm\u0026rdquo; Result: Comprehensive alerting system active!\nPhần 5: Enable CloudTrail Audit Logging Bước 1: Create CloudTrail Tìm kiếm \u0026ldquo;CloudTrail\u0026rdquo; Click \u0026ldquo;CloudTrail\u0026rdquo; service Click \u0026ldquo;Create trail\u0026rdquo; Trail name: smoking-cessation-audit Enable for all AWS regions: ✅ (recommended) Click \u0026ldquo;Next\u0026rdquo; Bước 2: Configure S3 for CloudTrail Logs S3 bucket: Create new bucket: ✅ Bucket name: smoking-cessation-cloudtrail-logs S3 key prefix (optional): cloudtrail-logs/ Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure CloudTrail Events Management events: ✅ All (captures API calls) Data events: (Optional - more expensive) Insights: ✅ CloudTrail Insights (detects unusual activity) Click \u0026ldquo;Next\u0026rdquo; Bước 4: Review \u0026amp; Create Review all settings Click \u0026ldquo;Create trail\u0026rdquo; ⏳ Chờ trail được tạo\nBước 5: Start Logging Trail created → click \u0026ldquo;Start logging\u0026rdquo; Trail status changes to \u0026ldquo;Logging\u0026rdquo; Now all API calls are being audited!\nBước 6: View CloudTrail Events CloudTrail → Event history Filter by: Event name: (e.g., PutFunction for Lambda code updates) Resource type: (e.g., AWS::Lambda::Function) Time range: Last 24 hours View event details (JSON format) This helps with:\nSecurity audits Compliance investigations Troubleshooting IAM issues Cost allocation Phần 6: Enable X-Ray Distributed Tracing Bước 1: Create X-Ray Sampling Rule Tìm kiếm \u0026ldquo;X-Ray\u0026rdquo; Click \u0026ldquo;X-Ray\u0026rdquo; service Left menu: \u0026ldquo;Sampling rules\u0026rdquo; Click \u0026ldquo;Create sampling rule\u0026rdquo; Rule name: smoking-cessation-sampling Priority: 1000 (lower = higher priority) Reservoir: 1 (always sample at least 1 per second) Fixed rate: 0.1 (10% of requests) Click \u0026ldquo;Create sampling rule\u0026rdquo; This controls how many traces are recorded (reducing cost).\nBước 2: Enable X-Ray for Lambda Functions For each Lambda function:\nLambda Console Click function name Configuration tab Click \u0026ldquo;General configuration\u0026rdquo; → Edit Under \u0026ldquo;Monitoring tools\u0026rdquo;: ✅ Check \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for all 5 Lambda functions.\nBước 3: Enable X-Ray for API Gateway API Gateway Console Select API: smoking-cessation-user-api Logging → Settings ✅ Check \u0026ldquo;X-Ray request tracing enabled\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for chat API Bước 4: Update Lambda IAM Role for X-Ray IAM Console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Add permissions → Attach policies directly Search: AWSXRayWriteAccess Check ✅ Click \u0026ldquo;Attach policies\u0026rdquo; Now Lambda can write X-Ray traces!\nBước 5: View Service Map X-Ray Console Left menu: \u0026ldquo;Service map\u0026rdquo; You\u0026rsquo;ll see a map showing: API Gateway → Lambda → EC2 (databases) Lambda → S3 Lambda → CloudFront Data flow between services As requests flow through the system, traces are recorded!\nBước 6: Analyze Traces X-Ray → Traces Click on a trace to view: Service timeline Latency breakdown per service Errors and exceptions Database query details Use this to identify performance bottlenecks Phần 7: Setup Cost Monitoring Bước 1: Create AWS Budget Billing Console Left menu: \u0026ldquo;Budgets\u0026rdquo; Click \u0026ldquo;Create budget\u0026rdquo; Budget type: Cost budget Period: Monthly Amount: $500/month Alerts: When actual \u0026gt; 80% ($400): Email When forecasted \u0026gt; 100% ($500): Email Click \u0026ldquo;Create budget\u0026rdquo; This prevents surprise bills!\nBước 2: Setup Cost Anomaly Detection Cost Management Console Left menu: \u0026ldquo;Anomaly Detection\u0026rdquo; Click \u0026ldquo;Create detector\u0026rdquo; Name: smoking-cessation-cost-anomaly Monitor: All AWS Services Frequency: Daily Alert frequency: Instant SNS topic: smoking-cessation-alerts Click \u0026ldquo;Create detector\u0026rdquo; Now you\u0026rsquo;ll be alerted if costs spike unexpectedly!\nBước 3: Use Cost Explorer Cost Explorer View costs by: Service: See which services cost the most Region: Compare regions Time: Identify trends Filter: Linked account Cost category Granularity: Daily or Monthly Common cost optimization findings:\nNAT Gateway data processing \u0026gt; 50% of bill EC2 instances running 24/7 \u0026gt; 30% of bill CloudFront data transfer \u0026gt; 10% of bill Phần 8: Create CloudWatch Synthetics (Health Checks) Bước 1: Create API Canary CloudWatch Console Left menu: \u0026ldquo;Synthetics\u0026rdquo; → \u0026ldquo;Canaries\u0026rdquo; Click \u0026ldquo;Create canary\u0026rdquo; Canary type: API canary Name: smoking-api-health-check Endpoint: Your API Gateway URL https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/health Method: GET Schedule: 5 minutes Click \u0026ldquo;Next\u0026rdquo; Bước 2: Configure Success Criteria Status codes: 200 Response time: \u0026lt; 1000ms Click \u0026ldquo;Next\u0026rdquo; Bước 3: Set S3 Storage S3 location: Create new bucket or select existing Bucket name: smoking-canary-results Click \u0026ldquo;Create canary\u0026rdquo; ⏳ Chờ canary được tạo\nBước 4: Monitor Canary Results Synthetics → Canaries Click smoking-api-health-check View: Success rate Latency graphs Failed requests If failures: Create CloudWatch alarm This continuously tests API availability!\nPhần 9: Create Incident Response Runbooks Bước 1: Document High Error Rate Response Create a file or document:\nINCIDENT: High Lambda Error Rate (\u0026gt; 5 errors/5min) Detection: CloudWatch Alarm \u0026#34;smoking-lambda-errors\u0026#34; triggered Immediate Actions: 1. Check CloudWatch Logs: - Go to CloudWatch → Logs → Log groups - Select `/aws/lambda/smoking-cessation` - Search for \u0026#34;error\u0026#34; or \u0026#34;Error\u0026#34; - Note error message \u0026amp; frequency 2. Identify Affected Function: - From alarm, determine which function - Check recent CloudTrail logs - Verify no recent code deployments 3. Database Connectivity Check: - If DB error: - EC2 → Instances - Check DB-PG and DB-Mongo status - Check security groups allow traffic - If not DB: Check Lambda timeout configuration 4. Escalation: - If not resolved in 15 min: Page on-call engineer - If data loss risk: Initiate disaster recovery Resolution: - Rollback recent deployments if applicable - Scale up database resources if overloaded - Increase Lambda memory if timeout issues - Update database connection pooling Post-Incident: - Document root cause - Update monitoring to catch earlier - Schedule post-mortem meeting Bước 2: Create High API Latency Runbook INCIDENT: High API Latency (\u0026gt; 1000ms p99) Actions: 1. Check X-Ray service map to identify slow service 2. If Lambda slow: - Increase memory (more CPU) - Check CloudWatch Logs for errors 3. If database slow: - Monitor EC2 instance CPU/Memory - Check slow query logs 4. If API Gateway slow: - Check request volume - Verify cache hit rate (CloudFront) 5. Resolution: - Scale resources up - Optimize queries/code - Add caching layer Bước 3: Create Database Disk Full Runbook INCIDENT: Database Disk Full (\u0026gt; 90%) Actions: 1. SSH to DB instance (EC2) 2. Check disk usage: df -h /var 3. Clean up: - Remove old logs: find /var/log -mtime +30 -delete - Archive old data from PostgreSQL - Delete old MongoDB collections 4. If still full: - Add EBS volume or expand existing - Migrate to larger instance type 5. Configure auto-cleanup for future Environment Variables \u0026amp; Monitoring Info Save for reference:\n# CloudWatch DASHBOARD_NAME=smoking-cessation-monitoring LOG_GROUP_LAMBDA=/aws/lambda/smoking-cessation LOG_GROUP_APIGATEWAY=/aws/apigateway/smoking-cessation LOG_GROUP_VPC=/aws/vpc/flow-logs LOG_RETENTION=30 # days # Alarms \u0026amp; Notifications SNS_TOPIC_ARN=arn:aws:sns:ap-southeast-1:xxx:smoking-cessation-alerts ALARM_LAMBDA_ERRORS=smoking-lambda-errors ALARM_APIGATEWAY_ERRORS=smoking-apigateway-errors ALARM_DB_CPU_HIGH=smoking-db-cpu-high # Audit \u0026amp; Tracing CLOUDTRAIL_BUCKET=smoking-cessation-cloudtrail-logs XRAY_SAMPLING_RATE=0.1 SYNTHETICS_BUCKET=smoking-canary-results # Budget MONTHLY_BUDGET=$500 ALERT_THRESHOLD=80% # $400 Checklist CloudWatch Log Groups created for all services Log retention set to 30 days CloudWatch Dashboard created with key metrics SNS topic created for notifications Email subscription verified CloudWatch Alarms created: Lambda errors API Gateway errors EC2 database high CPU CloudFront errors NLB health CloudTrail enabled \u0026amp; logging CloudTrail S3 bucket created X-Ray sampling rule configured X-Ray enabled on Lambda functions X-Ray enabled on API Gateway Lambda IAM role has X-Ray permissions AWS Budget configured ($500/month) Cost Anomaly Detection enabled CloudWatch Synthetics canary created Incident response runbooks documented Team trained on monitoring tools WORKSHOP COMPLETE ✅ Monitoring Best Practices Alert Fatigue Prevention Set thresholds based on historical baselines Use composite alarms for multiple conditions Implement alert deduplication Log Management Set appropriate retention (30 days = balance) Use filters to reduce noise Archive to S3 Glacier for long-term storage Cost Optimization Review CloudWatch costs monthly Use Log Insights selectively Archive old logs to S3 Security Enable CloudTrail multi-region Review CloudTrail logs weekly Monitor for suspicious IAM activity Cost Analysis Monitoring costs (estimated monthly):\nCloudWatch Logs: ~$20 (log ingestion + storage) CloudWatch Alarms: ~$5 (10 alarms × $0.50) CloudTrail: ~$3 (multi-region trail) X-Ray: ~$2 (10% sampling rate) Cost Explorer: Free Synthetics: ~$1 (1 canary every 5 min) Total: ~$31/month Next Steps Monitor dashboard daily during initial rollout Adjust alarm thresholds based on actual metrics Review CloudTrail logs for security Optimize costs based on Cost Explorer findings Plan disaster recovery based on CloudTrail audit trail Schedule monthly post-mortems for any incidents Kết Quả Đạt Được Sau Module 9, bạn sẽ có:\n✅ CloudWatch Log Groups for all services ✅ Centralized logging with 30-day retention ✅ Real-time monitoring dashboard ✅ Automated SNS alerts for critical issues ✅ Email/SMS notifications working ✅ CloudWatch Alarms monitoring performance ✅ CloudTrail enabled for compliance auditing ✅ X-Ray distributed tracing for debugging ✅ Service map showing architecture ✅ Cost monitoring \u0026amp; budgets configured ✅ CloudWatch Synthetics for continuous health checks ✅ Incident response runbooks documented ✅ Complete observability of infrastructure ✅ 🎉 AWS WORKSHOP 100% COMPLETE 🎉 Workshop Summary You have successfully built a complete AWS infrastructure for the Smoking Cessation Platform:\nModules Completed (9 Total): Module 1-2: Prerequisites \u0026amp; AWS Account Setup ✅ Module 3: Cognito Authentication ✅ Module 4: Lambda Functions ✅ Module 5: API Gateway REST APIs ✅ Module 6: EC2 Instances \u0026amp; Databases ✅ Module 7: S3 Frontend \u0026amp; CloudFront CDN ✅ Module 8: VPC, Security, Load Balancing ✅ Module 9: Monitoring, Logging \u0026amp; Alerts ✅ Architecture Highlights: ✅ Secure authentication (Cognito) ✅ Serverless compute (Lambda) ✅ RESTful APIs (API Gateway) ✅ Hybrid databases (PostgreSQL + MongoDB on EC2) ✅ Global content delivery (CloudFront) ✅ High-availability networking (VPC, NLB) ✅ Comprehensive monitoring (CloudWatch, X-Ray) ✅ Complete audit trail (CloudTrail) Estimated Monthly Cost: $320-350 EC2 (4 instances): $120 Lambda: $10 API Gateway: $5 S3 + CloudFront: $10 NAT Gateway: $32 NLB: $16 CloudWatch/Logs: $30 Other services: $30 Your infrastructure is production-ready! 🚀\n"},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.9-week9/","title":"Nhật ký Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9 Khởi động song song: Dựng khung cho Program Service và Chat Service bằng Java 25 và Spring Boot. Thiết kế DB: Thiết kế và triển khai schema cho cả hai service. Triển khai logic ban đầu: Xây dựng luồng Đánh giá \u0026amp; Gợi ý cho Program Service và áp dụng lớp bảo mật chung. Các công việc thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Program Service: Khởi tạo dự án Spring Boot và thiết kế ERD cho Programs, Quizzes. - Chat Service: Thiết kế ERD cho ChatRooms, Messages. 03/11/2025 03/11/2025 https://start.spring.io/ 3 - Program Service: Triển khai logic MeQuizController để phân loại mức độ nghiện. - Chat Service: Khởi tạo dự án Spring Boot và tạo các lớp Entity (ChatRoom, Message). 04/11/2025 04/11/2025 — 4 - Program Service: Seed dữ liệu ProgramTemplates và phát triển Engine Gợi ý. - Cơ sở dữ liệu: Áp dụng schema cho cả hai service bằng Flyway. 05/11/2025 05/11/2025 https://flywaydb.org/ 5 - Program Service: Xây dựng API Đăng ký Lộ trình (Enrollment). - Bảo mật chung: Tích hợp JWT authentication filter có thể tái sử dụng cho cả hai service. 06/11/2025 06/11/2025 https://spring.io/guides/gs/securing-web/ 6 - Kiểm thử: Dùng Postman để test luồng Đánh giá \u0026amp; Đăng ký của Program Service. - Rà soát: Code review cấu trúc của cả hai project, đảm bảo tính nhất quán. 07/11/2025 07/11/2025 — Kết quả đạt được Tuần 9 Thiết lập thành công khung sườn cho cả hai service: Program Service và Chat Service. Hoàn thành triển khai Database Schema cho cả hai service trên PostgreSQL, được quản lý bởi Flyway. Program Service: Hệ thống Đánh giá \u0026amp; Gợi ý đã hoạt động, cho phép phân loại và đề xuất lộ trình. Bảo mật: Lớp bảo mật JWT đã được tích hợp và sẵn sàng để bảo vệ các API trong tương lai. Bài học rút ra:\nKiến trúc Microservices: Hiểu được cách thiết lập và quản lý nhiều service trong cùng một hệ thống. Quản lý Schema DB: Sử dụng Flyway giúp việc quản lý và triển khai các thay đổi về cơ sở dữ liệu trở nên an toàn và tự động. Tái sử dụng: Thiết kế các thành phần chung (như lớp bảo mật) để có thể áp dụng cho nhiều service, tránh lặp code. "},{"uri":"https://masterltb.github.io/profile/vi/5-workshop/5.10-cleanup/","title":"5.10 Cleanup &amp; Cost Optimization","tags":[],"description":"","content":"Module 10: Cleanup \u0026amp; Cost Optimization Mục tiêu Module Identify unused/underutilized resources Delete test resources Optimize costs Archive important data Backup before deletion Documentation \u0026amp; lessons learned Phần 1: Resource Inventory \u0026amp; Assessment Current AWS Resources List tất cả resources từ AWS Console:\nLambda Functions:\nGo to Lambda console List functions in each region (us-east-1, ap-southeast-1) Note: Function names, creation dates, memory allocation API Gateways:\nGo to API Gateway console List all REST APIs in ap-southeast-1 Note: API names, deployment status EC2 Database Instances:\nGo to EC2 console List all instances in ap-southeast-1 Filter for database instances (DB-PG, DB-Mongo) Note: Instance IDs, instance types, IPs, creation dates S3 Buckets:\nGo to S3 console List all buckets Note: Bucket names, creation dates, storage used CloudFront Distributions:\nGo to CloudFront console List all distributions Note: Domain names, distribution IDs VPC Resources:\nGo to VPC console List all VPCs in ap-southeast-1 Note: VPC IDs, CIDR ranges Create inventory spreadsheet:\nResource name \u0026amp; type Region Creation date Current usage Estimated monthly cost Phần 2: Identify Unused Resources Check Resource Usage Lambda Functions To check Lambda invocations:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;Lambda\u0026rdquo; Select each function Choose metric: \u0026ldquo;Invocations\u0026rdquo; Set time range: Last 7 days Check if Sum = 0 (unused function) If no invocations in last 7 days = unused function (consider deletion)\nAPI Gateways To check API request count:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;API Gateway\u0026rdquo; Select your API Choose metric: \u0026ldquo;Count\u0026rdquo; Set time range: Last 30 days Check if Sum = 0 (unused API) S3 Buckets To check bucket sizes:\nGo to S3 console Click on each bucket Go to \u0026ldquo;Storage\u0026rdquo; tab See \u0026ldquo;Storage used\u0026rdquo; value Review storage class (Standard, Infrequent Access, Glacier) Consider moving old objects to cheaper storage classes S3 storage class pricing:\nStandard: $0.023/GB/month Infrequent Access: $0.0125/GB/month Glacier: $0.004/GB/month CloudFront To check cache hit ratio:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;CloudFront\u0026rdquo; Select your distribution Choose metric: \u0026ldquo;CacheHitRate\u0026rdquo; Set time range: Last 30 days If cache hit ratio \u0026lt; 50%, may need optimization EC2 Database Instances To check CPU \u0026amp; memory usage:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;EC2\u0026rdquo; Select your database instance (DB-PG or DB-Mongo) Choose metric: \u0026ldquo;CPUUtilization\u0026rdquo; Set time range: Last 30 days Check Average and Maximum values If CPU \u0026lt; 10% consistently: May downsize instance type (saves money on EC2)\nPhần 3: Cost Optimization Strategies 1. Right-Sizing EC2 Database Instances Current: t4g.small EC2 instances (PostgreSQL + MongoDB) Cost: ~$30-40/month per instance\nOptions:\nt4g.nano: ~$3-5/month (for test/dev) t4g.micro: ~$8-10/month (for light production) t4g.small: Keep as-is (recommended for production) Check: EC2 CPU \u0026lt; 10% on average → downsize to save money\n2. Reserve Capacity (if stable usage) For production, consider AWS EC2 Reserved Instances:\n1-year: ~30% discount 3-year: ~50% discount To purchase reserved EC2 instances:\nGo to EC2 console Click \u0026ldquo;Reserved Instances\u0026rdquo; (left menu) Click \u0026ldquo;Purchase Reserved Instances\u0026rdquo; Configure: Instance type: t4g.small Term length: 1-year or 3-year Click \u0026ldquo;Purchase\u0026rdquo; 3. Optimize Data Transfer Costs:\nS3 to CloudFront: Free S3 to Internet: $0.09/GB S3 to Lambda (same region): Free Recommendation: Keep CloudFront caching enabled\n4. Lambda Optimization Current: 256 MB average Cost: ~$0.0000002 per invocation\nIf high invocation rate:\nUse Lambda provisioned concurrency: Higher cost but predictable Monitor: Check if memory increase helps reduce duration (saves cost) 5. Database Optimization Recommendations:\nEnable automated backup (already done) Setup read replicas if scaling reads (cost: ~50% of main instance) Archive old logs (CloudWatch retention: 30 days by default) 6. CloudFront Optimization If cache hit ratio \u0026lt; 50%:\nIncrease TTL for static assets Add more cache behaviors Use cache policies with parameters Phần 4: Backup \u0026amp; Archive Bước 1: Backup EC2 Databases To backup PostgreSQL and MongoDB on EC2:\nPostgreSQL (DB-PG: 172.0.8.55):\nSSH into the EC2 instance Create backup: pg_dump smokingcessation \u0026gt; backup_$(date +%Y%m%d).sql Compress: gzip backup_*.sql MongoDB (DB-Mongo: 172.0.8.124):\nSSH into the EC2 instance Create backup: mongodump --db smokingcessation --out backup_$(date +%Y%m%d) Compress: tar czf backup_*.tar backup_* Bước 2: Upload Database Backups to S3 To export database backups for archival:\nSSH into database EC2 instance Upload to S3: Via AWS CLI (if configured): aws s3 sync /backups s3://smoking-cessation-backups/ Or manually download and upload via S3 console Bước 3: Archive S3 Data For old data (\u0026gt; 90 days), setup lifecycle policies:\nGo to S3 console Click on bucket name (e.g., \u0026ldquo;leaflungs-images\u0026rdquo;) Go to \u0026ldquo;Management\u0026rdquo; tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Configure: Name: \u0026ldquo;archive-old-data\u0026rdquo; Filter: Prefix \u0026ldquo;chat/\u0026rdquo; Transitions: Move to Glacier after 90 days Expiration: Delete after 365 days Click \u0026ldquo;Create rule\u0026rdquo; Phần 5: Test Resource Cleanup (Non-Production) Bước 1: Delete Test Lambda Functions If any test functions exist:\nGo to Lambda console Click on test function name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete\u0026rdquo; Type function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Bước 2: Delete Unused API Gateway If multiple APIs for testing:\nGo to API Gateway console Click on API name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete API\u0026rdquo; Confirm deletion Bước 3: Delete Empty S3 Buckets To delete a bucket:\nGo to S3 console Click on bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once empty, click \u0026ldquo;Delete\u0026rdquo; button Type bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Bước 4: Delete Unused CloudFront Distributions To delete a CloudFront distribution:\nGo to CloudFront console Click on distribution Click \u0026ldquo;Disable\u0026rdquo; (if enabled) Wait 15 minutes for propagation Once status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm deletion Phần 6: Delete Production Resources (if shutting down) WARNING: This is destructive and cannot be undone!\nBackup Checklist Before Deletion PostgreSQL data backed up (pg_dump) MongoDB data backed up (mongodump) Database backups uploaded to S3 S3 data backed up externally (if needed) CloudTrail logs reviewed \u0026amp; archived Code backed up to GitHub DNS records updated (if redirecting) Team notified Bước 1: Delete EC2 Database Instances To delete database EC2 instances:\nGo to EC2 console Click \u0026ldquo;Instances\u0026rdquo; Select database instance (DB-PG or DB-Mongo) Click \u0026ldquo;Instance State\u0026rdquo; → \u0026ldquo;Terminate\u0026rdquo; Confirm termination Wait for instance to terminate Verify EBS volumes are deleted (optional: create snapshots first if needed) Repeat for second database instance Bước 2: Delete Lambda Functions To delete each Lambda function:\nGo to Lambda console Click on function name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete\u0026rdquo; Type function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Repeat for each function Bước 3: Delete API Gateways To delete each API Gateway:\nGo to API Gateway console Click on API name (e.g., \u0026ldquo;LeafLungs-UserInfo-API\u0026rdquo;) Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete API\u0026rdquo; Confirm deletion Repeat for second API (leaflungs-chat-api) Bước 4: Delete Cognito User Pool To delete Cognito User Pool:\nGo to Cognito console Click \u0026ldquo;User pools\u0026rdquo; Click on your user pool Click \u0026ldquo;Delete user pool\u0026rdquo; (bottom right) Type the user pool name to confirm Click \u0026ldquo;Delete\u0026rdquo; Bước 5: Delete S3 Buckets (and contents) To delete each S3 bucket:\nGo to S3 console For each bucket (leaflungs-frontend-new, leaflungs-images, leaflungs-images-sg): Click on bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once empty, click \u0026ldquo;Delete\u0026rdquo; button Type bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Bước 6: Delete CloudFront Distribution To delete CloudFront distribution:\nGo to CloudFront console Click on distribution (if not already disabled) If enabled, click \u0026ldquo;Disable\u0026rdquo; first Wait 15 minutes for propagation Once status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm deletion Phần 7: Cost Analysis \u0026amp; Reporting Monthly Cost Breakdown Typical costs for this architecture:\nService Usage Cost Lambda 100K invocations/month ~$2 API Gateway 10M requests/month ~$50 EC2 (2x DB instances) 2 x t4g.small for PostgreSQL + MongoDB ~$60-70 EC2 (2x App instances) 2 x t4g.small for applications ~$60-70 S3 100 GB storage ~$2 CloudFront 1 TB/month transfer ~$85 Cognito 1K users ~$0 (free tier) NAT Gateway 10 GB transfer ~$5 Total ~$300-350/month Cost optimization opportunities:\nUse t4g.nano/micro for light databases: Saves ~$20-30/month Cache more aggressively: Saves ~$30/month Reserved EC2 instances: Saves ~$60-80/month Total savings: ~$110-140/month (35-40% reduction) AWS Cost Explorer AWS Console → Billing → Cost Explorer View costs by: Service Linked account Region Usage type Set up cost anomaly detection Review trends Phần 8: Documentation \u0026amp; Lessons Learned Create Post-Mortem Document # Workshop Completion Report ## Architecture Summary - Services deployed: Lambda, API Gateway, EC2 (PostgreSQL + MongoDB), S3, CloudFront, Cognito, NLB - Regions: us-east-1 (Cognito), ap-southeast-1 (main) - Total users: 1000+ - Monthly costs: $300-350 ## Key Learnings 1. Regional considerations - Cognito must be in us-east-1 for CloudFront - Main services in ap-southeast-1 for latency 2. Security best practices implemented - VPC isolation - Security group restrictions - IAM least-privilege - Secrets Manager for credentials 3. Cost optimization - CloudFront caching important - EC2 instances can be right-sized or use Reserved Instances - Reserved instances save 30-50% 4. Monitoring critical - CloudWatch alarms prevented many issues - X-Ray helped debug performance ## Recommendations for Next Phase 1. Setup automated backups for EC2 databases (pg_dump/mongodump cronjobs) 2. Implement CI/CD for automated deployments 3. Add comprehensive test suite 4. Setup on-call rotation \u0026amp; runbooks 5. Quarterly cost reviews Checklist - Cleanup Decision Before final cleanup, verify:\nAll data backed up Snapshots created CloudTrail logs archived Code pushed to GitHub Cost analysis completed Team trained on infrastructure Documentation complete Stakeholders approved DNS cutover plan (if applicable) Rollback plan documented Final Recommendations Keep infrastructure running (you\u0026rsquo;ve built it correctly) Implement automated scaling if needed Setup CI/CD pipeline for updates Add comprehensive testing Plan quarterly cost reviews Train team on operational procedures Consider disaster recovery plan Summary \u0026amp; Next Steps Congratulations! You\u0026rsquo;ve successfully:\n✓ Verified/setup Cognito authentication ✓ Verified/setup Lambda functions ✓ Verified/setup API Gateways ✓ Verified EC2 databases (PostgreSQL + MongoDB) ✓ Verified S3 \u0026amp; CloudFront ✓ Verified VPC \u0026amp; Security ✓ Implemented monitoring \u0026amp; logging ✓ Optimized costs This infrastructure can support:\n1000+ concurrent users 100K+ requests/day Highly available (multi-AZ capable) Scalable (auto-scale Lambda, upgrade EC2 instance types) Secure (VPC isolation, encryption, IAM) Observable (comprehensive logging \u0026amp; monitoring) Kết Quả Đạt Được Sau Module 10:\nResource inventory \u0026amp; usage analyzed Cost optimization strategies identified Unused resources identified for cleanup Backup procedures implemented Cost reduction plan created (up to 36% savings possible) Post-mortem \u0026amp; lessons learned documented Recommendations for next phase Workshop complete \u0026amp; infrastructure production-ready "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.10-week10/","title":"Nhật ký Tuần 10","tags":[],"description":"","content":"Mục tiêu Tuần 10 Program Service: Triển khai logic cốt lõi (Nhiệm vụ Hàng ngày, Theo dõi Chuỗi, Sự kiện Hút thuốc). Chat Service: Chuẩn bị lớp truy cập dữ liệu (Data Access Layer). Các công việc thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Program Service: Triển khai logic sinh ra 4 bước nhiệm vụ hàng ngày cho người dùng. - Chat Service: Tạo các interface ChatRoomRepository và MessageRepository. 10/11/2025 10/11/2025 — 3 - Program Service: Xây dựng API đánh dấu hoàn thành bước và triển khai StreakService. - Chat Service: Viết các truy vấn JPQL tùy chỉnh để tìm tin nhắn theo phòng chat có phân trang. 11/11/2025 11/11/2025 — 4 - Program Service: Phát triển trigger \u0026ldquo;Sự kiện Hút thuốc\u0026rdquo; và logic \u0026ldquo;Soft Reset\u0026rdquo; (Trạng thái: PENDING_RECOVERY). 12/11/2025 12/11/2025 — 5 - Program Service: Triển khai logic khôi phục: gán \u0026ldquo;Bài Quiz Khôi phục\u0026rdquo; và xử lý kết quả (tối đa 3 lần). 13/11/2025 13/11/2025 — 6 - Program Service: Viết Unit Test cho StreakService và thực hiện kiểm thử tích hợp cho toàn bộ luồng. 14/11/2025 14/11/2025 https://junit.org/junit5/ Kết quả đạt được Tuần 10 Program Service: Engine Nhiệm vụ Hàng ngày và Hệ thống Streak đã hoạt động hoàn chỉnh. Cơ chế Khôi phục xử lý thành công \u0026ldquo;Sự kiện Hút thuốc\u0026rdquo; một cách nhân văn. Chat Service: Lớp Truy cập Dữ liệu (Repository) đã được định nghĩa và sẵn sàng để triển khai ở tuần tiếp theo. Bài học rút ra:\nQuản lý Trạng thái Phức tạp: Xử lý các trạng thái của người dùng (Active, Pending Recovery) đòi hỏi một logic máy trạng thái (state machine) vững chắc. Tập trung vào một Service: Dành phần lớn thời gian cho một service phức tạp giúp đảm bảo chất lượng và tiến độ, trong khi vẫn có thể thực hiện các công việc chuẩn bị cho service khác. JPQL cho Truy vấn Tùy chỉnh: Sử dụng JPQL là một cách mạnh mẽ để viết các truy vấn phức tạp mà Spring Data JPA không tự động hỗ trợ. "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.11-week11/","title":"Nhật ký Tuần 11","tags":[],"description":"","content":"Mục tiêu Tuần 11 Chat Service: Triển khai các API cốt lõi (lấy phòng chat, lịch sử tin nhắn). Program Service: Tinh chỉnh logic nghiệp vụ (Slip/Relapse) và bổ sung các tính năng quản trị. Các công việc thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Chat Service: Triển khai ChatController và API GET /api/v1/chat-rooms/me để lấy danh sách phòng chat của người dùng. 17/11/2025 17/11/2025 — 3 - Chat Service: Triển khai API GET /api/v1/chat-rooms/{roomId}/messages với logic phân trang và sắp xếp. - Chat Service: Triển khai API nội bộ POST /internal/api/v1/chat-rooms. 18/11/2025 18/11/2025 — 4 - Program Service: Triển khai logic phân biệt Slip (khôi phục ngay) và Relapse (hard reset). - Program Service: Bổ sung Flyway để quản lý các thay đổi schema. 19/11/2025 19/11/2025 https://flywaydb.org/ 5 - Program Service: Xây dựng Admin API (CRUD) cho Quiz Templates. - Program Service: Tối ưu hóa logic bộ đếm reset (tối đa 3 lần khôi phục). 20/11/2025 20/11/2025 — 6 - Program Service: Phát triển bộ lập lịch @Scheduled cho Đánh giá Hàng tuần. - Kiểm thử: Dùng Postman để test các API của Chat Service. 21/11/2025 21/11/2025 https://spring.io/guides/gs/scheduling-tasks/ Kết quả đạt được Tuần 11 Chat Service: Các API chính để lấy danh sách phòng chat và lịch sử tin nhắn đã hoạt động. API nội bộ để tạo phòng chat đã sẵn sàng cho các service khác gọi. Program Service: Logic Slip vs Relapse đã hoàn thiện, giúp hệ thống xử lý các tình huống thất bại một cách linh hoạt. Module Admin cho phép quản lý nội dung Quiz một cách độc lập. Hệ thống Đánh giá Hàng tuần được tự động hóa. Bài học rút ra:\nThiết kế API Phân trang: Tầm quan trọng của việc triển khai phân trang hiệu quả cho các API trả về danh sách lớn (lịch sử tin nhắn). Lập lịch (Scheduling): Sử dụng Spring Scheduler là một cách hiệu quả để chạy các công việc định kỳ mà không cần cấu hình phức tạp. Phân bổ công việc: Chuyển đổi trọng tâm giữa các service trong một sprint/tuần giúp duy trì tiến độ đồng đều cho toàn bộ hệ thống. "},{"uri":"https://masterltb.github.io/profile/vi/1-worklog/1.12-week12/","title":"Nhật ký Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12 Đảm bảo chất lượng toàn hệ thống: Thực hiện Unit \u0026amp; Integration Testing cho cả Program Service và Chat Service. Tối ưu hóa hiệu năng: Phân tích và tối ưu hóa các truy vấn PostgreSQL ở cả hai service. Hoàn thiện \u0026amp; Bàn giao: Hoàn tất tài liệu API và chuẩn bị bàn giao hệ thống. Các công việc thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Program Service: Viết Unit Test cho StreakService và QuizService. - Chat Service: Viết Unit Test cho ChatService để kiểm tra logic lấy tin nhắn. 24/11/2025 24/11/2025 https://site.mockito.org/ 3 - Program Service: Viết Integration Test cho luồng \u0026ldquo;Sự kiện hút thuốc -\u0026gt; Khôi phục\u0026rdquo;. - Chat Service: Viết Integration Test cho luồng \u0026ldquo;Lấy danh sách phòng chat -\u0026gt; Lấy lịch sử tin nhắn\u0026rdquo;. 25/11/2025 25/11/2025 — 4 - Tối ưu hóa: Dùng EXPLAIN ANALYZE để phân tích và thêm index cho các bảng của cả hai service, đặc biệt là các cột khóa ngoại và cột dùng để sắp xếp. 26/11/2025 26/11/2025 https://www.postgresql.org/docs/current/using-explain.html 5 - Tài liệu: Cập nhật api-docs.md với đầy đủ thông tin chi tiết cho tất cả các API của cả hai service. - Báo cáo: Hoàn thiện báo cáo thực tập, mô tả kiến trúc microservices. 27/11/2025 27/11/2025 https://swagger.io/ 6 - Rà soát: Dọn dẹp code, kiểm tra lại cấu hình và các biến môi trường. - Thuyết trình: Chuẩn bị demo và trình bày kiến trúc tổng thể của cả hai service cho mentor. 28/11/2025 28/11/2025 — Kết quả đạt được Tuần 12 Chất lượng hệ thống: Cả hai service đều có độ bao phủ kiểm thử tốt, đảm bảo tính ổn định và đúng đắn của các luồng nghiệp vụ. Tối ưu hiệu năng: Hiệu suất truy vấn của cả hai service được cải thiện, sẵn sàng cho lượng tải thực tế. Tài liệu hoàn chỉnh: Bàn giao tài liệu API thống nhất và rõ ràng cho toàn bộ hệ thống. Hoàn thành: Xây dựng và bàn giao thành công một hệ thống backend microservices hoàn chỉnh. Tổng kết kỳ thực tập: Trong 4 tuần cuối, tôi đã thiết kế và triển khai một hệ thống microservices từ con số 0, bao gồm Program Service và Chat Service. Tôi đã áp dụng các nguyên tắc phát triển phần mềm chuyên nghiệp từ việc thiết kế, triển khai, kiểm thử, tối ưu hóa cho đến việc viết tài liệu, và đã chuyển đổi thành công các yêu cầu nghiệp vụ phức tạp thành một sản phẩm phần mềm hoạt động.\n"},{"uri":"https://masterltb.github.io/profile/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://masterltb.github.io/profile/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]